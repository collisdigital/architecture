{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to NHS Wales Architecture","text":"<p>This site serves as a repository for sharing NHS Wales architectural knowledge, decisions, and principles. It is maintained by Digital Health and Care Wales (DHCW).</p>"},{"location":"#what-youll-find-here","title":"What You'll Find Here","text":""},{"location":"#architecture-principles","title":"Architecture Principles","text":"<p>Our Architecture Principles guide how we design and build systems across NHS Wales. These principles cover areas including:</p> <ul> <li>User-Centred Design</li> <li>Security and Identity</li> <li>Cloud and Infrastructure</li> <li>Digital Products and Software Engineering</li> <li>Data and Analytics</li> <li>Open Architecture</li> </ul>"},{"location":"#architecture-decisions","title":"Architecture Decisions","text":"<p>We use Architecture Decision Records (ADRs) to document important architectural choices, including their context, consequences, and rationale. This documentation helps teams understand not just what was decided, but why those decisions were made.</p> <p>Our decisions are organised into three categories:</p> <ul> <li>Meta Decisions: Decisions about our ADR process itself, documentation   standards, and tooling</li> <li>Process Decisions: Decisions about how we work, including security   processes, development workflows, and operational procedures</li> <li>Technical Decisions: Technology choices, system architectures, integration   patterns, and infrastructure decisions</li> </ul>"},{"location":"#design-authority","title":"Design Authority","text":"<p>The DHCW Technical Design Authority (TDA) oversees architectural decisions and ensures alignment with NHS Wales's strategic objectives. You'll find:</p> <ul> <li>Our ADR process and templates</li> <li>Terms of reference</li> <li>Meeting records and decisions</li> <li>Enterprise architecture metamodel</li> </ul>"},{"location":"#getting-started","title":"Getting Started","text":"<ol> <li> <p>New to ADRs? Read why we write architecture decision records    and this practical overview of ADRs</p> </li> <li> <p>Want to propose a new architecture decision? Follow our ADRProcess</p> </li> <li> <p>Looking for guidance? Start with our Architecture Principles</p> </li> <li> <p>Need to review past decisions? Browse our Categorised decisions</p> </li> </ol>"},{"location":"#contributing","title":"Contributing","text":"<p>This site is managed through our GitHub repository. We welcome contributions from the NHS Wales technology community.</p> <p>Feel free to raise an Issue to start a discussion.</p> <p>See also our ADR process documentation for details on how to propose or contribute new decisions.</p>"},{"location":"decisions/","title":"Architecture Decisions","text":"<p>Warning</p> <p>The ADR Process, Template and this site are iterating rapidly right now as we seek to introduce ADRs and change our ways of working. Content may be at different levels of completeness and consistency right now, this will improve with time.</p> <p>This section contains all architecture decisions that have been made and documented using our Architecture Decision Records (ADR) process. The decisions are organised into three main categories:</p> <p>Each decision is documented using our standard ADR Template, which ensures consistent and complete documentation of the context, consequences, and rationale behind each choice.</p>"},{"location":"decisions/#meta-decisions","title":"Meta Decisions","text":"<p>Meta decisions are decisions about how we make and document decisions. These include choices about our ADR process itself, documentation standards, and tooling. These includes decisions about:</p> <ul> <li>Naming conventions for ADRs</li> <li>Documentation format and tools</li> <li>Site navigation enhancements</li> <li>Quality assurance tools like linters and spell checkers</li> </ul>"},{"location":"decisions/#process-decisions","title":"Process Decisions","text":"<p>Process decisions document important choices about how we work and operate. For example, these cover areas such as:</p> <ul> <li>Security processes (e.g., vulnerability disclosure)</li> <li>Development workflows</li> <li>Operational procedures</li> </ul>"},{"location":"decisions/#technical-decisions","title":"Technical Decisions","text":"<p>Technical decisions are specific architectural choices about our systems, technologies, and implementations. These are include decisions about:</p> <ul> <li>Technology selections</li> <li>System architectures</li> <li>Integration patterns</li> <li>Security implementations</li> <li>Infrastructure choices</li> </ul>"},{"location":"decisions/meta-decisions/architecture-decision-records-naming-conventions/","title":"Architecture Decision Records Naming Convention","text":"<p>Pending Approval</p> <p>Awaiting approval by DHCW Technical Design Authority</p> <p>Status: proposed Date: 2025-03-25 Governance: Drafted for DHCW Technical Design Authority (TDA) for approval</p>"},{"location":"decisions/meta-decisions/architecture-decision-records-naming-conventions/#situation-context-and-problem-statement","title":"Situation - Context and Problem Statement","text":"<ul> <li>We want to record architecture related decisions for NHS Wales organisations, made via agreed governance mechanisms.</li> <li>We need to agree a naming convention for the records i.e how to name records and refer to them.</li> <li>We should also agree a folder &amp; filename convention aligned with the naming convention.</li> </ul>"},{"location":"decisions/meta-decisions/architecture-decision-records-naming-conventions/#background-decision-drivers","title":"Background - Decision Drivers","text":"<p>We want:</p> <ul> <li>a consistent naming convention for our decisions.</li> <li>names to be human readable and easy to understand.</li> <li>to be able to cross-reference Architecture Decision Records easily.</li> <li>the naming to support multiple Architecture Decision Records being developed in parallel (i.e. avoid naming clashes).</li> </ul>"},{"location":"decisions/meta-decisions/architecture-decision-records-naming-conventions/#assessment-considered-options","title":"Assessment - Considered Options","text":"<p>For naming itself:</p> <ul> <li>Just sequential numbering e.g. ADR 0001, ADR 0002, ...</li> <li>Sequential numbering and titles e.g. ADR 0001 - Title, ADR 0002 - Title, ...</li> <li>Just titles e.g. \"Title of a Record\"</li> <li>Formless \u2013 No naming convention - author's choice.</li> </ul> <p>For filenames:</p> <ul> <li>The title of the Architecture Decision Record as above as-is e.g. <code>Title Goes Here.md</code></li> <li>Use of lowercase 'kebab' style for filenames e.g. <code>title-goes-here.md</code></li> <li>Use of lowercase 'snake' style for filenames e.g. <code>title_goes_here.md</code></li> </ul> <p>On acronyms:</p> <ul> <li>Use 'ADR' as an acronym for Architecture Decision Record.</li> <li>Avoid acronyms, e.g. always spell out \"Architecture Decision Record\" in full.</li> </ul>"},{"location":"decisions/meta-decisions/architecture-decision-records-naming-conventions/#recommendation-decision-outcome","title":"Recommendation - Decision Outcome","text":""},{"location":"decisions/meta-decisions/architecture-decision-records-naming-conventions/#naming-conventions","title":"Naming Conventions","text":"<p>Adopt an Architecture Decision Record naming convention of:</p> <ul> <li>Just titles, in Title Case</li> <li>Author to ensure the title makes it clear what the decision relates to.</li> <li>Author to ensure titles are human readable and unique.</li> <li>Avoid the use of acronyms</li> <li>Examples:</li> <li>'Use Architecture Decision Records and Structure'</li> <li>'Architecture Decision Records Naming Conventions'</li> <li>'Format Architecture Decision Records with Markdown'</li> </ul> <p>Whilst numbering Architecture Decision Records makes them easy to cross-reference, it introduces an administrative/process overhead to ensure numbers are unique and sequential and adds complexity in the ordering of records, especially when multiple records are in development in parallel (which gets published first, who gets the next record number etc.)</p> <p>Avoiding acronyms and using human readable names makes them easier for users to understand, refer to and talk about.</p> <p>Note: We are referring to 'Architecture' decision records, not 'Architectural' or other similar words.</p> <p>Note: Readability is important, it may be better to refer to Architecture Decision Records as decisions and records in documents rather than always writing out the full Architecture Decision Records every time e.g.</p> <ul> <li>\"This record builds on the previous decision\" (good - emphasis only added here for clarity).</li> <li>\"This Architecture Decision Record builds on the previous Architecture Decision Record\" (worse/avoid).</li> </ul>"},{"location":"decisions/meta-decisions/architecture-decision-records-naming-conventions/#folder-and-filenames","title":"Folder and Filenames","text":"<p>Given the above, apply the following convention to the storage and naming of records, this convention makes publishing easier even though it adds a little complexity:</p> <p>Each decision should have its own folder, whose name should match the Title of the record, with whitespace removed and adopting a kebab style e.g.</p> <ul> <li><code>./architecture-decision-records-naming-conventions/</code></li> <li><code>./use-architecture-decision-records-and-structure/</code></li> <li><code>./format-architecture-decision-records-with-markdown/</code></li> </ul> <p>Within each folder create an <code>index.md</code> file which contains the decision contents. Create a symbolic link from <code>README.md</code> to <code>index.md</code> - this ensures that GitHub renders the documents when navigating the repository e.g.</p> <ul> <li><code>./architecture-decision-records-naming-conventions/index.md</code></li> <li><code>./architecture-decision-records-naming-conventions/README.md -&gt; index.md</code></li> </ul> <p>Both <code>index.md</code> and <code>README.md</code> should be added and committed to Git.</p> Creating a symbolic link (Windows/Mac/Linux) WindowsMacOS/Linux <p>You can think of a symbolic link as a shortcut that points to another file.</p> <p>Note PowerShell doesn't seem to create relative symbolic links so you must instead launch Command Prompt with Admin privileges, navigate to the folder containing the index.md and run:</p> <p><code>mklink README.md index.md</code></p> <p>Running <code>dir</code> afterwards should show output similar to this:</p> <pre><code>    &gt; dir\n     ...\n    16/05/2025  13:04    &lt;DIR&gt;          .\n    16/05/2025  13:01    &lt;DIR&gt;          ..\n    16/05/2025  13:01             5,660 index.md\n    16/05/2025  13:04    &lt;SYMLINK&gt;      README.md [index.md]\n</code></pre> <p>Navigate to the folder containing the index.md and run:</p> <p><code>ln -s index.md README.md</code></p>"},{"location":"decisions/meta-decisions/architecture-decision-records-naming-conventions/#cross-referencing","title":"Cross Referencing","text":"<p>When cross-referencing decisions, use the full title of the decision and add a relative link to the record <code>index.md</code> itself e.g.</p> <ul> <li>See Architecture Decision Records Naming Conventions</li> </ul>"},{"location":"decisions/meta-decisions/architecture-decision-records-naming-conventions/#branches","title":"Branches","text":"<p>Git branch names should utilise the same convention as the main folder name of the decision itself e.g.</p> <ul> <li><code>git checkout -b architecture-decision-records-naming-conventions</code></li> </ul>"},{"location":"decisions/meta-decisions/architecture-decision-records-naming-conventions/#confirmation","title":"Confirmation","text":"<p>This decision will be enforced by reviewers of newly submitted records, who should refer to this decision and confirm the naming convention and decision herein is being adhered to.</p>"},{"location":"decisions/meta-decisions/architecture-decision-records-naming-conventions/#more-information","title":"More Information","text":"<p>See Use Architecture Decision Records and Structure for the structure of records.</p>"},{"location":"decisions/meta-decisions/enable-mkdocs-enhanced-site-navigation/","title":"Site Navigation","text":"<p>Status: accepted</p> <p>Date: Updated 2025-04-08</p> <p>Governance: Chris &amp; Joel for now because this is so lightweight.</p>"},{"location":"decisions/meta-decisions/enable-mkdocs-enhanced-site-navigation/#situation-context-and-problem-statement","title":"Situation - Context and Problem Statement","text":"<p>The currently published docs don't have a good structure/navigation and we have a mix of approaches (folders, named files etc). We need to review this and decide an approach.</p>"},{"location":"decisions/meta-decisions/enable-mkdocs-enhanced-site-navigation/#background-decision-drivers","title":"Background - Decision Drivers","text":"<ul> <li>Ideally minimise the need to manually maintain the navigation, accepting this may be unavoidable.</li> <li>We want a solution that provides good flexibility in structure/hierarchy/naming etc.</li> <li>We should have a logical structure for navigation that would make sense to consumers.</li> <li>It would be good to also publish architectural principles, so consider how these could fit in.</li> </ul>"},{"location":"decisions/meta-decisions/enable-mkdocs-enhanced-site-navigation/#joels-learning-from-past-experience","title":"Joel's learning from past experience","text":"<p>I have a very-strong preference for always using a topic folder. This is earned learning thanks to many clients. It's the least-worst solution I've found in practice, for a bunch of reasons.</p> <p>I have a moderately-strong preference for always using a file index.*, which makes the work highly compatible with web services.</p> <p>GitHub doesn't do automatic rendering of the index.md file, even when there's no README.md file. My opinion is this is a problem with GitHub, and is easy enough to fix with a symlink, though the symlink sometimes (50%?) have subpar UI effects in other pipeline tooling.</p> <p>I do many projects where the index file format isn't markdown. The most common for web documentation is index.html, for web APIs is index.json, for web data is index.tsv, for databases is index.sql, etc. In my experience this pattern scales really well.</p> <p>I have a moderate preference for all folders using kebab-lower-case-plural by default, because this works especially well for web slugs, autocomplete, AI ingestion, etc.</p> <p>GitHub is notoriously bad about sorting by case-sensitive first, which IMHO is a UI/UX bug.</p> <p>I do use many exceptions though, if a project/platform/language uses conventions, such as Apple XCode using \"FooBars\" word case no spaces, or Rust Axum using \"foo_bars\" snake case, or JavaScript Express using singular camel case \"fooBar\".</p>"},{"location":"decisions/meta-decisions/enable-mkdocs-enhanced-site-navigation/#assessment-considered-options","title":"Assessment - Considered Options","text":"<p>In order to keep the index.md/README.md in a folder structure approach and sticking with MkDocs, after some research it looks like we will need to manually set/maintain the navigation, this can be done natively in MkDocs config but it has some limitations (e.g. won't show anything that isn't manually added to the nav explicitly); therefore we should consider MkDocs plugins - assessed below:</p>"},{"location":"decisions/meta-decisions/enable-mkdocs-enhanced-site-navigation/#mkdocs-literate-nav","title":"mkdocs-literate-nav","text":"<p>mkdocs-literate-nav - lets you create a <code>SUMMARY.md</code> file containing the name in the <code>doc/</code> folder itself e.g.</p> <pre><code>* [Alpha](alpha.md)\n* [Beta](beta.md)\n* [Delta](delta/index.md)\n    * [Bar](delta/bar.md)\n    * [Foo](delta/foo.md)\n</code></pre> <p>You can also nest <code>SUMMARY.md</code> files, so each sub-folder can maintain its own nav structure if desired. Also allows for parts of the nav to be manually set and other parts to be auto-populated based on folder/structure etc. and supports wildcards.</p> <p>Because the Nav is in Markdown it would also render in GitHub.</p>"},{"location":"decisions/meta-decisions/enable-mkdocs-enhanced-site-navigation/#mkdocs-awesome-nav","title":"mkdocs-awesome-nav","text":"<p>mkdocs-awesome-nav - Similar to literal nav but nav is configured via YAML files.</p> <pre><code>sort:\n  sections: mixed\n\nnav:\n  - About:\n    - Getting Started: index.md\n    - philosophy.md\n    - migration-v3.md\n  - \"*\"\n</code></pre> <p>Looks to offer more configuration/flexibility, such as automatic sorting of pages and also 'flattening' of structure - which would help with the one folder per document preference.</p>"},{"location":"decisions/meta-decisions/enable-mkdocs-enhanced-site-navigation/#recommendation-decision-outcome","title":"Recommendation - Decision Outcome","text":"<ol> <li>Adopt the mkdocs-awesome-nav plugin as it does everything we need, including flattening navigation</li> <li>Enable MkDocs headers and footers in the published site to make navigation easier</li> <li>Set top level headings such as Home, Decision, Principles, Values</li> <li>Flatten the nav to remove empty nested items as needed</li> <li>Determine a logical structure and evolve over time as need records are added</li> </ol>"},{"location":"decisions/meta-decisions/format-architecture-decision-records-with-markdown/","title":"Format Architecture Decision Records using plaintext Markdown","text":"<p>Pending Approval</p> <p>Awaiting approval by DHCW Technical Design Authority</p> <p>Status: proposed Date: 2025-03-27 Governance: Drafted for DHCW Technical Design Authority (TDA) for approval</p>"},{"location":"decisions/meta-decisions/format-architecture-decision-records-with-markdown/#situation-context-and-problem-statement","title":"Situation - Context and Problem Statement","text":"<ul> <li>We want to record architecture related decisions for NHS Wales organisations, made via agreed governance mechanisms.</li> <li>The structure is decided by Use Architecture Decision Records</li> <li>We need to agree the format.</li> </ul>"},{"location":"decisions/meta-decisions/format-architecture-decision-records-with-markdown/#background-decision-drivers","title":"Background - Decision Drivers","text":"<ul> <li>We want the format to be simple and easy to publish on the internet.</li> <li>We want the format to support 'formatting' e.g. headings, bold, italics, lists.</li> <li>We don't want any proprietary tools to be required to contribute Architecture Decision Records.</li> <li>We want to align with industry standards (not reinvent the wheel).</li> <li>We want the selected format to be easily adopted.</li> </ul>"},{"location":"decisions/meta-decisions/format-architecture-decision-records-with-markdown/#assessment-considered-options","title":"Assessment - Considered Options","text":"<ul> <li>Markdown</li> <li>Microsoft DOCX</li> <li>Open Document</li> <li>No format \u2013 just plaintext</li> </ul>"},{"location":"decisions/meta-decisions/format-architecture-decision-records-with-markdown/#recommendation-decision-outcome","title":"Recommendation - Decision Outcome","text":"<p>Format Architecture Decision Records as plaintext Markdown documents, using the CommonMark specification.</p> <ul> <li>Allows for Architecture Decision Records to be created and edited in any text editor, no specific software needed.</li> <li>Markdown is easy to learn.</li> <li>Markdown supports the basic formatting we need (bold, italics, headings, lists etc.)</li> <li>Due to the limitations, it guides us to keep things simple (KISS) and easy to read.</li> <li>The CommonMark standard for Markdown is supported by GitHub and many other tools, so widely supported.</li> </ul> <p>Tip</p> <p>Use Markdown Lint in Visual Studio  Code to ensure the formatting in documents will work well when publishing/rendering.</p>"},{"location":"decisions/meta-decisions/format-architecture-decision-records-with-markdown/#consequences","title":"Consequences","text":"<ul> <li>This does require some learning as most staff are familiar with DOCX/Word and may have limited experience of Markdown.</li> <li>Markdown limits the formatting of the document (can be seen as a positive) so users may be constrained in presenting information.</li> </ul>"},{"location":"decisions/meta-decisions/format-architecture-decision-records-with-markdown/#more-information","title":"More Information","text":"<p>See Use Architecture Decision Records and Structure for the structure of an Architecture Decision Record.</p>"},{"location":"decisions/meta-decisions/mastering-of-architecture-templates/","title":"Mastering of Architecture Templates","text":"<p>Info</p> <p>Status: Accepted</p> <p>Level: 1</p> <p>Updated: 2025-10-20</p>"},{"location":"decisions/meta-decisions/mastering-of-architecture-templates/#summary","title":"Summary","text":"<p>This decision addresses the need to establish a definitive source of truth for the Architecture Decision Record (ADR) and Architecture Design Overview (ADO) templates. The decision is to master these templates in Markdown within this GitHub repository. Microsoft Word versions will be automatically generated from the Markdown source to support various stakeholders. This approach preserves the benefits of a \"docs-as-code\" methodology while lowering the barrier to entry for individuals less familiar with Markdown and GitHub.</p>"},{"location":"decisions/meta-decisions/mastering-of-architecture-templates/#drivers","title":"Drivers","text":"<ul> <li>Accessibility for All Stakeholders: A primary driver is to enable staff   with limited or no GitHub/Markdown experience to engage with the ADR/ADO   process. Providing Word-based templates lowers the barrier to entry.</li> <li>Single Source of Truth: To prevent versioning conflicts, content drift,   and maintenance overhead, it is crucial to maintain a single, definitive   master copy of each template.</li> <li>Efficiency and Automation: The process for maintaining both Markdown and   Word versions must be efficient. Manual synchronization is error-prone and   time-consuming.</li> <li>Alignment with Existing Principles: The decision should align with our   existing preference for Markdown, as established in the ADR   Format Architecture Decision Records with Markdown,   which values simplicity and developer-friendliness.</li> </ul>"},{"location":"decisions/meta-decisions/mastering-of-architecture-templates/#options","title":"Options","text":""},{"location":"decisions/meta-decisions/mastering-of-architecture-templates/#option-1-master-in-markdown-generate-word","title":"Option 1: Master in Markdown, Generate Word","text":"<p>The templates will be mastered as Markdown files within the GitHub repository. A CI/CD pipeline (e.g., GitHub Actions) using a tool like Pandoc will automatically generate Microsoft Word versions whenever the source Markdown files are updated.</p> <ul> <li>Source of Truth: GitHub (Markdown)</li> <li>Word Version: Generated artifact</li> </ul>"},{"location":"decisions/meta-decisions/mastering-of-architecture-templates/#option-2-master-in-word-manually-convert-to-markdown","title":"Option 2: Master in Word, Manually Convert to Markdown","text":"<p>The templates will be mastered as Word documents, likely stored in SharePoint. Markdown versions would be created and updated manually by copying content from the Word document.</p> <ul> <li>Source of Truth: SharePoint (Word)</li> <li>Markdown Version: Manual copy</li> </ul>"},{"location":"decisions/meta-decisions/mastering-of-architecture-templates/#option-3-dual-manual-maintenance","title":"Option 3: Dual-Manual Maintenance","text":"<p>Maintain both Markdown and Word versions of the templates manually. Both versions would be considered \"master\" copies, and changes in one would need to be replicated in the other by hand.</p> <ul> <li>Source of Truth: Both GitHub (Markdown) and SharePoint (Word)</li> <li>Synchronization: Manual</li> </ul>"},{"location":"decisions/meta-decisions/mastering-of-architecture-templates/#options-analysis","title":"Options Analysis","text":""},{"location":"decisions/meta-decisions/mastering-of-architecture-templates/#option-1-assessment","title":"Option 1 Assessment","text":"<p>Pro:</p> <ul> <li>Single Source of Truth: Establishes a definitive master version in a   version-controlled environment.</li> <li>Automation: The generation of Word documents is automated, ensuring   consistency and minimizing manual effort.</li> <li>Alignment: Reinforces the \"docs-as-code\" approach and aligns with the   existing decision to use Markdown.</li> <li>Collaboration: Technical stakeholders can easily collaborate on the   templates using standard Git workflows.</li> </ul> <p>Con:</p> <ul> <li>Formatting Limitations: The automatically generated Word documents may not   have the same level of rich formatting or stylistic flexibility as a manually   crafted Word document.</li> <li>Feature Limitation: The automatically generated Word documents may not   utilise dynamic content features of Word, such as generated table of contents   or diagrams etc.</li> </ul> <p>Other:</p> <ul> <li>Leverages existing, well-understood tooling like GitHub Actions.</li> </ul>"},{"location":"decisions/meta-decisions/mastering-of-architecture-templates/#option-2-assessment","title":"Option 2 Assessment","text":"<p>Pro:</p> <ul> <li>Feature Rich Tooling: Allows template editors to use the full feature set   of Microsoft Word.</li> <li>Accessibility: Easier for non-technical staff to edit the master   templates directly.</li> </ul> <p>Con:</p> <ul> <li>Manual Effort: Manual conversion to Markdown is tedious and highly   susceptible to human error.</li> <li>Version Control: Storing the master copy outside of Git makes tracking   changes and managing versions more difficult.</li> <li>Friction for Developers: Creates an inconvenient workflow for technical   staff who prefer plain text and Git.</li> </ul>"},{"location":"decisions/meta-decisions/mastering-of-architecture-templates/#option-3-assessment","title":"Option 3 Assessment","text":"<p>Pro:</p> <ul> <li>Format Optimization: Allows each version to be perfectly formatted using   its native tools.</li> </ul> <p>Con:</p> <ul> <li>High Overhead: Requires double the effort to maintain and is the most   expensive option in terms of time.</li> <li>Synchronization Issues: It is virtually guaranteed that the two versions   will become out of sync over time.</li> <li>Confusion: The lack of a single source of truth creates confusion for   users.</li> </ul>"},{"location":"decisions/meta-decisions/mastering-of-architecture-templates/#recommendation","title":"Recommendation","text":"<p>The decision is to adopt Option 1: Master in Markdown, Generate Word.</p> <p>This option provides the best balance of all requirements. It establishes a single source of truth in a version-controlled system, aligns with our established architectural principles, and uses automation to provide accessible Word versions for all stakeholders. While we accept the potential for minor formatting limitations in the generated Word documents, the benefits of consistency, low maintenance overhead, and a clear, automated workflow far outweigh this drawback.</p>"},{"location":"decisions/meta-decisions/mastering-of-architecture-templates/#consequences","title":"Consequences","text":"<p>Pro:</p> <ul> <li>A clear process and ownership for template management is established.</li> <li>Administrative overhead is significantly reduced.</li> <li>The ADR/ADO process becomes more accessible to a wider range of   stakeholders.</li> </ul> <p>Con:</p> <ul> <li>We accept that the generated Word documents will be functionally effective   but may not be as aesthetically polished as a manually created document.</li> </ul> <p>Other:</p> <ul> <li>A GitHub Actions workflow for Pandoc conversion will be created and   maintained as part of our CI/CD process.</li> </ul>"},{"location":"decisions/meta-decisions/mastering-of-architecture-templates/#confirmation","title":"Confirmation","text":"<ul> <li>Verification: The decision will be considered implemented once a GitHub   Actions workflow is created that successfully converts the ADR and ADO   Markdown templates into Word documents (<code>.docx</code>).</li> <li>Adherence: This automated workflow will be the sole approved method for   producing the Word versions of the templates. Manual creation and uploading   will be discouraged.</li> <li>Metrics: Success will be measured by the consistent availability of   up-to-date Word templates that accurately reflect the latest version of their   Markdown masters.</li> </ul>"},{"location":"decisions/meta-decisions/mastering-of-architecture-templates/#more-information","title":"More Information","text":"<p>This decision builds upon the principles set out in a previous decision:</p> <ul> <li>Format Architecture Decision Records with Markdown</li> </ul>"},{"location":"decisions/meta-decisions/use-a-linter-for-markdown-documents/","title":"Use a Linter for Markdown Documents","text":"<p>Info</p> <p>Status: Accepted</p> <p>Level: 1</p> <p>Updated: 2025-10-20</p>"},{"location":"decisions/meta-decisions/use-a-linter-for-markdown-documents/#summary","title":"Summary","text":"<p>This ADR addresses the need for a standardized approach to maintaining the quality and consistency of markdown documents within the project. It proposes the adoption of a linting tool to automatically check for common mistakes, enforce style guidelines, and improve overall readability. The decision focuses on selecting a tool that is readily available, configurable, and integrates well with the development environment.</p>"},{"location":"decisions/meta-decisions/use-a-linter-for-markdown-documents/#drivers","title":"Drivers","text":"<p>The primary drivers for this decision are:</p> <ul> <li>Improving Quality: To enhance the quality of documentation by automatically catching common errors and inconsistencies.</li> <li>Immediate Need: The need to implement a solution quickly to address current documentation practices.</li> <li>Local Execution: The requirement for a tool that can be run locally without sending data to external services.</li> <li>VS Code Integration: To ensure compatibility with the primary editor used by the team.</li> <li>Good Marketplace Rating: To select a tool that is well-regarded and trusted by the community.</li> <li>Focus on Markdown: The immediate priority is to improve the quality of markdown documents.</li> <li>Shareable Configuration: The ability to store the linter's configuration within the project repository for consistency across the team.</li> </ul>"},{"location":"decisions/meta-decisions/use-a-linter-for-markdown-documents/#options","title":"Options","text":""},{"location":"decisions/meta-decisions/use-a-linter-for-markdown-documents/#markdownlint","title":"markdownlint","text":"<p>markdownlint is a popular, fast, and configurable linter that focuses specifically on markdown. Its configuration can be stored in a <code>.markdownlint.json</code> file, making it easy to share across a team.</p>"},{"location":"decisions/meta-decisions/use-a-linter-for-markdown-documents/#trunkio","title":"trunk.io","text":"<p>trunk.io is a more comprehensive tool that supports linting for multiple languages and offers a range of features beyond basic linting.</p>"},{"location":"decisions/meta-decisions/use-a-linter-for-markdown-documents/#options-analysis","title":"Options Analysis","text":""},{"location":"decisions/meta-decisions/use-a-linter-for-markdown-documents/#markdownlint-assessment","title":"markdownlint Assessment","text":"<p>Pro:</p> <ul> <li>Focus on Markdown: Specifically designed for markdown, which aligns with the immediate need.</li> <li>Popularity: Widely used and well-regarded.</li> <li>Integrates with VS Code: See VS Code marketplace.</li> <li>Speed and Configurability: Fast and allows for a customized ruleset.</li> <li>Shared Configuration: The configuration can be checked into the repository, ensuring consistency.</li> </ul> <p>Con:</p> <ul> <li>Limited Scope: Only supports markdown, which may require additional tools for other languages.</li> </ul> <p>Other:</p> <ul> <li>Community Support: Benefits from a large user base and active development.</li> </ul>"},{"location":"decisions/meta-decisions/use-a-linter-for-markdown-documents/#trunkio-assessment","title":"trunk.io Assessment","text":"<p>Pro:</p> <ul> <li>Multi-language Support: Can handle various file types, offering a single solution for broader linting needs.</li> <li>Extensive Features: Provides more than just linting, which could be beneficial in the long term.</li> </ul> <p>Con:</p> <ul> <li>Complexity: The additional features may introduce unnecessary complexity for the immediate goal.</li> <li>Further Research Needed: Requires more investigation to fully understand its capabilities and suitability.</li> </ul> <p>Other:</p> <ul> <li>Potential for Future Use: Could be a viable option as the project's needs evolve.</li> </ul>"},{"location":"decisions/meta-decisions/use-a-linter-for-markdown-documents/#recommendation","title":"Recommendation","text":"<p>The recommendation is to adopt markdownlint for the following reasons:</p> <ul> <li>It directly addresses the immediate need to improve markdown quality.</li> <li>Its simplicity, speed, and configurability make it a practical choice for the current requirements.</li> <li>The ability to include the configuration file in the repository ensures that all team members adhere to the same standards.</li> <li>Has a VS Code extension to enable built-in linting but can also be run standalone.</li> </ul> <p>The <code>.markdownlint.json</code> configuration file will be committed to the top level of the repository. This decision can be revisited if the team's needs change or if a more comprehensive tool becomes necessary.</p>"},{"location":"decisions/meta-decisions/use-a-linter-for-markdown-documents/#consequences","title":"Consequences","text":"<p>Pro:</p> <ul> <li>Improved Consistency: All markdown documents will follow a consistent style, improving readability and maintainability.</li> <li>Reduced Errors: Automated checks will catch common mistakes, reducing the manual effort required for reviews.</li> </ul> <p>Con:</p> <ul> <li>Initial Setup: Some initial effort will be required to configure the rules and integrate the linter into the workflow.</li> <li>Learning Curve: Team members will need to familiarize themselves with the chosen linter and its rules.</li> </ul> <p>Other:</p> <ul> <li>Potential for Automation: This decision opens the door to integrating automated linting checks into the CI/CD pipeline.</li> </ul>"},{"location":"decisions/meta-decisions/use-a-linter-for-markdown-documents/#confirmation","title":"Confirmation","text":"<p>To confirm the successful implementation of this decision, the following steps will be taken:</p> <ul> <li>Configuration File: The <code>.markdownlint.json</code> file will be created and added to the repository.</li> <li>Documentation: The <code>README.md</code> file will be updated with instructions on how to install and run the linter.</li> <li>Local Setup: The project's <code>Makefile</code> will be updated to include a <code>lint</code> target for easy local running.</li> <li>PR Process\": A GitHub Action workflow <code>markdownlint.yml</code> will be added to run the linter on PRs and fail them if there are errors.</li> <li>AI Support: The project's <code>AGENTS.md</code> file will include the need to lint &amp; fix before raising a PR.</li> </ul>"},{"location":"decisions/meta-decisions/use-a-linter-for-markdown-documents/#more-information","title":"More Information","text":"<p>For more information on <code>markdownlint</code>, please refer to the official documentation and the VS Code marketplace page. Any proposed changes to the linting rules should be discussed with the team and approved before being implemented.</p>"},{"location":"decisions/meta-decisions/use-arc42-for-architecture-overview-documents/","title":"Adoption of Architecture Overview Documents","text":"<p>Info</p> <p>Status: Proposed</p> <p>Level: 2</p> <p>Updated: 2025-07-24</p>"},{"location":"decisions/meta-decisions/use-arc42-for-architecture-overview-documents/#summary","title":"Summary","text":"<p>DHCW has well-established assurance processes for design that have been aligned to traditional waterfall methodologies for many years. As part of this approach, architects complete designs documented in Solution Architecture Documents (SADs), which are then peer-reviewed by the TDAG committee comprising experts from all major technical domains.</p> <p>There are several issues associated to using SADs within the organisation:</p> <ul> <li>SADs reflect the initial design from an architectural perspective, but they do not reflect what gets implemented.</li> <li>SADs tend to be very lengthy documents and are difficult to consume for the end reviewers.</li> <li>SAD format doesn't take into account all areas of design concern.</li> </ul>"},{"location":"decisions/meta-decisions/use-arc42-for-architecture-overview-documents/#drivers","title":"Drivers","text":"<p>The current assurance process results in SADs that often become obsolete once services are delivered, as changes made during implementation are not consistently captured or updated. This leads to a loss of accuracy in the documented state of the global architecture, reducing confidence in SADs as a reliable source of truth.  Decision drivers are as follows:</p> <ul> <li>Modern ways of working need to focus on iterative approaches to design.</li> <li>Design assurance is needed earlier and iteratively.</li> <li>Architecture needs to be a continuous activity, and documentation needs to reflect that.</li> <li>Architects are no longer singularly responsible for updating designs, and collaboration between disciplines to maintain the documentation is needed.</li> <li>Focus on end-to-end design architecture, rather than just software.</li> <li>Adopt a template format that AI can interpret and work with to improve their output when asked to contribute to projects.</li> </ul>"},{"location":"decisions/meta-decisions/use-arc42-for-architecture-overview-documents/#options","title":"Options","text":"<p>Several options were identified that were considered for the review.</p>"},{"location":"decisions/meta-decisions/use-arc42-for-architecture-overview-documents/#option-1-keep-existing-documentation-standards","title":"Option 1 - Keep existing documentation standards","text":"<p>Retain the existing processes and design artefacts such as SAD, SRS, HLD, LLD.</p>"},{"location":"decisions/meta-decisions/use-arc42-for-architecture-overview-documents/#option-2-dhcw-specific-lightweight-design-template","title":"Option 2 - DHCW specific lightweight design template","text":"<p>DHCW would design a lightweight document template, managing the new format as a product.</p>"},{"location":"decisions/meta-decisions/use-arc42-for-architecture-overview-documents/#option-3-adopt-a-recognised-industry-standard","title":"Option 3 - Adopt a recognised industry standard","text":"<p>A lightweight format that can be adopted in line with other new tools, and maintained by the industry keeping it relevant to the latest architecture concerns.</p>"},{"location":"decisions/meta-decisions/use-arc42-for-architecture-overview-documents/#options-analysis","title":"Options Analysis","text":""},{"location":"decisions/meta-decisions/use-arc42-for-architecture-overview-documents/#option-1-assessment","title":"Option 1 Assessment","text":"<p>Pros:</p> <ul> <li>DHCW architects familiar with the existing artefacts and processes.</li> </ul> <p>Cons:</p> <ul> <li>Documents are not kept up to date.</li> <li>Implementation does not match the design.</li> <li>Very lengthy documents and difficult to consume for the end reviewers.</li> <li>Not sustainable for the change to Product focussed delivery.</li> <li>Doesn't cover all aspects of the end to end design.</li> </ul>"},{"location":"decisions/meta-decisions/use-arc42-for-architecture-overview-documents/#option-2-assessment","title":"Option 2 Assessment","text":"<p>Pros:</p> <ul> <li>DHCW can tailor a template for itself.</li> <li>Can utilise and complement our existing toolset.</li> <li>New lightweight design template.</li> </ul> <p>Cons:</p> <ul> <li>DHCW responsible for maintaining the template.</li> <li>Architecture function will be responsible for training.</li> </ul>"},{"location":"decisions/meta-decisions/use-arc42-for-architecture-overview-documents/#option-3-assessment","title":"Option 3 Assessment","text":"<p>Pros:</p> <ul> <li>Maintained and supported industry standard.</li> <li>Pre-existing templates and examples.</li> <li>Well known in the architect community.</li> </ul> <p>Cons:</p> <ul> <li>DHCW responsible for maintaining the template.</li> <li>Architecture function will be responsible for training.</li> </ul>"},{"location":"decisions/meta-decisions/use-arc42-for-architecture-overview-documents/#recommendation","title":"Recommendation","text":"<p>After an initial assessment of the pros and cons for all options, option 3 was selected for further investigation to identify possible standards.  The following standards were considered:</p> <ul> <li> <p>C4 modelling - excellent tool for modelling software, however lacking the end-to-end view.</p> </li> <li> <p>Arc42 - An industry wide adopted methodology for documenting architecture, open source and supported, primarily based on Markdown.  Well documented template in multiple formats, with supporting documentation to assist architects through the information gathering process.  Many supporting examples.</p> </li> </ul> <p>After consideration, the recommendation is that DHCW will adopt the arc42 modelling template for solution architecture for the following reasons:</p> <p>1. Structured and Comprehensive Framework - arc42 provides a well-defined, standardised template covering all critical aspects of architecture, including context, constraints, quality scenarios, building blocks, runtime views, and decisions. This ensures designs are documented holistically rather than inconsistently or partially, which is common with unstructured documentation.</p> <p>2. Decision-Centric and Maintainable - It integrates architectural decisions (via ADRs) directly within the design structure, promoting traceability of why choices were made. This is more maintainable than freeform documents like traditional SADs, which often focus only on static design outputs rather than design rationale.</p> <p>3. Technology-Agnostic and Methodology-Neutral - arc42 does not enforce any specific technology stack or delivery methodology (waterfall, agile, or hybrid). Its adaptability makes it ideal in mixed delivery environments like DHCW, where multiple approaches coexist.</p> <p>4. Widely Adopted and Supported - It is an internationally recognised and peer-reviewed framework used across industries, with extensive guidance, examples, and community support. This ensures new team members can onboard quickly and understand documentation without bespoke organisational training.</p> <p>5. Promotes Consistency and Reuse - By enforcing a common structure and language across projects and teams, arc42 reduces cognitive load, facilitates reviews and assurance processes (such as TDAG), and enables reuse of design knowledge across programmes, improving architectural governance maturity.</p> <p>6. Optimised for AI Interpretation and Generation - The structured and consistent nature of the arc42 template makes it highly suitable for AI tools to interpret, generate, or update documentation efficiently. Its clear separation of concerns and predictable sectioning allow AI assistants to analyse, summarise, validate, or even draft architecture content with minimal ambiguity, enhancing productivity and ensuring documentation remains up to date.</p> <p>For more information on arc42, go to arc42.org</p>"},{"location":"decisions/meta-decisions/use-architecture-decision-records-and-structure/","title":"Use Architecture Decision Records and Structure","text":"<p>Pending Approval</p> <p>Awaiting approval by DHCW Technical Design Authority</p> <p>Status: proposed Date: 2025-03-25 Governance: Drafted for DHCW Technical Design Authority (TDA) for approval</p>"},{"location":"decisions/meta-decisions/use-architecture-decision-records-and-structure/#situation-context-and-problem-statement","title":"Situation - Context and Problem Statement","text":"<ul> <li>We want to record architecture related decisions for NHS Wales organisations, made via agreed governance mechanisms.</li> <li>We need to agree the structure of the records i.e what information a record should contain.</li> </ul>"},{"location":"decisions/meta-decisions/use-architecture-decision-records-and-structure/#background-decision-drivers","title":"Background - Decision Drivers","text":"<ul> <li>We want the structure to support both detailed and lightweight records.</li> <li>We want to align with industry standards (not reinvent the wheel).</li> <li>We want the selected structure to be easily adopted.</li> </ul>"},{"location":"decisions/meta-decisions/use-architecture-decision-records-and-structure/#assessment-considered-options","title":"Assessment - Considered Options","text":"<p>The structure utilised by:</p> <ul> <li>Michael Nygard's template \u2013 The first incarnation of the term \"Architecture Decision Records\" (ADR)</li> <li>MADR 4.0.0 \u2013 The Markdown Architectural Decision Records</li> <li>Decision record template by Jeff Tyree and Art Akerman - Used in CapitalOne (regulated industry)</li> <li>Other templates listed at https://github.com/joelparkerhenderson/architecture_decision_record</li> <li>SBAR (Situation, Background, Assessment, Recommendation) template - used by DHCW internally and in healthcare generally.</li> <li>Formless \u2013 No conventions for structure</li> </ul>"},{"location":"decisions/meta-decisions/use-architecture-decision-records-and-structure/#recommendation-decision-outcome","title":"Recommendation - Decision Outcome","text":"<p>Adopt an Architecture Decision Record structure with mandatory and optional fields,  taking elements of MADR and aligning it with the existing SBAR structure.</p> <ul> <li>Allows for structured capturing of any decision.</li> <li>The structure is comprehensible and facilitates usage &amp; maintenance.</li> <li>It allows varying levels of detail to suit the decision being made.</li> <li>Aligns with existing terminology and structure that teams will be familiar with.  </li> <li>The structure enables flexibility in format, storage and publishing.</li> </ul> <p>See Architecture Decision Record Template</p>"},{"location":"decisions/meta-decisions/use-material-for-mkdocs-for-publishing/","title":"Use Material for MkDocs for Publishing","text":"<p>Pending Approval</p> <p>Awaiting approval by DHCW Technical Design Authority</p> <p>Status: proposed Date: 31/03/2025 Governance: Drafted for DHCW Technical Design Authority (TDA) for approval</p>"},{"location":"decisions/meta-decisions/use-material-for-mkdocs-for-publishing/#situation-context-and-problem-statement","title":"Situation - Context and Problem Statement","text":"<p>We are capturing architecture decisions as plaintext Markdown documents and storing these in a GitHub repository. This is quite a 'technical' way of working that requires understanding of Git, Markdown and the GitHub.com website and workflow. This represents a barrier for people engaging with our content.</p>"},{"location":"decisions/meta-decisions/use-material-for-mkdocs-for-publishing/#background-decision-drivers","title":"Background - Decision Drivers","text":"<p>We want:</p> <ul> <li>to use our existing Markdown files, not create separate documents</li> <li>the content to be open and public (no login, paywall, registration etc.)</li> <li>the content to be kept up-to-date automatically</li> <li>a good user experience and visual design</li> <li>alignment with NHS Wales branding</li> <li>the ability for user to search our content</li> <li>the ability for users to navigate our content in a logical and structured way</li> <li>a widely supported approach/technology</li> <li>a free and open source solution</li> <li>low or no cost</li> <li>something easy to configure/manage and work with</li> <li>flexibility to change in the future should we choose</li> </ul>"},{"location":"decisions/meta-decisions/use-material-for-mkdocs-for-publishing/#assessment-considered-options","title":"Assessment - Considered Options","text":"<ul> <li>GitHub Pages with Jekyll</li> <li>Docusaurus</li> <li>Readthedocs</li> <li>MkDocs</li> <li>Material for MkDocs</li> <li>A review of these alternative tools</li> </ul>"},{"location":"decisions/meta-decisions/use-material-for-mkdocs-for-publishing/#recommendation-decision-outcome","title":"Recommendation - Decision Outcome","text":"<p>Use Material for MkDocs hosted on  GitHub Pages.</p> <p>Rationale:</p> <ul> <li>MkDocs allows us to build static HTML files from Markdown files, these can be published using GitHub Pages, at no cost.</li> <li>MkDocs is FOSS; mature, well supported and actively maintained.</li> <li>It is simple to setup and run locally.</li> <li>It is based on Python, which is destined to be one of our preferred languages.</li> <li>It is straightforward to automate publishing using GitHub Actions, meaning the site is always up-to-date with the latest changes.</li> <li>The 'Material' theme provides a good user experience that is visually pleasing</li> <li>Plugins and Markdown extensions provide us flexibility to enhance the site in future.</li> <li>The default site/layout/organisation fits our needs/audience well.</li> <li>It is is commitment, we could change to another of the solutions with minimal effort in the future.</li> </ul> <p>Other options ruled out:</p> <ul> <li>Docusaurus - preference was for a static HTML site rather than a Single Page App/Javascript heavy approach, keeping things simple.</li> <li>readthedocs - Was a strong contender, and it does have a free plan, but this has advertising embedded and an on-ramp to paid plans which we prefer to avoid</li> <li>Jekyll/GitHub Pages - The default site/layout/organisation wasn't as favourable as Material for MkDocs.</li> </ul>"},{"location":"decisions/meta-decisions/use-mermaid-for-documenting-diagrams/","title":"Use Mermaid for Diagrams","text":"<p>Pending Approval</p> <p>Awaiting approval</p> <p>Status: pending Date: 16/05/2025 Governance: Drafted for approval</p>"},{"location":"decisions/meta-decisions/use-mermaid-for-documenting-diagrams/#situation-context-and-problem-statement","title":"Situation - Context and Problem Statement","text":"<p>We require a standardised and maintainable method for embedding diagrams within our Architecture Decision Records (ADRs). Currently, diagrams are created using a variety of tools and methods, leading to inconsistencies in style, difficulties in updating, and challenges with version controlling these visual assets alongside the textual documentation. This ad-hoc approach hinders the clarity and long-term maintainability of our architectural documentation.</p>"},{"location":"decisions/meta-decisions/use-mermaid-for-documenting-diagrams/#background-decision-drivers","title":"Background - Decision Drivers","text":"<ul> <li>Version Control: Diagrams should be easily version-controlled alongside     the ADR markdown files.</li> <li>Developer Experience: Need for a low-friction method for developers to     create, view, and update diagrams.</li> <li>Consistency: Desire for a uniform look and feel for diagrams across all     records.</li> <li>Accessibility: Diagrams should be easily viewable by all team members     without requiring specialised licensed software.</li> <li>Maintainability: Diagrams should be easy to update as the architecture     evolves.</li> </ul>"},{"location":"decisions/meta-decisions/use-mermaid-for-documenting-diagrams/#assessment-considered-options","title":"Assessment - Considered Options","text":"<ul> <li>Mermaid</li> <li>PlantUML</li> <li>draw.io (diagrams.net)</li> </ul>"},{"location":"decisions/meta-decisions/use-mermaid-for-documenting-diagrams/#recommendation-decision-outcome","title":"Recommendation - Decision Outcome","text":"<p>Chosen Option: Mermaid</p> <p>We will use Mermaid for creating and embedding diagrams in our Architecture Decision Records.</p> <p>Info</p> <p>To enhance accessibility for screen readers, always include <code>accTitle</code> (a short, descriptive title) and <code>accDescr</code> (a longer description) within your Mermaid diagram code blocks.</p> <p>This provides context for users who cannot see the visual diagram.</p> <p>For more details, see Mermaid Accessibility - accTitle and accDescr.</p> <p>Tip</p> <p>Install the Markdown Preview Mermaid Support VS Code Extension to preview diagrams when editing Markdown files in VS Code.</p>"},{"location":"decisions/meta-decisions/use-mermaid-for-documenting-diagrams/#justification","title":"Justification","text":"<p>Mermaid is chosen due to its excellent integration with Markdown-based documentation systems like MkDocs, which we use. Its \"diagrams as code\" approach allows diagrams to be stored as text, making them inherently version-controllable alongside the ADR content. The syntax is relatively simple for common diagram types (flowcharts, sequence diagrams, class diagrams, state diagrams, etc.), lowering the barrier to entry for team members. This approach reduces reliance on external tools for creation and viewing, and helps ensure diagrams are kept up-to-date as they are co-located with the descriptive text.</p>"},{"location":"decisions/meta-decisions/use-mermaid-for-documenting-diagrams/#consequences","title":"Consequences","text":"<ul> <li>Good, because diagrams can be diffed and version-controlled effectively with Git.</li> <li>Good, because it simplifies the toolchain for documentation, as diagrams render directly in our documentation portal.</li> <li>Good, because it encourages consistency in diagramming style and notation.</li> <li>Good, because lots of tooling exists (e.g. VS Code extensions)</li> <li>Bad, because Mermaid's capabilities for very complex diagrams or highly specific styling are limited compared to dedicated GUI tools.</li> <li>Bad, because team members will need to learn the Mermaid syntax, which may present an initial learning curve.</li> <li>Neutral, because the rendering of complex diagrams might sometimes require careful structuring of the Mermaid code.</li> </ul>"},{"location":"decisions/meta-decisions/use-mermaid-for-documenting-diagrams/#confirmation","title":"Confirmation","text":"<p>Compliance will be confirmed by:</p> <ul> <li>Reviewing new and updated ADRs to ensure diagrams are created using Mermaid.</li> <li>Ensuring our MkDocs build successfully renders Mermaid diagrams.</li> <li>Periodically checking for consistency and clarity of diagrams in the documentation.</li> </ul>"},{"location":"decisions/meta-decisions/use-mermaid-for-documenting-diagrams/#pros-and-cons-of-the-options","title":"Pros and Cons of the Options","text":""},{"location":"decisions/meta-decisions/use-mermaid-for-documenting-diagrams/#mermaid","title":"Mermaid","text":"<p>Mermaid is a Javascript-based diagramming and charting tool that renders Markdown-inspired text definitions to create and modify diagrams dynamically.</p> <ul> <li>Good, because it's text-based, enabling \"diagrams as code\" and straightforward version control.</li> <li>Good, because it integrates seamlessly with Markdown and is widely supported (e.g., GitHub, GitLab, MkDocs via plugins).</li> <li>Good, because it has a relatively simple and intuitive syntax for common diagram types.</li> <li>Good, because diagrams render directly in browsers or Markdown previews, often without needing separate tools for viewing.</li> <li>Good, because it encourages diagrams to be updated along with the documentation text.</li> <li>Bad, because it offers limited layout control and customization compared to GUI tools or PlantUML.</li> <li>Bad, because it may not support very complex or niche diagram types as comprehensively as other tools.</li> <li>Bad, because extremely complex diagrams can become difficult to write and maintain in text.</li> </ul>"},{"location":"decisions/meta-decisions/use-mermaid-for-documenting-diagrams/#plantuml","title":"PlantUML","text":"<p>PlantUML is an open-source tool that uses a simple textual description language to create UML diagrams and a variety of other software development-related diagrams.</p> <ul> <li>Good, because it's text-based (\"diagrams as code\"), excellent for version control.</li> <li>Good, because it supports a very wide range of UML diagrams and many other diagram types.</li> <li>Good, because it offers more powerful layout algorithms and styling options compared to Mermaid.</li> <li>Good, because it has a large, active community and extensive documentation.</li> <li>Bad, because its syntax can be more verbose and complex than Mermaid's, especially for simpler diagrams.</li> <li>Bad, because rendering often requires a local Java installation and generation step, or a dedicated server, although IDE integrations exist.</li> <li>Bad, because integration into Markdown-centric static site generators like MkDocs can be more involved (e.g., requiring specific plugins and potentially a Java runtime on the build server).</li> </ul>"},{"location":"decisions/meta-decisions/use-mermaid-for-documenting-diagrams/#drawio-diagramsnet","title":"draw.io (diagrams.net)","text":"<p>draw.io (now diagrams.net) is a free, open-source, web-based and desktop diagramming application.</p> <ul> <li>Good, because it's a powerful and flexible GUI-based diagramming tool with a drag-and-drop interface.</li> <li>Good, because it supports a vast array of diagram types, shapes, and customization options.</li> <li>Good, because it has a user-friendly interface, making it accessible for users who prefer visual tools.</li> <li>Good, because it can export to various formats (PNG, SVG, PDF, XML) and allows embedding diagrams in web pages.</li> <li>Bad, because diagrams are typically stored as binary files (e.g., <code>.drawio</code> which is XML but not easily human-readable for diffs, or image files like <code>.png</code>, <code>.svg</code>) which are difficult to diff and merge meaningfully in version control.</li> <li>Bad, because updating diagrams often involves a manual export/import cycle, making it less integrated with the \"docs as code\" workflow.</li> <li>Bad, because it can lead to inconsistencies in style and formatting across different diagrams and authors if not strictly managed with templates.</li> <li>Neutral, because while <code>.drawio</code> files are XML, their diffs are generally not helpful for understanding visual changes.</li> </ul>"},{"location":"decisions/meta-decisions/use-mermaid-for-documenting-diagrams/#example","title":"Example","text":"<p>See Material for MkDocs Diagram support</p> <p>Below is an example flowchart diagram embedded in this record:</p> <pre><code>graph LR\n  accTitle: Example flowchart diagram\n  accDescr {\n      A simple flowchart diagram with points A, B, C and D with a few \n      connections between them to demonstrate the use of Mermaid.\n  }\n  A[Start] --&gt; B{Error?};\n  B --&gt;|Yes| C[Hmm...];\n  C --&gt; D[Debug];\n  D --&gt; B;\n  B ----&gt;|No| E[Yay!];</code></pre>"},{"location":"decisions/meta-decisions/use-spell-checker-for-documents/","title":"Spell","text":"<p>Status: first sketch, work in progress, request for collaboration</p> <p>Date: Updated 2025-04-04</p> <p>Governance: Chris &amp; Joel for now because this is so lightweight.</p>"},{"location":"decisions/meta-decisions/use-spell-checker-for-documents/#context","title":"Context","text":"<p>We want to use a spell check program for our documentation, because it's helpful if there's an automatic spell check step that checks our work for common mistakes.</p>"},{"location":"decisions/meta-decisions/use-spell-checker-for-documents/#drivers","title":"Drivers","text":"<p>Broadly, we want use spell programs in many ways to improve quality.</p> <p>Specifically, we want to add a spell tool:</p> <ul> <li> <p>Right now.</p> </li> <li> <p>Installable locally so we're not sending data elsewhere.</p> </li> <li> <p>For VS Code because we both use it</p> </li> <li> <p>With a good rating in the VS Code marketplace.</p> </li> <li> <p>Focusing on our immediate need for writing markdown.</p> </li> <li> <p>With a configuration file that we can check into this git repository.</p> </li> </ul>"},{"location":"decisions/meta-decisions/use-spell-checker-for-documents/#assessment","title":"Assessment","text":""},{"location":"decisions/meta-decisions/use-spell-checker-for-documents/#cspell","title":"cspell","text":"<p>https://cspell.org/</p> <p>The CSpell mono-repo, a spell checker for code.</p> <p>This also offers a cspell command-line application, and related tools.</p> <p>It's fast and configurable, and the configuration file can be checked into a git repository, such as as a file <code>cspell.json</code>, so it's usable by all the people who use the repo with VS Code or any other editor that uses the same file.</p> <p>It can use custom dictionaries.</p>"},{"location":"decisions/meta-decisions/use-spell-checker-for-documents/#spelling-checker-for-visual-studio-code","title":"Spelling Checker for Visual Studio Code","text":"<p>https://marketplace.visualstudio.com/items?itemName=streetsidesoftware.code-spell-checker</p> <p>A basic spell checker that works well with code and documents.</p> <p>The goal of this spell checker is to help catch common spelling errors while keeping the number of false positives low.</p> <p>This tool leverages cspell as above.</p>"},{"location":"decisions/meta-decisions/use-spell-checker-for-documents/#recommendation-decision-outcome","title":"Recommendation - Decision Outcome","text":"<p>Adopt cspell for right now.</p> <p>Commit the file <code>cspell.json</code> to the top level of this repo.</p> <p>Revisit if/when a teammate is ready to research if there's something better.</p>"},{"location":"decisions/process-decisions/git-organizations/","title":"Git organizations","text":"<p>Status: first sketch, work in progress, request for collaboration</p> <p>Date: Updated 2025-04-04</p> <p>Governance: To Be Discovered; potentially a combo of this repo partipants, DHCW CISO, NHS Wales UCB peers, etc.</p>"},{"location":"decisions/process-decisions/git-organizations/#situation-context-and-problem-statement","title":"Situation - Context and Problem Statement","text":"<p>Generally we aim to encourage principles of public health, public health code, public health data, public health participation, and public health involvement.</p> <p>Specifically Joel needs to immediately work on the emergency department module authentication demonstration, which involves external Microsoft Entra free accounts, all fake data for testing purposes, and open for partners and advisors especially Microsoft, Kainos, Capacitas, NCSC. The immediate next project is radiology test automation with rapid setup of fake data such as via external FHIR services.</p> <p>Joel is delivering these via a public health free open source git organization. This is a new capability for NHS Wales and for DHCW, based on best practices for U.S. healthcare companies that have a bright-line divider between their external-public-free-open-source and their internal-private-expensed-closed-source.</p> <p>Dan wants to use the learnings that come from these, in order to improve the internal systems.</p>"},{"location":"decisions/process-decisions/git-organizations/#background-decision-drivers","title":"Background - Decision Drivers","text":"<p>Joel's decision drivers are the typical best practices in the U.S. and E.U. which is to create a bright-line information security separation between two categories of work:</p> <ol> <li> <p>Category one is for the public. This includes things like demonstrations, examples, tutorials, free open source software, fake testing information, data that is free and clear of any personally identifying information, etc.</p> </li> <li> <p>Category two is for employees. This includes things like internal-only applications, employment records, paid closed source software, personally identifiable information (PII), confidential documents, security secrets, and the like.</p> </li> </ol> <p>This is the approach taken by organizations such as Apple, Microsoft, Google, etc. and it improves security with U.S. SOC 2 compliance, the EU Cybersecurity Act, the  International Standards Organization (ISO) 27001 information security framework, etc.</p> <p>Dan's decision drivers are TODO @Dan.</p>"},{"location":"decisions/process-decisions/git-organizations/#decision-driver-questions","title":"Decision Driver Questions","text":"<p>One of the areas we're exploring as a group on our chat is coming up with questions that can help us assess options.</p> <p>Here are  some questions that we're considering thus far.</p> <p>TODO @Joel add questions here.</p> <p>TODO @Dan add questions here.</p>"},{"location":"decisions/process-decisions/git-organizations/#assessment-considered-options","title":"Assessment - Considered Options","text":"<p>Option 1: Our current path.</p> <ul> <li> <p>Joel and DevOps continue to use the category one GitHub repo.</p> </li> <li> <p>Dan and NDR continue to use the category 2 GitHub repo, plus do anything they want to improve the internal systems.</p> </li> <li> <p>We update each other about learnings as we go.</p> </li> <li> <p>We revisit together later on, such as after the emergency department module ships and the radiology testing ships.</p> </li> </ul> <p>Option 2: TODO @Dan.</p>"},{"location":"decisions/process-decisions/git-organizations/#recommendation-decision-outcome","title":"Recommendation - Decision Outcome","text":"<p>TODO</p>"},{"location":"decisions/process-decisions/hosting-data-in-the-united-states-or-the-united-kingdom/","title":"Hosting data in the United States or the United Kingdom","text":"<p>Note</p> <p>Work in Progress</p> <p>Status: first sketch, work in progress, request for collaboration</p> <p>Date: Updated 2025-04-08</p> <p>Governance: To Be Discovered; potentially a combo of this repo participants, DHCW CISO, NHS Wales UCB peers, etc.</p>"},{"location":"decisions/process-decisions/hosting-data-in-the-united-states-or-the-united-kingdom/#context","title":"Context","text":"<p>Our organisation stakeholders are asking questions about hosting data in the United States versus the United Kingdom.</p> <p>The decision will have significant implications for data security, compliance with legal and regulatory requirements, performance (e.g., latency), cost, risk, piloting, and more.</p> <p>We want to learn more about how to make a well-informed choice between hosting the data in one of these countries, considering the current needs and potential future growth.</p> <p>We also want to learn more about hosting in both regions, such as using a multi-cloud approach.</p> <ul> <li>We believe there are tradeoffs compliance and operational efficiency.</li> </ul> <p>We also want to learn more about hosting in the EU region, such as using a European hosting company.</p> <ul> <li> <p>There may be benefits of EU scale/cost/capabilities over the UK. For example, Germany may offer larger-scale, better-cost, faster-deployment, etc. than the UK.</p> </li> <li> <p>There may be EU law/harmonization/openness as compared to the US. For example, the EU has better legal harmony with the UK relating to GDPR, ISO 27001, etc.</p> </li> </ul>"},{"location":"decisions/process-decisions/hosting-data-in-the-united-states-or-the-united-kingdom/#drivers","title":"Drivers","text":"<p>We intend to research this area more in depth.</p> <p>Data Sovereignty and Compliance:</p> <ul> <li> <p>U.K.: Hosting in the U.K. offers compliance with the General Data Protection Regulation (GDPR), ensuring data privacy and protection. As the U.K. is no longer part of the EU, there are unique data protection regulations, but they are still aligned with GDPR principles.</p> </li> <li> <p>U.S.: The U.S. follows a more fragmented approach to data privacy and protection regulations, with different states having their own laws (e.g., CCPA in California). U.S. regulations may be less stringent than those in the E.U. and U.K., particularly in areas like consumer rights over data.</p> </li> </ul> <p>International Data Transfers:</p> <ul> <li> <p>U.K.: The U.K. provides more certainty for international data transfers, as it follows a similar framework to the EU's GDPR for cross-border data flow. There is also the UK-EU adequacy decision, which means data can be transferred between the U.K. and the EU without needing additional safeguards.</p> </li> <li> <p>U.S.: Data transfers from the EU/UK to the U.S. are subject to stricter scrutiny, and compliance with frameworks like the EU-U.S. Data Privacy Shield (though invalidated in 2020) or Standard Contractual Clauses (SCCs) is required for lawful data transfer. The U.S. may require more legal efforts and complex agreements around data transfer.</p> </li> </ul> <p>Latency and Performance:</p> <ul> <li> <p>U.K.: Hosting in the U.K. is ideal if the user base is primarily located in Europe or other parts of the world that have low-latency access to the U.K. data centers. This can result in better response times for users in these regions.</p> </li> <li> <p>U.S.: If the majority of the user base is based in North America, hosting in the U.S. might offer lower latency and better performance for those users.</p> </li> </ul> <p>Cost:</p> <ul> <li> <p>U.K.: Hosting in the U.K. may be more expensive due to higher energy costs, data center hosting fees, and regional operational expenses. However, this could be offset by the benefits of regulatory compliance.</p> </li> <li> <p>U.S.: The U.S. is often considered a more affordable location for data hosting due to lower operational costs in many regions (e.g., server hosting, energy, etc.). Certain providers may offer cost-effective hosting options, especially for large-scale operations.</p> </li> </ul> <p>Legal and Political Environment:</p> <ul> <li> <p>U.K.: The U.K. offers a stable political environment, though post-Brexit regulations and trade agreements may introduce some uncertainty around data sovereignty.</p> </li> <li> <p>U.S.: The U.S. has a well-established legal framework for technology and data, but its approach to data privacy and government surveillance (e.g., FISA and Patriot Act) may raise concerns, particularly in Europe or with users who prioritize data privacy.</p> </li> </ul> <p>Future Considerations:</p> <ul> <li> <p>U.K.: As a key player in the global economy, the U.K. will likely remain a strong choice for hosting for years to come, especially given its alignment with GDPR-like regulations.</p> </li> <li> <p>U.S.: Depending on future political shifts and regulatory changes, hosting in the U.S. might face stricter scrutiny and regulatory changes, particularly for businesses with international customers.</p> </li> </ul>"},{"location":"decisions/process-decisions/hosting-data-in-the-united-states-or-the-united-kingdom/#recommendation-decision-outcome","title":"Recommendation - Decision Outcome","text":"<p>TODO</p>"},{"location":"decisions/process-decisions/hosting-data-in-the-united-states-or-the-united-kingdom/#consequences","title":"Consequences","text":"<p>We intend to research this area more in depth.</p> <p>U.K.:</p> <ul> <li> <p>Easier to comply with GDPR-like regulations and to transfer data across EU borders.</p> </li> <li> <p>Potentially higher costs due to the region\u2019s operational overhead.</p> </li> <li> <p>Low latency for European users.</p> </li> </ul> <p>U.S.:</p> <ul> <li> <p>Potentially cheaper but may require more complex regulatory agreements for international data transfer.</p> </li> <li> <p>Increased latency for European users.</p> </li> <li> <p>More fragmented privacy laws and potential surveillance concerns.</p> </li> </ul>"},{"location":"decisions/process-decisions/knowledge/","title":"Knowledge","text":"<p>Note</p> <p>Work in Progress</p> <p>Status: first sketch, work in progress, request for collaboration</p> <p>Date: 2025-03-21</p> <p>Governance: To Be Discovered; potentially a combo of this repo participants, DHCW CISO, NHS Wales UCB peers, etc.</p>"},{"location":"decisions/process-decisions/knowledge/#context","title":"Context","text":"<p>Broadly, our organization aims to improve our knowledge building and knowledge sharing. For example, we have major multi-year work fronts to create our medical software with domain knowledge, to improve software engineering with programming knowledge, to widen our data research needs with statistical knowledge, and to innovate our AI adoption with machine learning knowledge. Knowledge work can be improved by better ways of working and by software for knowledge management systems (KMS).</p> <p>Specifically, right now for the emergency department module, Joel is discovering that knowledge within the organization tends to be tribal and trapped in internal systems. In the past week, Joel and teammates have had total knowledge misses, meaning our people know the work exists but can't find it or can't share it. This causes delays, confusions, frustrations, and unnecessary redos. Joel and the software engineers need ways to find documentation and share it with each other.</p>"},{"location":"decisions/process-decisions/knowledge/#drivers","title":"Drivers","text":"<p>We want to immediately increase our capabilities to create knowledge, find it, share it, and update it. We want to do this immediately for knowledge for the emergency department module and it's related software engineering work.</p> <p>A couple of pieces where Joel believes better knowledge management is urgent for this specific project:</p> <ol> <li> <p>Authentication such as for our use cases, which also will lead into authentication for more of our software engineering projects.</p> </li> <li> <p>Reification, which means we \"make real\" the various high-level knowledge that we have in hand, so we can ship real code faster, then iterate on the knowledge and the code.</p> </li> </ol> <p>A couple of ways of working that we believe are lightweight and can help right now:</p> <ol> <li> <p>Shifting what we can from private-first to public-first. For example, shifting from intranet knowledge to more extranet knowledge. Newer ways of working include us working in the open on ADRs such as this one, as well as our new public GitHub organization, and our relationships with peer organizations including NHS England, GOV.UK, UK NCSC, etc.</p> </li> <li> <p>Shifting what we can from must-be-perfect to could-be-good-enough. For example, shifting documentation from a many-day many-tier many-person approval process of a final finished gorgeous PowerPower to a few-hour few-person approval process of a first draft of a markdown text file.</p> </li> </ol> <p>A couple of knowledge management systems that we believe are lightweight and can help right now:</p> <ol> <li> <p>Something TBD for upskilling our team. We have multiple inbound requests from staff about how to learn GitHub to work on ADRs, how to use AI code assistants to speed up boilerplate programming, how to share work-in-progress documentation URLs with our peer organizations, etc.</p> </li> <li> <p>Something TBD for tagging and searching for knowledge. We have need obvious tags such as for software engineering topics (e.g. #authentication, #authorization), software tools (e.g. #git, #copilot), software languages (e.g. #javascript, #python).</p> </li> </ol> <p>Business drivers:</p> <ol> <li>The organization needs a way to ensure knowledge is not only captured but also shared effectively among all employees. Knowledge sharing is essential for innovation, problem-solving, and continuous learning across departments.</li> </ol>"},{"location":"decisions/process-decisions/knowledge/#options","title":"Options","text":"<p>Knowledge is a massive topic, so we want to quickly sketch some options for us to consider.</p>"},{"location":"decisions/process-decisions/knowledge/#formal-synchronous-knowledge-sharing","title":"Formal synchronous knowledge-sharing","text":"<p>Examples: webinars, workshops, upskilling sessions, training programs.</p> <p>Resources: typically these work best when there is dedicated time, equipment, rooms, and people.</p> <p>Example pros: High-quality, structured content; clear focus on knowledge dissemination.</p> <p>Example cons: Time-consuming; could be difficult to maintain long-term.</p>"},{"location":"decisions/process-decisions/knowledge/#informal-asynchronous-knowledge-sharing","title":"Informal asynchronous knowledge-sharing","text":"<p>Examples: collaboration tools and communication platforms, such as wikis, blogs, chats, virtual whiteboards, kanban boards, etc.</p> <p>Resources: typically these work best when there is organizational IT capability for setup, ongoing tuning, and scaling.</p> <p>Example pros: Easier to scale; integrates well with daily work; encourages spontaneous knowledge sharing.</p> <p>Example cons: Lack of structure may lead to fragmented knowledge sharing; less formalized tracking.</p>"},{"location":"decisions/process-decisions/knowledge/#hybrid-formalinformal-knowledge-sharing","title":"Hybrid formal/informal knowledge-sharing","text":"<p>Examples: a quarterly presentation about a topic that aligns with an ongoing chat channel where people can ask questions, share links, etc.</p> <p>Resources: as above.</p> <p>Example pros: Combines the best of both worlds; structured programs for high-priority topics, while also allowing organic knowledge sharing.</p> <p>Example cons: More complex to implement; people might miss out on knowledge in one of the presentations or one of the channels, without realizing it.</p>"},{"location":"decisions/process-decisions/knowledge/#system-quality-attributes-to-consider","title":"System quality attributes to consider","text":"<p>Usability: Team members need to be able to easily contribute, edit, and interact with the knowledge base.</p> <p>Flexibility: The solution must accommodate both structured and informal ways of sharing knowledge.</p> <p>Searchability: The ability to search through documents and retrieve relevant information quickly is essential.</p> <p>Scalability: The system must be able to handle increasing amounts of data as the organization grows.</p> <p>Security: Sensitive information must be stored securely, with access control in place.</p> <p>Integrability: The system should integrate well with other internal tools (e.g., document management systems, chat apps, etc.).</p>"},{"location":"decisions/process-decisions/knowledge/#consequences","title":"Consequences","text":"<p>Examples that we want to know more about...</p> <p>Positive:</p> <ul> <li> <p>Employees will have multiple avenues to share knowledge, which increases engagement.</p> </li> <li> <p>Combining formal and informal approaches allows for scalability while maintaining quality.</p> </li> <li> <p>By using communication platforms like Slack, employees can seamlessly share knowledge in real-time, fostering continuous learning.</p> </li> </ul> <p>Negative:</p> <ul> <li> <p>Maintaining engagement could become challenging if the initiative is not properly supported by leadership.</p> </li> <li> <p>Lack of structure in informal sharing may result in valuable knowledge being lost or overlooked.</p> </li> </ul>"},{"location":"decisions/process-decisions/knowledge/#recommendations","title":"Recommendations","text":"<p>Start right now with lightweight ways of working and lightweight documentation tooling.</p> <p>Use these as landing zones:</p> <ol> <li> <p>Create our new external GitHub organization, with new public repositories, where we add new documentation, code, tests, etc. Share it among staff, and peer organizations, and the general public.</p> </li> <li> <p>Favor simple open formats and simple open standards for good-enough knowledge discussion, such as favoring text files over PowerPoint, ADRs over SADs, ad-hoc tagging with \"#tag\" syntax over formal rigid hierarchical ontologies.</p> </li> <li> <p>Leverage free open source software for searching and indexing our external knowledge work. We're starting with mkdocs and iterating to add mkdocs-awesome-nav.</p> </li> </ol>"},{"location":"decisions/process-decisions/ways-of-working/","title":"Ways Of Working (WOW)","text":"<p>Note</p> <p>Work in Progress</p> <p>Status: first sketch, work in progress, request for collaboration</p> <p>Date: 2025-03-21</p> <p>Governance: To Be Discovered; potentially a combo of this repo partipants, DHCW CISO, NHS Wales UCB peers, etc.</p>"},{"location":"decisions/process-decisions/ways-of-working/#situation-context-and-problem-statement","title":"Situation - Context and Problem Statement","text":"<ul> <li> <p>We want to encourage high-trust high-speed participation in our org and our repos, and help shape what good participation can look like, rather than just a blank slate.</p> </li> <li> <p>Broadly this is known as our \"ways of working\", and some people and companies may also know this as a mix of principles, values, whys, tenets, ground rules, aspirations, norms, working agreements, culture, etc.</p> </li> </ul>"},{"location":"decisions/process-decisions/ways-of-working/#background-decision-drivers","title":"Background - Decision Drivers","text":"<ul> <li> <p>We want to get good-enough quality work in place now, so we can try it out, ask for feedback, get help with it with Capacitas consultants who have two more weeks with us, etc.</p> </li> <li> <p>We want to align with industry standards (not reinvent the wheel).</p> </li> </ul>"},{"location":"decisions/process-decisions/ways-of-working/#assessment-considered-options","title":"Assessment - Considered Options","text":"<p>For immediate ship, we want to align with what we know works well broadly (which Joel has) and what works well for NHS (which NHS England has):</p> <ul> <li> <p>Ways of Working \u2013 Joel's many-year multi-client aggregation.</p> </li> <li> <p>NHS England GitHub ways of working</p> </li> </ul> <p>To expand this ADR during the work-in-progress, here are a bunch of additional options, and we could/should add more as we discover them:</p> <ul> <li> <p>Team Norms, Working Agreements, and Simple Rules by Esther Derby</p> </li> <li> <p>Working Agreements by Jane Haskell</p> </li> <li> <p>Adult Principles by John Perry Barlow</p> </li> <li> <p>Principles by Nabeel S. Qureshi</p> </li> <li> <p>Ground rules at Tesla by Elon Musk</p> </li> <li> <p>Ground Rules by Tree Bressen</p> </li> <li> <p>Ground rules for effective meetings by Get The Picture</p> </li> <li> <p>High-velocity decision making by Amazon</p> </li> <li> <p>How to send progress updates by Slava Akhmechet</p> </li> <li> <p>How we structure our work and teams at Basecamp</p> </li> <li> <p>Leadership Principles by United States Marine Corps</p> </li> <li> <p>Project management practices by Hacker News participants</p> </li> <li> <p>Rules of the Road by Jerry Perenchio</p> </li> <li> <p>Scaled Agile Framework (SAFe)</p> </li> <li> <p>Software Engineering at Google</p> </li> <li> <p>Software working advice by Cyranix</p> </li> <li> <p>Team working agreements example by giffconstable</p> </li> <li> <p>The Core Protocols by McCarthy</p> </li> <li> <p>The Five Keys to a Successful Google Team</p> </li> <li> <p>The unwritten laws of engineering at Stedi</p> </li> <li> <p>Engineering management checklist by Patrick Newman</p> </li> <li> <p>Strategies to improve workplace communication - By Calm Business</p> </li> <li> <p>Onboarding and induction checklist - By employmenthero</p> </li> <li> <p>Our Values - What it Means to Work at ZOE</p> </li> <li> <p>101 Additional Advices by Kevin Kelly</p> </li> </ul>"},{"location":"decisions/process-decisions/ways-of-working/#recommendation-decision-outcome","title":"Recommendation - Decision Outcome","text":"<p>Adopt a ways-of-working repository, taking elements of the NHS England existing work, Joel's existing work, and any feedback as we go.</p> <ul> <li> <p>We start now, and iterate as we learn-- this is likely to be especially true for small tuning thanks to CISO participation for the emergency department authentication project ASAP.</p> </li> <li> <p>We understand that NHS England is significantly ahead of NHS Wales with this kind of work, so we have catch up to do, and some of the wording may need simplification or more explanation.</p> </li> <li> <p>We anticipate that no one will actually care much about this for a while, because it's just docs and checklists; the goal is to get a few points on the scoreboard, not boil the oceans.</p> </li> </ul>"},{"location":"decisions/technical-decisions/cloud-hosting-for-documents-capabilities/","title":"Cloud Hosting for Documents Capability","text":"<p>Status: Request for collaboration, decision Date: 2025-18-07 Governance: Collaboration to be confirmed, TDA, TDAG?</p>"},{"location":"decisions/technical-decisions/cloud-hosting-for-documents-capabilities/#situation-context-and-problem-statement","title":"Situation: Context and Problem Statement","text":"<p>As part of the National Target Architecture (NTA) there is a business capability requirement for documents. However, there is currently a strategic misalignment regarding the choice of cloud platform for hosting documents. Two major programmes are influencing the direction:</p> <ul> <li>Azure: Backed by the Cloud Migration Programme, with a focus on core infrastructure, identity management, and operational services.</li> <li>Google Cloud Platform (GCP): Aligned with the Data Strategy, prioritising advanced analytics, machine learning, and integration with BigQuery.</li> </ul> <p>A key architectural consideration is determining which cloud platform will host the operational microservices responsible for realising document-related business capabilities, in a way that balances both strategic alignment and technical suitability.</p> <p>This indecision is introducing significant delivery risks:</p> <ul> <li>Duplication of effort: Separate DevOps pipelines, monitoring systems, and access control frameworks.</li> <li>Resource contention: Teams are being pulled in multiple directions, reducing focus and efficiency.</li> <li>Increased training overhead: Staff must become proficient in multiple cloud platforms.</li> <li>Lack of strategic clarity: Delays delivery, creates uncertainty, and hampers long-term planning.</li> </ul> <p>This decision is critical, as it directly impacts funding, resource allocation, team coordination, and delivery timelines. Proceeding without a clear direction may result in duplication and rework\u2014for example, initial implementation in Azure followed by migration to GCP\u2014leading to delays, increased cost, and retraining requirements.</p>"},{"location":"decisions/technical-decisions/cloud-hosting-for-documents-capabilities/#background-decision-drivers","title":"Background: Decision Drivers","text":"<p>The Clinical Document Service aims to empower both citizens and health and care professionals through a secure, scalable, and accessible platform for storing and sharing clinical documents. It will be built on open standards, ensuring long-term sustainability and supporting informed clinical decision-making across organisational boundaries.</p> <p>Designed for use by clinicians and citizens across Wales, the service will:</p> <ul> <li>Align with DHCW\u2019s architecture principles and strategic direction.</li> <li>Align National Target Architecture (NTA) business capabilities to under lying technical architecture.</li> <li>Unify the user experience across diverse healthcare settings.</li> <li>Adopt a cloud-first approach, enabling a more scalable, flexible, and modular solution to meet future demands.</li> <li>Reduce complexity and improve delivery times.</li> <li>Enhance data quality through the use of industry standards and open architecture.</li> <li>Strengthen security and access controls.</li> <li>Provide a consistent, intuitive experience for end users.</li> </ul> <p>To realise this vision, the service must be underpinned by a fit-for-purpose cloud hosting platform that meets its evolving technical and operational requirements. This will ensure:</p> <ul> <li>Clinical Document Service is positioned to meet its long-term goals, avoiding delays, duplicated effort, and architectural missteps.</li> <li>Cloud storage of clinical document binaries, accessible for operational use and analytics (e.g., NDAP).</li> <li>Microservice hosting, leveraging containerisation and orchestration for scalable, portable, re-useable and resilient service delivery.</li> <li>Core security services, including malware scanning, access auditing, and alignment with national standards.</li> <li>API management (e.g., Apigee), to support secure authentication, access control, logging, and monitoring.</li> <li>Unify business-as-usual (BAU) operations through the consistent use of technologies such as SOLR, streamlining search, indexing, and retrieval.</li> </ul> <p>A clear and unified decision on the cloud platform is urgently needed to allow the delivery team to proceed with confidence, establish a stable foundation, and ensure alignment with future scaling and strategic direction. Ensuring the Clinical Document Service is positioned to meet its long-term goals, avoiding delays, duplicated effort, and architectural missteps.</p>"},{"location":"decisions/technical-decisions/cloud-hosting-for-documents-capabilities/#assessment-considered-options","title":"Assessment: Considered Options","text":"<p>Two platforms were evaluated, each aligned to distinct strategic objectives:</p> <ul> <li>Azure: Favoured by the Cloud Migration Programme for infrastructure, identity, and operational alignment.</li> <li>Google Cloud Platform (GCP): Favoured by the Data Strategy for data-driven capabilities, including integration with analytics pipelines and BigQuery.</li> </ul> <p>For microservice infrastructure, the decision is not straightforward. While technical alignment and strategic direction remain important, the ultimate choice will likely be driven by financial considerations\u2014such as total cost of ownership, licensing models, and long-term sustainability.</p>"},{"location":"decisions/technical-decisions/cloud-hosting-for-documents-capabilities/#recommendation-decision-outcome","title":"Recommendation: Decision Outcome","text":"<p>Following a cross-functional meeting on 18/07/2025 with representation from NDR, Operations, and Architecture, the following decision was agreed:</p> <ul> <li>Document Binary Storage will be hosted in GCP, as this aligns with the Data Strategy and supports seamless integration with National Data and Analytics Platforms (BigQuery, machine learning and vertex AI).</li> <li>Clinical Data will be stored in the CDR</li> <li>Indexed data will continue to be stored in our current SOLR-based indexing solution. While SOLR is being maintained for business continuity, it is considered a transitional platform pending full migration to the strategic solution.</li> <li>Microservices supporting operational workflows and aligning with NTA business capabilities can be hosted on the most suitable platform from an infrastructure, resourcing, and deployment perspective\u2014platform-neutral at this stage. This decision can be placed on lowest cost option.</li> <li>Google Apigee will provide the proxy layer and access mechanisms for users of the microservices.</li> </ul> <p>This hybrid approach balances strategic alignment, delivery pragmatism, and long-term scalability.</p>"},{"location":"decisions/technical-decisions/containerization/","title":"Containerization","text":"<p>Note</p> <p>Work in Progress</p> <p>Status: first sketch, work in progress, request for collaboration</p> <p>Date: 2025-04-17</p> <p>Governance: To Be Discovered; potentially a combo of this repo participants, DHCW CISO, NHS Wales UCB peers, etc.</p>"},{"location":"decisions/technical-decisions/containerization/#situation-context-and-problem-statement","title":"Situation - Context and Problem Statement","text":"<p>To support our software engineering teams with reliable, portable, and secure environments for application development, testing, and deployment, we need a consistent approach to containerization, container management, and container deployment.</p> <p>Right now we need:</p> <ul> <li> <p>Capabilities for software engineers to develop software locally in a container.</p> </li> <li> <p>Capabilities for software engineers to download and run software in containers.</p> </li> </ul> <p>Broadly we want to aim for:</p> <ul> <li> <p>Support for infrastructure-as-code and CI/CD pipelines.</p> </li> <li> <p>Demand for rootless and secure containers (developer-friendly, production-safe).</p> </li> <li> <p>Consideration for direct vs. orchestrated container management.</p> </li> <li> <p>Growing interest in serverless runtimes and integration with ephemeral compute.</p> </li> </ul> <p>We must decide on:</p> <ul> <li> <p>Container engine(s) to use (such as Docker, Podman, etc.)</p> </li> <li> <p>How we build, run, and manage containers (locally, in CI/CD/CT, in demos, in production, etc).</p> </li> <li> <p>Deployment methods (manual, automated, orchestrated, serverless, etc).</p> </li> </ul>"},{"location":"decisions/technical-decisions/containerization/#drivers","title":"Drivers","text":"<ul> <li> <p>Compatibility: Must work well with Git/GitHub, Tofu/Terraform, CI/CD/CT pipelines.</p> </li> <li> <p>Portability: Support across developer machines and CI environments.</p> </li> <li> <p>Flexibility: Support serverless where appropriate.</p> </li> <li> <p>Security: Rootless containers reduce the attack surface.</p> </li> <li> <p>Simplicity: Avoid Kubernetes unless orchestration is absolutely required.</p> </li> </ul>"},{"location":"decisions/technical-decisions/containerization/#considered-options-and-related-tooling","title":"Considered options and related tooling","text":"<ul> <li> <p>Container implementations: Docker, Podman, any others?</p> </li> <li> <p>Serverless e.g. closed-source platform-specific such as AWS Fargate Serverless Compute, open-source platform-agnostic such as Knative, any others?</p> </li> <li> <p>Direct management (e.g., via systemd or scripts)</p> </li> <li> <p>Orchestration tools: Kubernetes, any others?</p> </li> </ul>"},{"location":"decisions/technical-decisions/containerization/#summaries-by-chatgpt","title":"Summaries by ChatGPT","text":"<p>Docker is an open-source platform that enables developers to build, package, and run applications in lightweight, portable containers. A container bundles an application with all its dependencies, libraries, and configuration files, ensuring it runs consistently across different environments\u2014from a developer\u2019s laptop to production servers. Docker simplifies software delivery by isolating applications from the underlying infrastructure, reducing conflicts and streamlining DevOps workflows. It includes tools for building container images, managing containers, and orchestrating multi-container applications, and it serves as a foundational technology for modern, microservices-based and cloud-native architectures.</p> <p>Podman is an open-source container management tool that allows users to build, run, and manage containers and pods without requiring a daemon, unlike Docker. Developed by Red Hat, Podman is designed with security and rootless operation in mind, enabling users to run containers as non-root users for better system isolation and compliance. It supports the same container image formats as Docker and offers a compatible command-line interface (<code>podman</code> can often replace <code>docker</code> commands). Podman also supports Kubernetes YAML generation and can manage pods natively, making it a strong choice for secure and standards-compliant container workflows.</p> <p>Kubernetes is an open-source container orchestration platform that automates the deployment, scaling, management, and networking of containerized applications. Originally developed by Google and now maintained by the Cloud Native Computing Foundation (CNCF), Kubernetes allows users to define the desired state of their applications and ensures that the system continuously works to maintain that state. It manages clusters of nodes (servers) and coordinates containers to run efficiently across them, handling load balancing, service discovery, rolling updates, and self-healing in case of failures. Kubernetes is a foundational technology for cloud-native infrastructure, enabling resilient, scalable, and portable application deployments across diverse environments.</p> <p>kubectl is the command-line tool used to interact with Kubernetes clusters, allowing users to deploy applications, inspect and manage cluster resources, and view logs or events. It communicates with the Kubernetes API server to execute commands such as creating pods, scaling deployments, updating configurations, and troubleshooting workloads. The kubectl command is essential for developers and administrators working with Kubernetes, providing a powerful and flexible interface for managing the full lifecycle of containerized applications.</p> <p>Buildah is an open-source command-line tool designed to create and manage container images without requiring a Docker daemon. It enables developers to build container images in a flexible and lightweight manner, either by using a Dockerfile or through direct commands to add files and configure image layers. Buildah is particularly useful in environments where running a full Docker daemon is unnecessary, such as in CI/CD pipelines or Kubernetes setups. It integrates well with other container tools like Podman and can push images to container registries, offering a more efficient and customizable alternative for building and managing container images.</p> <p>Conmon** (short for \"container monitor\") is an open-source tool designed to monitor and manage container processes in a lightweight and efficient manner. It is typically used in conjunction with container runtimes like Podman and Kubernetes to handle the monitoring of container lifecycles, including logging, handling the standard input/output streams, and managing the container\u2019s exit status. Conmon runs as a subprocess alongside the container, ensuring that the container\u2019s logs and process status are properly captured and reported. It provides a minimal, low-overhead solution for container monitoring, focusing on keeping the container's environment clean and efficient without introducing unnecessary complexity.</p> <p>Trivy is an open-source vulnerability and security scanner developed by Aqua Security, designed to detect issues in container images, file systems, and source code repositories. It scans for a wide range of security problems, including OS package vulnerabilities (e.g., in Alpine, Debian, Ubuntu), language-specific package issues (e.g., pip, npm, bundler), misconfigurations in Kubernetes and Docker, exposed secrets, and software licenses. Trivy is lightweight, easy to use, and integrates well into CI/CD pipelines, making it a popular tool for DevSecOps workflows to ensure containers and infrastructure are secure before deployment.</p> <p>Copacetic is an open-source command-line tool developed by Microsoft and hosted under the CNCF Sandbox. It enables DevSecOps teams to patch container image vulnerabilities directly, without the need to rebuild the entire image. By integrating with popular vulnerability scanners like Trivy, Copacetic identifies outdated or vulnerable packages and applies updates as additional layers on top of the existing image. This tool is particularly beneficial for patching inherited base image vulnerabilities or third-party application images without waiting for upstream updates.</p> <p>Harbor is an open-source cloud-native registry project that stores, signs, and scans container images for vulnerabilities, with a focus on security, compliance, and performance in enterprise environments. Developed by VMware and now part of the CNCF (Cloud Native Computing Foundation), Harbor extends Docker Registry with features like role-based access control, image replication across registries, and integration with vulnerability scanners such as Trivy for continuous scanning. It automates security checks on container images as they're pushed or pulled, enabling organizations to enforce policies and maintain a secure software supply chain throughout the development lifecycle.</p> <p>Kind (Kubernetes in Docker) is an open-source tool for running local Kubernetes clusters using Docker container \"nodes.\" Designed primarily for testing and development, Kind allows users to spin up lightweight Kubernetes clusters without needing virtual machines or external cloud infrastructure. It runs each Kubernetes node inside a Docker container, making it ideal for CI/CD pipelines, prototyping, and learning Kubernetes in a controlled, resource-efficient environment. Kind supports multi-node clusters and integrates well with standard Kubernetes tooling like <code>kubectl</code>.</p> <p>Crossplane is an open-source, multi-cloud control plane that enables the management of cloud infrastructure and services using Kubernetes-style declarative APIs. It extends Kubernetes to allow users to provision and manage resources across multiple cloud providers (like AWS, Azure, Google Cloud) and on-prem environments from a single control plane. Crossplane enables infrastructure as code (IaC) by defining resources using Kubernetes manifests, allowing developers to manage everything from databases to networking resources and virtual machines. This unified approach simplifies complex infrastructure management, promotes consistency across cloud environments, and supports a more flexible, scalable architecture for modern cloud-native applications.</p> <p>Rancher is an open-source container management platform that simplifies deploying, managing, and scaling Kubernetes clusters across on-premises, cloud, and hybrid environments. Developed by SUSE, Rancher provides a centralized user interface and API for administering multiple Kubernetes clusters, regardless of where they're running. It offers tools for lifecycle management, access control, monitoring, security policy enforcement, and integrated application catalogs. Rancher streamlines DevOps workflows by abstracting much of the complexity of Kubernetes, making it easier for teams to operate and govern containerized applications at scale.</p> <p>Helm is an open-source package manager for Kubernetes that helps developers and operators define, install, and manage complex Kubernetes applications using reusable, version-controlled templates called charts. A Helm chart bundles all the necessary Kubernetes manifests\u2014like deployments, services, and config maps\u2014into a single package, making it easy to deploy applications consistently across environments. Helm simplifies application lifecycle management by enabling upgrades, rollbacks, and configuration overrides through values files. As a CNCF project, Helm is widely used to streamline Kubernetes operations, reduce manual configuration, and promote best practices in infrastructure as code.</p> <p>Knative is an open-source platform built on Kubernetes that enables the development, deployment, and management of serverless applications. It provides a set of components that abstract away the complexity of managing serverless workloads, allowing developers to focus on writing code without worrying about the underlying infrastructure. Knative includes features like automatic scaling (including scaling to zero), event-driven architecture, and support for both stateless and stateful workloads. It integrates seamlessly with Kubernetes and tools like Istio, offering capabilities for routing, traffic splitting, and service management. Knative is ideal for building modern, cloud-native applications that need to scale dynamically based on demand while leveraging Kubernetes for orchestration.</p> <p>Amazon Web Services (AWS) Fargate is a serverless compute engine for containers that allows users to run containerized applications without having to manage the underlying server infrastructure. Integrated with Amazon ECS (Elastic Container Service) and Amazon EKS (Elastic Kubernetes Service), Fargate automatically provisions, scales, and manages compute resources needed to run containers, so developers can focus on building and deploying applications. With Fargate, there\u2019s no need to choose instance types or manage cluster capacity\u2014users simply define their container requirements, and AWS handles the rest, offering a pay-as-you-go model that improves scalability, security, and operational efficiency.</p> <p>Amazon Web Services (AWS) Elastic Container Service (ECS) is a fully managed container orchestration service provided by AWS, designed to simplify the deployment, management, and scaling of containerized applications. It allows users to run and manage Docker containers across a cluster of virtual machines, using tasks and services to automate container deployment, scaling, and networking. ECS integrates seamlessly with other AWS services like Elastic Load Balancing, IAM, and CloudWatch, providing a secure and scalable platform for containerized applications. ECS offers two launch types: EC2 (for running containers on EC2 instances) and Fargate (for serverless container management), giving users flexibility in how they manage their container infrastructure.</p> <p>Amazon Web Services (AWS) Elastic Kubernetes Service (Amazon EKS) is a managed service provided by AWS that simplifies the deployment, management, and scaling of containerized applications using Kubernetes. EKS automatically handles tasks like cluster provisioning, patching, and scaling, allowing developers to focus on building and deploying applications rather than managing infrastructure. It integrates seamlessly with other AWS services such as Elastic Load Balancing, IAM, and Amazon VPC, providing security, networking, and monitoring capabilities. EKS supports both AWS infrastructure and on-premises environments, making it ideal for running scalable, resilient containerized applications in a secure and managed Kubernetes environment.</p> <p>Google Kubernetes Engine (GKE) is a fully managed Kubernetes service provided by Google Cloud, designed to simplify the deployment, management, and scaling of containerized applications using Kubernetes. GKE handles the complexities of Kubernetes, such as managing the control plane, upgrades, and scaling, while giving users full control over the worker nodes and container workloads. It offers integrated features like auto-scaling, monitoring, security, and load balancing, as well as deep integration with other Google Cloud services, enabling seamless DevOps workflows and efficient cloud-native application management. GKE provides a highly available and reliable platform for running applications at scale, making it one of the most popular managed Kubernetes services in the cloud.</p> <p>Microsoft Azure Kubernetes Service (AKS) is a managed Kubernetes service provided by Microsoft Azure that simplifies the deployment, management, and scaling of containerized applications using Kubernetes. With AKS, Microsoft handles the Kubernetes control plane, including updates, patching, and scaling, allowing developers to focus on building and running their applications rather than managing infrastructure. AKS integrates with Azure\u2019s ecosystem, providing built-in monitoring, security features, and seamless integration with other Azure services like Azure Active Directory, networking, and storage. It supports automated scaling, load balancing, and rolling updates, making it easier to deploy, maintain, and scale applications in a cloud-native environment.</p> <p>ArgoCD is an open-source continuous delivery (CD) tool for Kubernetes that automates the deployment of applications using GitOps principles. It enables declarative management of Kubernetes resources by linking them to Git repositories, where application configurations and manifests are stored. ArgoCD continuously monitors these repositories for changes and automatically applies them to the Kubernetes clusters, ensuring the deployed state matches the desired configuration in Git. It provides a user-friendly web interface and CLI for managing applications, visualizing deployment status, and rolling back changes when necessary. By integrating with Git as the source of truth, ArgoCD ensures a secure, auditable, and automated workflow for Kubernetes application delivery.</p> <p>Portainer is an open-source, lightweight container management platform that simplifies the deployment, management, and monitoring of Docker and Kubernetes environments. It provides a user-friendly web interface for managing containerized applications, allowing users to easily create, configure, and monitor containers, images, networks, and volumes. Portainer supports both Docker and Kubernetes clusters, offering a unified management interface for users who may work with different container orchestration systems. It also provides role-based access control (RBAC) and a variety of features to streamline DevOps workflows, making it a popular choice for both beginners and experienced developers looking to manage containers in a simplified, accessible way.</p>"},{"location":"decisions/technical-decisions/containerization/#evaluation","title":"Evaluation","text":""},{"location":"decisions/technical-decisions/containerization/#docker","title":"Docker","text":"<p>Pros:</p> <ul> <li> <p>Ubiquity</p> </li> <li> <p>Wide ecosystem</p> </li> <li> <p>Docker Compose is very handy.</p> </li> </ul> <p>Cons:</p> <ul> <li> <p>Requires daemon</p> </li> <li> <p>Default setup needs root access unless configured</p> </li> <li> <p>Licensing shenanigans</p> </li> </ul>"},{"location":"decisions/technical-decisions/containerization/#podman","title":"Podman","text":"<p>Pros:</p> <ul> <li> <p>Rootless</p> </li> <li> <p>Daemonless</p> </li> <li> <p>OCI-compatible</p> </li> <li> <p>Docker CLI compatible</p> </li> </ul> <p>Cons:</p> <ul> <li> <p>Some ecosystem gaps</p> </li> <li> <p>Fewer tutorials and LLM prompts</p> </li> </ul>"},{"location":"decisions/technical-decisions/containerization/#serverless-lambda-knative","title":"Serverless (Lambda, Knative)","text":"<p>Pros:</p> <ul> <li> <p>Auto-scaling</p> </li> <li> <p>No infra to manage.</p> </li> </ul> <p>Cons:</p> <ul> <li> <p>Cold start latency</p> </li> <li> <p>Limited runtime control</p> </li> <li> <p>Vendor-specific setup doesn't lend itself to multi-cloud resilience</p> </li> <li> <p>No overlap with local tooling</p> </li> </ul>"},{"location":"decisions/technical-decisions/containerization/#direct-management-eg-via-systemd-or-scripts","title":"Direct management (e.g., via systemd or scripts)","text":"<p>Pros:</p> <ul> <li> <p>Lightweight, fast, easy</p> </li> <li> <p>Excellent for local software engineering</p> </li> </ul> <p>Cons:</p> <ul> <li> <p>Lacks orchestration</p> </li> <li> <p>Not scalable</p> </li> <li> <p>Not easy in the cloud</p> </li> </ul>"},{"location":"decisions/technical-decisions/containerization/#kubernetes-orchestration-tools","title":"Kubernetes / Orchestration tools","text":"<p>Pros:</p> <ul> <li> <p>By far the most powerful, scalable, and capable, for professional operations teams</p> </li> <li> <p>Definitely where we want to be aiming in the next couple of years</p> </li> </ul> <p>Cons:</p> <ul> <li> <p>Complex - probably too complex to ask mid-level software engineers to pick up for a non-ops project</p> </li> <li> <p>Overhead - probably too big a lift right now for us, because we don't have the networking setups</p> </li> </ul>"},{"location":"decisions/technical-decisions/containerization/#implications","title":"Implications","text":"<ul> <li> <p>Software engineering developer environments should transition to containers where feasible.</p> </li> <li> <p>CI/CD/CT pipelines will include container build steps with containers, depending on runner environment.</p> </li> <li> <p>Documentation and training needs to be created for software engineers to learn about containerization.</p> </li> <li> <p>For more-complex deployment needs, we'll need to create a path for   containerization leading to eventual use of Kubernetes or serverless platforms   depending on cost/performance trade-offs.</p> </li> </ul>"},{"location":"decisions/technical-decisions/containerization/#references","title":"References","text":"<ul> <li> <p>Podman Documentation</p> </li> <li> <p>Docker Documentation</p> </li> <li> <p>Open Container Initiative (OCI)</p> </li> <li> <p>AWS Lambda Container Support</p> </li> </ul>"},{"location":"decisions/technical-decisions/containerization/#decision","title":"Decision","text":"<p>We will adopt the following containerization and management strategy:</p> <p>Container Engine:</p> <ul> <li> <p>Use Podman as the default engine for local development and rootless use cases.</p> </li> <li> <p>Support Docker where Podman isn't viable, such as a project already using Docker Compose.</p> </li> </ul> <p>Container Image Management:</p> <ul> <li> <p>Use OCI-compliant image builds.</p> </li> <li> <p>Store and retrieve images via internal and external registries (e.g., ECR, Docker Hub, GitHub Container Registry).</p> </li> </ul> <p>Execution and Management:</p> <ul> <li> <p>For local development: encourage Podman rootless containers to increase security and reduce dependency on Docker daemon.</p> </li> <li> <p>For CI/CD/CT: Use containerized runners (e.g., GitHub Actions, GitLab Runners) with Podman setups depending on environment support.</p> </li> <li> <p>For ephemeral execution: leverage serverless runtimes when the workload fits.</p> </li> </ul> <p>Infrastructure as Code Integration:</p> <ul> <li> <p>Container lifecycle (build, deploy, destroy) will be managed through IaC tools such as Tofu/Terraform, or similar complementary technologies such as Dagger, Pulumi or Ansible. We intend to do a complementary ADR for these.</p> </li> <li> <p>All container-related infra should be declarative and version-controlled.</p> </li> </ul>"},{"location":"decisions/technical-decisions/document-services/","title":"What is a Document","text":"<p>Status: Request for collaboration, Decision Date: 2025-05-07 Governance: Collaboration to be confirmed, TDA, TDAG?</p>"},{"location":"decisions/technical-decisions/document-services/#situation-context-and-problem-statement","title":"Situation - Context and Problem Statement","text":"<p>There is inconsistency and confusion across teams and systems regarding the definition of a \"document\" within digital health services. This impacts communication, integration, and data governance.</p>"},{"location":"decisions/technical-decisions/document-services/#background-decision-drivers-optional","title":"Background - Decision Drivers (Optional)","text":"<p>Clinical documents are a fundamental part of a patient\u2019s record, capturing key information about care events, decisions, and outcomes. They are used for communication between professionals, legal recordkeeping, and continuity of care.</p> <p>Documents can vary in formats\u2014from scanned paper records and PDFs to structured digital notes generated by clinical systems. Despite their varied formats, these share common traits: they are authored, versioned, time-stamped, and intended for long-term reference in the clinical record.</p> <p>There is ongoing ambiguity across systems, teams, and stakeholders about what constitutes a clinical document, leading to inconsistent handling, impact on storage, misclassification, and poor user experience in accessing patient records.</p> <p>By clarifying what is a document makes them distinguishable from other clinical artefacts such as, but not limited to, clinical data, images and results. This definition is essential for effective governance, maintenance, storage, metadata tagging, information lifecycle management, and ensuring the right information is available at the right time for care decisions.</p>"},{"location":"decisions/technical-decisions/document-services/#assessment-considered-options","title":"Assessment - Considered Options","text":"<p>A document should be defined not just by its file format (e.g., PDF, CDA, DOCX), or by its type (clinic letter, discharge letter, clinic note) but by its function, intent, and context within clinical and administrative workflows. A true document represents a discrete, authored unit of information that:</p> <ul> <li>Has clear authorship and creation metadata</li> <li>Is version-controlled and auditable</li> <li>Is bound to a specific clinical or administrative event</li> <li>Is intended for long-term storage and retrieval</li> <li>Is readable, shareable, and legally defensible as a snapshot of care or decision-making</li> <li>Can be indexed and discovered via metadata and search</li> </ul> <p>Documents serve a critical role in continuity of care, legal accountability, information governance, and clinical safety. They offer a formal, persistent record designed to be understood by others (clinicians, patients, auditors), often across organisational boundaries.</p> <p>However, it is equally important to define what a document is NOT:</p> <ul> <li>It is not a discrete data point: individual measurements like heart rate, lab results, or blood pressure readings are data\u2014not documents.</li> <li>It is not a real-time stream: telemetry feeds or continuously updated dashboards are transient, not persistent.</li> <li>It is not an image: diagnostic images (e.g., X-rays, CT scans, echocardiograms, ultrasound) or media files that may be referenced by documents but are not themselves documents.</li> <li>It is not raw, unstructured notes without context or authorship (e.g., free-text comments in forms or internal system logs).</li> <li>It is not UI output or screen printouts unless preserved in an authored, versioned, and clinically contextual format.</li> <li>It is not temporary or incomplete drafts: unless formally authored, signed off, and stored as part of the health record.</li> <li>It is not an active form, that is structured clinical data and should be standardised and maintained in a clinical data repository. When a form is finalised and made into a pdf it can be a classed as a document and stored in a document repository.</li> </ul> <p>Without this functional definition and boundary-setting, we risk storing unnecessary or incomplete information, leading to:</p> <ul> <li>Information overload in the patient record</li> <li>Search and classification issues</li> <li>Legal and governance gaps (e.g., storing unapproved or draft content as part of the official record)</li> <li>Inconsistent clinician experience and trust in the system</li> </ul> <p>A shared understanding of what a document is, and is not, will help inform system architecture, clinical workflows, information governance, and retention strategies across NHS Wales and beyond.</p>"},{"location":"decisions/technical-decisions/document-services/#recommendation-decision-outcome","title":"Recommendation - Decision Outcome","text":"<p>Adopt and operationalise a definition of a clinical or administrative document across systems, teams, and governance processes to ensure consistency, safety, and interoperability. This definition should guide system design, information governance, user training, and record-keeping practices.</p> <p>A document should be defined as:</p> <p>A discrete, authored, version-controlled unit of clinical or administrative information that is contextually bound to a care event or activity, intended for long-term storage and reference. It should be retrievable, legally defensible, and include sufficient metadata (e.g., author, creation time, document type, subject, version control and encounter context).  </p> <p>Examples include:</p> <p>Discharge summaries</p> <ul> <li>Clinic letters</li> <li>Consent forms</li> <li>Care plans</li> </ul> <p>To ensure clarity and prevent misclassification, it must also be stated that a document is NOT:</p> <ul> <li>A single data point (e.g., a lab value or BP reading)</li> <li>A dynamic feed or real-time telemetry</li> <li>A medical image (e.g., X-ray, scan, ultrasound, echocardiograms)</li> <li>Raw or un-contextualised text notes</li> <li>Temporary drafts or internal UI outputs</li> <li>A file lacking authorship, provenance, or clinical context</li> <li>An active form, as that is structured clinical data.</li> </ul> <p>Action Steps:</p> <p>Embed this definition into technical specifications, governance frameworks, and clinical safety cases</p> <p>Align with national and international standards (e.g., Document metadata standard, IHE XDS, FHIR DocumentReference)</p> <p>Train system designers, product teams, and clinical staff on appropriate classification and usage</p> <p>Ensure search, lifecycle management, and metadata tagging are aligned with the above definition</p> <p>Exclude non-document artefacts from document repositories (e.g., data points, logs, raw media, images, active forms, etc)</p>"},{"location":"decisions/technical-decisions/fhir-for-interoperability-first/","title":"FHIR for Interoperability First","text":"<p>Info</p> <p>Status: Proposed</p> <p>Level: 3</p> <p>Updated: 2025-10-03</p>"},{"location":"decisions/technical-decisions/fhir-for-interoperability-first/#summary","title":"Summary","text":"<p>This Architecture Decision Record (ADR) mandates that Fast Healthcare Interoperability Resources (FHIR) be the primary standard for all new healthcare interoperability initiatives. This decision is driven by both the Welsh Health Circular (WHC/2023/018), which mandates FHIR for NHS Wales, and the strategic alignment with the National Data Resource (NDR), which is built on the Google Healthcare platform and natively uses FHIR. Adopting a FHIR-first approach will enhance data exchange, accelerate development, and ensure our systems are future-ready.</p>"},{"location":"decisions/technical-decisions/fhir-for-interoperability-first/#drivers","title":"Drivers","text":"<p>The primary driver for this decision is the Welsh Health Circular (WHC/2023/018), which mandates the use of FHIR. This is further supported by the Digital Health and Care Wales (DHCW) investment in the National Data Resource (NDR), a strategic platform based on Google Healthcare's FHIR-native infrastructure. To maximize the value of the NDR and ensure seamless data integration across the Welsh healthcare ecosystem, it is essential to standardize on a common interoperability framework.</p> <ul> <li>National Mandate: The Welsh Health Circular (WHC/2023/018) formally mandates FHIR as the foundational interoperability standard for all IT and digital systems across NHS Wales, aligning with the FAIR data principles (Findable, Accessible, Interoperable, Reusable).</li> <li>Strategic Alignment: We need to align our interoperability standards with the core platform of the NDR.</li> <li>Consistency: A single, nationally adopted standard is required to prevent fragmented data silos and reduce integration complexity.</li> <li>Future-Proofing: We must adopt a modern, actively developed standard to ensure the long-term viability of our healthcare systems.</li> </ul>"},{"location":"decisions/technical-decisions/fhir-for-interoperability-first/#options","title":"Options","text":""},{"location":"decisions/technical-decisions/fhir-for-interoperability-first/#1-adopt-a-fhir-first-policy","title":"1: Adopt a \"FHIR-First\" Policy","text":"<p>Mandate that FHIR is the default, preferred standard for all healthcare data interoperability projects.</p>"},{"location":"decisions/technical-decisions/fhir-for-interoperability-first/#2-allow-individual-project-based-standards","title":"2: Allow Individual Project-Based Standards","text":"<p>Permit teams to select their own interoperability standards (e.g., HL7v2, openEHR) on a case-by-case basis.</p>"},{"location":"decisions/technical-decisions/fhir-for-interoperability-first/#options-analysis","title":"Options Analysis","text":""},{"location":"decisions/technical-decisions/fhir-for-interoperability-first/#option-1-adopt-a-fhir-first-policy","title":"Option 1: Adopt a \"FHIR-First\" Policy","text":"<p>Pro:</p> <ul> <li>Enhanced Interoperability: Ensures all new systems can seamlessly connect with the National Data Resource and other FHIR-compliant systems.</li> <li>Accelerated Development: Teams can leverage a growing ecosystem of FHIR tools, libraries, and expertise, reducing development time and cost.</li> <li>Vendor Support: FHIR is widely adopted by major health IT vendors, improving our ability to integrate with third-party systems.</li> <li>Future-Ready: FHIR is a modern, evolving standard that will keep our architecture current.</li> </ul> <p>Con:</p> <ul> <li>Legacy System Integration: Integrating with older systems that do not support FHIR may require custom middleware or converters, adding complexity.</li> <li>Niche Use Cases: For some highly specialized use cases, FHIR may not be the most efficient or suitable standard.</li> <li>Bottlenecks: Increased dependency on FHIR Standards team for FHIR Profiles where none exist for a specific use case could introduce delays.</li> </ul>"},{"location":"decisions/technical-decisions/fhir-for-interoperability-first/#option-2-allow-individual-project-based-standards","title":"Option 2: Allow Individual Project-Based Standards","text":"<p>Pro:</p> <ul> <li>Flexibility: Teams can choose the standard that is the absolute best fit for their specific, immediate requirements.</li> <li>Commercial Scope: Ability to procure 3rd-party systems and products that don't support FHIR, providing potential access to a wider set of products.</li> </ul> <p>Con:</p> <ul> <li>Increased Complexity and Cost: Leads to a fragmented technology landscape, requiring multiple integration engines and skillsets, driving up costs.</li> <li>Data Silos: Creates barriers to data sharing between systems that use different standards, undermining the goal of a national data resource.</li> <li>Reduced Reusability: Prevents the reuse of common components and expertise across projects.</li> </ul>"},{"location":"decisions/technical-decisions/fhir-for-interoperability-first/#recommendation","title":"Recommendation","text":"<p>We will adopt a \"FHIR-First\" policy.</p> <p>FHIR is to be considered the primary and default standard for all healthcare interoperability initiatives within DHCW. This approach provides the most significant long-term benefits by aligning our technical architecture with the strategic National Data Resource, fostering a cohesive data ecosystem, and positioning us to take advantage of modern healthcare technology.</p>"},{"location":"decisions/technical-decisions/fhir-for-interoperability-first/#consequences","title":"Consequences","text":"<ul> <li>Pro: Improved Interoperability: Aligns systems with the National Data Resource (NDR) and promotes seamless data exchange.</li> <li>Pro: Accelerated Development: Teams can reuse common tools and resources, speeding up project delivery.</li> <li>Pro: Future-Ready: Adopting a modern, evolving standard ensures our architecture remains current.</li> <li>Con: Legacy System Challenges: Integrating older, non-FHIR systems may require additional effort and custom solutions, although this is generally true for any non-standards based system.</li> <li>Con: Potential for Misfit: FHIR might not be the best choice for every situation.</li> </ul>"},{"location":"decisions/technical-decisions/fhir-for-interoperability-first/#confirmation","title":"Confirmation","text":"<p>Compliance with this decision will be enforced by the Technical Design Assurance Group (TDAG) during solution review.</p> <p>If a team believes FHIR is not suitable for their specific use case, they must document their reasoning and propose an alternative. This proposal must be submitted to the Technical Design Assurance Group (TDAG) in the form of a new Architecture Decision Record for review and approval before proceeding.</p>"},{"location":"decisions/technical-decisions/fhir-for-interoperability-first/#more-information","title":"More Information","text":"<ul> <li>Welsh Health Circular (WHC/2023/018): Introduction of HL7 FHIR as a foundational standard in all NHS Wales Bodies</li> </ul>"},{"location":"decisions/technical-decisions/live-dora-metrics-dashboards/","title":"Live DORA Metrics Dashboards","text":"<p>Note</p> <p>Work in Progress</p> <p>Status: first sketch, work in progress, request for collaboration</p> <p>Date: Updated 2025-04-08</p> <p>Governance: To Be Discovered; potentially a combo of this repo participants, DHCW CISO, NHS Wales UCB peers, etc.</p>"},{"location":"decisions/technical-decisions/live-dora-metrics-dashboards/#context","title":"Context","text":"<p>Broadly, our organization wants to improve the quality of our software engineering, and we want to do this by making software engineering metrics visible. We intend to start with the DevOps Research and Assessment (DORA) report because these are well-known, well-understood, and well-researched.</p>"},{"location":"decisions/technical-decisions/live-dora-metrics-dashboards/#what-are-dora-metrics","title":"What are DORA Metrics?","text":"<p>https://dora.dev/guides/dora-metrics-four-keys/</p> <p>The DORA metics are:</p> <ul> <li> <p>Lead Time - This metric measures the time it takes for a code commit or change   to be successfully deployed to production. It reflects the efficiency of your   software delivery process.</p> </li> <li> <p>Deployment Frequency - This metric measures how often application changes are   deployed to production. Higher deployment frequency indicates a more efficient   and responsive delivery process.</p> </li> <li> <p>Change Failure - This metric measures the percentage of deployments that cause   failures in production, requiring hotfixes or rollbacks. A lower change   failure rate indicates a more reliable delivery process.</p> </li> <li> <p>Recovery Time a.k.a. Time to Restore Service a.k.a. Failed Deployment Reset   Time - This metric measures the time it takes to recover from a failed   deployment. A lower recovery time indicates a more resilient and responsive   system.</p> </li> </ul> <p>These metrics are in two categories:</p> <ul> <li> <p>Throughput: Lead Time &amp; Deployment Frequency.</p> </li> <li> <p>Stability: Change Failure &amp; Recovery Time.</p> </li> </ul>"},{"location":"decisions/technical-decisions/live-dora-metrics-dashboards/#drivers","title":"Drivers","text":"<p>We want to develop a live dashboard to track our projects' DORA metrics. This dashboard will be used by software engineering teams, including our programmers, project managers, and all the project's other stakeholders.</p> <p>We believe this kind of visibility, transparency, and monitoring can help us improve our software engineering practices and outcomes.</p> <p>We believe the live DORA metrics dashboards will likely include the kinds of aspects below.</p> <p>Data Sources:</p> <ul> <li> <p>Git/CI/CD System to retrieve lead time, deployment frequency, change   failure rate, and recovery time.</p> </li> <li> <p>Incident Management Tools to help calculate the time to restore service.</p> </li> </ul> <p>Data Collection and ETL Process:</p> <ul> <li> <p>ETL (Extract, Transform, Load) pipelines to gather data from the above   systems, across projects, then aggregate it into a central data store.</p> </li> <li> <p>Data will be refreshed at regular intervals (e.g., every hour) to provide   usable daily-quality metrics.</p> </li> <li> <p>The collected data will be stored in a data store TBD. We may want to try a   Time-series Database (TSDB) rather than a relational database (RDB) because   time-series data may provide efficient querying and retrieval of time-based   metrics.</p> </li> </ul> <p>Backend Services:</p> <ul> <li> <p>A RESTful API will serve as the backend for the dashboard, handling   requests from the frontend.</p> </li> <li> <p>Authentication and authorization TBD.</p> </li> </ul> <p>Frontend (Dashboard):</p> <ul> <li> <p>The dashboard will be built using JavaScript/TypeScript for flexibility and   maintainability.</p> </li> <li> <p>Data visualization will be handled using an off-the-shelf charting library TBD.</p> </li> <li> <p>We'll consider developing the frontend to update dynamically based on data   changes via WebSockets or Server-Sent Events (SSE).</p> </li> </ul> <p>Monitoring and Alerts:</p> <ul> <li> <p>We may want to create alerts. For example, we may want to create alerts that   will be triggered when certain thresholds are exceeded (e.g., high failure   rate, slow recovery time). These alerts will be visible in the dashboard and   could also be pushed to our messaging system.</p> </li> <li> <p>We will also monitor the health of the dashboard itself.</p> </li> </ul>"},{"location":"decisions/technical-decisions/live-dora-metrics-dashboards/#alternatives-considered","title":"Alternatives Considered","text":"<p>Manual data collection vs. automated ETL pipelines:</p> <ul> <li>Initially, we considered manually extracting metrics through scheduled   scripts, but this would be error-prone and less maintainable. The automated   ETL pipelines were chosen for their scalability and reliability.</li> </ul> <p>Using a traditional relational database vs. time-series database:</p> <ul> <li>We considered using a relational database (e.g., PostgreSQL) to store DORA   metrics, but time-series databases like InfluxDB offer optimized storage   and query performance for time-based data, making them a better choice for   this use case.</li> </ul> <p>*Frontend technologies:</p> <ul> <li>We evaluated using Vue.js or Angular for the frontend but decided on   React.js due to its widespread adoption, large community, and extensive   library support for real-time data visualization.</li> </ul>"},{"location":"decisions/technical-decisions/live-dora-metrics-dashboards/#common-pitfalls","title":"Common pitfalls","text":"<p>From https://dora.dev/guides/dora-metrics-four-keys/</p> <p>There are some pitfalls to watch out for as your team adopts DORA\u2019s software delivery metrics, including the following:</p> <ul> <li> <p>Setting metrics as a goal. Ignoring Goodhart\u2019s law and making broad statements   like, \u201cEvery application must deploy multiple times per day by year\u2019s end,\u201d   increases the likelihood that teams will try to game the metrics.</p> </li> <li> <p>Having one metric to rule them all. Attempting to measure complex systems with   the idea that only one metric matters. Teams should identify multiple metrics,   including some with a healthy amount of tension between them. The SPACE   framework can guide your discovery of a set of metrics.</p> </li> <li> <p>Using industry as a shield against improving. For example, some teams in   highly regulated industries might claim that compliance requirements prevent   them from disrupting the status quo.</p> </li> <li> <p>Making disparate comparisons. These metrics are meant to be applied at the   application or service level. Comparing metrics between vastly different   applications (for example, a mobile app and a mainframe system) can be   misleading.</p> </li> <li> <p>Having siloed ownership. Sharing all four metrics across development,   operations, and release teams fosters collaboration and shared ownership of   the delivery process. Isolating teams with specific metrics can lead to   friction and finger-pointing.</p> </li> <li> <p>Competing. The goal is to improve your team\u2019s performance over time, not to   compete against other teams or organizations. Use the metrics as a guide for   identifying areas for growth and celebrating progress.</p> </li> <li> <p>Focusing on measurement at the expense of improvement. The data your team   needs to collect for the four keys is available in a number of different   places today. Building integrations to multiple systems to get precise data   about your software delivery performance might not be worth the initial   investment. Instead, it might be better to start with having conversations,   taking the DORA Quick Check, or using a source-available or commercial product   that comes with pre-built integrations.</p> </li> </ul>"},{"location":"decisions/technical-decisions/live-dora-metrics-dashboards/#consequences","title":"Consequences","text":"<p>Maintenance: The dashboard will require ongoing maintenance, especially with regards to data source integrations and ensuring the ETL pipelines are functioning properly.</p>"},{"location":"decisions/technical-decisions/live-dora-metrics-dashboards/#next-steps","title":"Next Steps","text":"<p>We believe we should gather information about two kinds of approaches:</p> <ol> <li> <p>Build: We can build the dashboard from scratch.</p> </li> <li> <p>Buy: We can purchase a commercial dashboard solution.</p> </li> </ol> <p>If we choose to build, then we believe the steps would be:</p> <ol> <li> <p>Build the frontend dashboard with real-time visualizations of test metrics.</p> </li> <li> <p>Develop the RESTful API to serve data to the frontend.</p> </li> <li> <p>Implement the ETL pipelines for collecting data from the various sources.</p> </li> <li> <p>Deploy the system by using CI/CD and ideally targeting a public cloud.</p> </li> </ol>"},{"location":"decisions/technical-decisions/live-dora-metrics-dashboards/#recommendation-decision-outcome","title":"Recommendation - Decision Outcome","text":"<p>TODO</p>"},{"location":"decisions/technical-decisions/python-script-runner/","title":"python script runner","text":"<p>Status: WIP + RFC + adopting now for pragmatic trial/pilot/PoC</p> <p>Date: 2025-03-31</p> <p>Governance: To Be Discovered; potentially a combo of this repo participants, DHCW CISO, NHS Wales UCB peers, etc.</p>"},{"location":"decisions/technical-decisions/python-script-runner/#situation-context-and-problem-statement","title":"Situation - Context and Problem Statement","text":"<p>Generally we are aiming for software engineering to use the python programming language for many needs, such as general purpose scripting, system administration, test automation, AI/ML interconnection, etc.</p> <p>Specifically we are aiming to make it fast and easy for python programmers to run python scripts that are standalone and as self-supporting as reasonably possible. For example this means a typical one-file python script that can download its own dependencies, create its own virtual environments, and run itself from the command line.</p>"},{"location":"decisions/technical-decisions/python-script-runner/#background-decision-drivers","title":"Background - Decision Drivers","text":"<p>Python has a long history of many ways to launch it that are incompatible, many kinds of dependency management that are incompatible, and many kinds of virtual environment managers that are incompatible. As far as we know, there is no perfect way to write a standalone self-supporting python script.</p> <p>Therefore we aim to get as close as reasonably possible, using good modern tooling and good modern practices. We're willing to accept some up-front setup, such as ensuring that a system already has a current runtime python and current runtime manager.</p> <p>Scope:</p> <ul> <li> <p>In scope: single-file python scripts (or a small set of files that are python scripts and any related files such as assets) that don't use a python package manager.</p> </li> <li> <p>Out of scope: any larger-scale python projects, such as multi-file python scripts that already have a requirements.txt file, or a python package that's deployable with pip, or a python notebook such as in Jupyter, or a python web app such as with Django, etc.</p> </li> </ul> <p>Background reading:</p> <ul> <li> <p>Self-contained python scripts with uv</p> </li> <li> <p>Self-contained python scripts with uv - discussion on Hacker News)</p> </li> <li> <p>Python specifications: inline script metadata</p> </li> </ul>"},{"location":"decisions/technical-decisions/python-script-runner/#givens","title":"Givens","text":"<p>At previous clients, Joel evaluated <code>pip</code>, <code>pipx</code>, <code>poetry</code>, <code>uv</code>, by trying them in real use on real projects that had significant needs such as for AI, cloud services, and test automation. Joel chose uv because it provides more-reliable dependency version management, more-batteries-included capabilities, and much faster speed; Digital Health and Care Wales could do a separate architecture decision record for choosing uv, if there's anyone that feels that there's a better choice or a strong need to consider other choices.</p> <p>\"The whole point of uv is to solve the nightmare that is running a script with the right version of python with the right dependencies. \"Just use the system python\" gets you right back to the start such as, oh no! It didn't parse because it used python 3.11 features and I'm still on 3.6.\"</p>"},{"location":"decisions/technical-decisions/python-script-runner/#assessment-considered-options","title":"Assessment - Considered Options","text":"<p>Options so far:</p> <ul> <li> <p>uv with inline script metadata</p> </li> <li> <p>uv execute runner</p> </li> <li> <p>nuitka compiler</p> </li> </ul>"},{"location":"decisions/technical-decisions/python-script-runner/#option-uv-with-inline-script-metadata","title":"Option: uv with inline script metadata","text":"<p>To launch a python script that's as self-supporting as reasonable possible, use this the code, as described in the link above:</p> <p>File <code>example.py</code>:</p> <pre><code>#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \"&gt;=3.13\"\n# dependencies = [\n#   \"alfa&gt;=1\", \n#   \"bravo&gt;=2\", \n#   \"charlie&gt;=3\",\n# ]\n# ///\nimport alfa\nimport bravo\nimport charlie\n</code></pre> <p>Change to be executable:</p> <pre><code>chmod +x example.py\n</code></pre> <p>Run:</p> <pre><code>./example.py\n</code></pre> <p>Caveats thanks to discussion:</p> <ul> <li> <p>The script requires uv to already be installed. Arguably you could make it a shell script that checks if uv is already installed and then installs it via curlpipe if not... but that's quite a bit of extra boilerplate and the curlpipe pattern is bad. \u2026 Installing uv will become less of an issue as package managers include uv in their repositories. For example, uv is already available in Alpine Linux and Homebrew: https://repology.org/project/uv/versions.</p> </li> <li> <p>Inline script metadata is a Python standard. When there is no uv on the system and uv isn't packaged but you have the right version of Python for the script, you can run the script with pipx: https://pipx.pypa.io/stable/examples/#pipx-run-examples. pipx is much more widely packaged: https://repology.org/project/pipx/versions.</p> </li> <li> <p>Auto-creating a venv somewhere in your home directory is not really self-contained. If you run the script as a one-off and then delete it, that venv is still there, taking up space. I can't find any assertion in the uv docs that these temporary virtual environments are ever automatically cleaned up.</p> </li> <li> <p>This technique doesn't change the semantics of the code itself, it just changes the environment in which the code runs. In that respect it is no different from a <code>#!/bin/bash</code> comment at the top of a shell script.</p> </li> <li> <p>The showstopper for us is our SCA vulnerability scanner doesn't work with uv yet. You can add an intermediate sca stage that exports the uv dependencies as requirements.txt.</p> </li> <li> <p>Windows doesn't support shebang lines as you probably know, but if you associate uv with .py files you'll get the same result. I think it should be something like this: <code>ftype Python.File=C:\\Path\\to\\uv.exe run %L %*</code>. If you don't use the CPython installer the Python.File file type might not be defined, so you might need to set that with <code>assoc</code> first: <code>assoc .py=Python.File</code>.</p> </li> </ul>"},{"location":"decisions/technical-decisions/python-script-runner/#option-uv-execute-runner","title":"Option: uv execute runner","text":"<p>From discussion:</p> <p>I have my own uv execute script:</p> <p>File <code>uve</code>:</p> <pre><code>#!/bin/bash\ntemp=$(mktemp)\ntrap 'unlink $temp' EXIT\nuv export --script $1 --no-hashes &gt; $temp\nuv run --with-requirements $temp vim $1\n</code></pre>"},{"location":"decisions/technical-decisions/python-script-runner/#option-nuitka-compiler","title":"Option: nuitka compiler","text":"<p>From discussion.</p> <p>For those who want a really self-contained Python script, I'd like to point out the Nuitka compiler.</p> <p>I've been using it in production for my gRPC services with no issues whatsoever - just \"nuitka --onefile run.py\" and that's it. It Just Werks.</p> <p>Since it's a compiler, the resulting binary is even faster than the original Python program would be if it were bundled via Pyinstaller.</p> <p>https://nuitka.net/</p> <p>https://github.com/kayhayen</p>"},{"location":"decisions/technical-decisions/python-script-runner/#recommendation-decision-outcome","title":"Recommendation - Decision Outcome","text":"<p>Adopt.</p> <p>Revisit periodically, such as when there are new capabilities for <code>uv</code>, or new launching options for <code>python</code>, or new defaults for busybox or Alpine.</p> <p>Cautions thanks to the original article:</p> <ul> <li> <p>Be aware the virtual environment is not created/resolved before running. This means that you won't get linting/autocomplete properly for the environment.</p> </li> <li> <p>Be aware that the <code>-S</code> flag depends on coreutils env, which isn't available by default on some systems, such as the busybox env that you get when using default Alpine. One workaround is to install GNU <code>coreutils</code> in your container, or to install <code>uutils-coreutils</code> for a more lightweight implementation in Rust.</p> </li> </ul>"},{"location":"design-authority/","title":"Introduction","text":"<p>The Digital Health and Care Wales (DHCW) Technical Design Authority (TDA) is a key governance body that commissions, owns, and steers the development of DHCW's Enterprise Architecture. The TDA ensures alignment with strategic objectives of both the organisation and wider Health and Care policy and strategy.</p> <p>This section contains the following key areas:</p>"},{"location":"design-authority/#architecture-decision-records-adrs","title":"Architecture Decision Records (ADRs)","text":"<ul> <li>Decision Template - The   standard template used for documenting architecture decisions.</li> <li>Decision Process - The   approved process for proposing, developing, and approving ADRs.</li> </ul>"},{"location":"design-authority/#governance","title":"Governance","text":"<ul> <li>Terms of Reference - The TDA's objectives,   membership, and operating model.</li> <li>Meeting Records - Documentation of TDA meetings, decisions, and actions</li> </ul>"},{"location":"design-authority/#enterprise-architecture","title":"Enterprise Architecture","text":"<ul> <li>Enterprise Architecture Metamodel - The structured   overview of how NHS Wales architecture is modeled, including component types   and relationships.</li> </ul>"},{"location":"design-authority/dhcw/architecture-decision-record-template/","title":"{Your Title Here}","text":"<p>Info</p> <p>Status: { Proposed | Under Review | Accepted |               Rejected | Superseded   | Deprecated }</p> <p>Level: { 1 - 4 }</p> <p>Updated: { YYYY-MM-DD }</p>"},{"location":"design-authority/dhcw/architecture-decision-record-template/#summary","title":"Summary","text":"<p>{This is the 'executive summary' or 'elevator pitch' for your ADR. In a few concise sentences (typically 2-4), clearly state the core problem, question, or opportunity this ADR addresses. Include a brief hint at the decision made or the area of focus. The goal is to help readers quickly understand what this ADR is about and decide if it's relevant to them, without needing to read the entire document. Think of it as the abstract of a technical paper or a very brief introduction to the main topic.}</p>"},{"location":"design-authority/dhcw/architecture-decision-record-template/#drivers","title":"Drivers","text":"<p>{This section explains why this decision is being made now. Clearly articulate the primary motivations, needs, or problems that necessitate this architectural decision. Think about the underlying reasons and pressures.}</p> <ul> <li>{e.g. We are developing a new feature/capability that needs...}</li> <li>{e.g. We need to improve performance, accessibility, remove debt...}</li> <li>{e.g. Feedback from users suggests...}</li> <li>{e.g. The current approach imposes these limitations...}</li> </ul>"},{"location":"design-authority/dhcw/architecture-decision-record-template/#options","title":"Options","text":"<p>{This is where you list the different options you are considering. Stick to the facts and avoid opinions, the next section covers the analysis. Include a concise description, links to relevant documentation or examples.</p> <p>Include all significant alternatives you explored, even if they were ultimately not chosen. The goal is to give readers a clear, unbiased understanding of each alternative before you dive into the evaluation.}</p>"},{"location":"design-authority/dhcw/architecture-decision-record-template/#option-1-title","title":"{Option 1 Title}","text":"<p>{Describe the option, provide a summary, list the facts, provide links etc.}</p>"},{"location":"design-authority/dhcw/architecture-decision-record-template/#option-n-title","title":"{Option n Title}","text":"<p>...</p>"},{"location":"design-authority/dhcw/architecture-decision-record-template/#options-analysis","title":"Options Analysis","text":"<p>{This is where you critically evaluate each option presented in the Options section. For each option, provide a balanced view of its advantages, disadvantages, and any other relevant considerations or trade-offs. Be specific and, where possible, relate your points back to the Drivers.</p> <p>Consider aspects like:</p> <ul> <li>Cost (development, operational, licensing)</li> <li>Complexity (implementation, maintenance, learning curve)</li> <li>Risks (technical, operational, security)</li> <li>Alignment with architectural principles or existing standards</li> <li>Impact on performance, scalability, usability, maintainability,     security etc.</li> </ul> <p>Include as many Pro/Con/Other statements as required.}</p>"},{"location":"design-authority/dhcw/architecture-decision-record-template/#option-1-assessment","title":"{Option 1 Assessment}","text":"<p>Pro:</p> <ul> <li>{A specific advantage or benefit of this option.}</li> <li>...</li> </ul> <p>Con:</p> <ul> <li>{A specific disadvantage, risk, or cost associated with this option.}</li> <li>...</li> </ul> <p>Other:</p> <ul> <li>{A relevant point that isn't strictly a pro or con.}</li> <li>...</li> </ul>"},{"location":"design-authority/dhcw/architecture-decision-record-template/#option-n-assessment","title":"{Option n Assessment}","text":"<p>...</p>"},{"location":"design-authority/dhcw/architecture-decision-record-template/#recommendation","title":"Recommendation","text":"<p>{This is where you clearly state the final decision, and explicitly name the option that has been selected. Explain in detail why this option was chosen. You should clearly articulate how the chosen option best addresses the Drivers and meets the key requirements or solves the stated problem.}</p>"},{"location":"design-authority/dhcw/architecture-decision-record-template/#consequences","title":"Consequences","text":"<p>{This section is optional.}</p> <p>{Now that a decision has been made what are the expected outcomes and impacts, both positive and negative? What known limitations, costs, or risks are being accepted by making this decision? How will this decision affect different stakeholders, other systems, development practices, operational procedures, or user experience?}</p> <ul> <li> <p>Pro: {A specific positive outcome or benefit expected from this decision.}</p> </li> <li> <p>Con: {A specific accepted downside, cost, or risk resulting from this     decision. }</p> </li> <li> <p>Other: {A consequence that isn't strictly a pro or con.}</p> </li> </ul>"},{"location":"design-authority/dhcw/architecture-decision-record-template/#confirmation","title":"Confirmation","text":"<p>{This section is optional.}</p> <p>{Outline how the implementation of this decision will be verified and how ongoing compliance will be ensured. This helps demonstrate that the decision isn't just theoretical but will be actively put into practice and monitored.</p> <p>How will you check that the decision has been correctly implemented? (e.g., code reviews, specific tests, demonstrations, peer review).</p> <p>How will adherence to this decision be maintained over time? (e.g., automated checks, periodic audits, updates to team guidelines, training).</p> <p>Are there specific metrics or indicators that will show the decision is achieving its intended positive outcomes? (e.g., performance benchmarks, adoption rates, reduction in specific errors, user feedback scores).</p> <p>Who is responsible for overseeing this, and what happens if the decision is not followed?}</p>"},{"location":"design-authority/dhcw/architecture-decision-record-template/#more-information","title":"More Information","text":"<p>{This section is optional.}</p> <p>{Use this section to provide any supplementary information that supports the decision, adds context, or guides future actions. Links to other decisions and resources might appear here as well.</p> <p>You could briefly note who was involved in the decision-making process and if/how consensus was reached. You may also want to suggest a timeframe or specific events that might prompt a re-evaluation of this decision in the future.}</p>"},{"location":"design-authority/dhcw/architecture-design-overview-template/","title":"Architecture Design Overview:","text":""},{"location":"design-authority/dhcw/architecture-design-overview-template/#document-details","title":"Document Details","text":"<p>Document author: ...</p> <p>Document version: ...</p> <p>Status: { Draft | Approved }</p> <p>Approved by: ...</p> <p>Date approved: ...</p> <p>Review date: yyyy/mm/dd</p> <p>Template version: 1.2</p>"},{"location":"design-authority/dhcw/architecture-design-overview-template/#revision-history","title":"Revision History","text":"Date Version Author Revision Summary yyyy-mm-dd v0.1 ... ..."},{"location":"design-authority/dhcw/architecture-design-overview-template/#approvalscrutiny-history","title":"Approval/Scrutiny History","text":"Committee or Group Date Outcome ... yyyy-mm-dd {Draft / Approved / Approved with caveats / Not Approved}"},{"location":"design-authority/dhcw/architecture-design-overview-template/#1-introduction-and-goals","title":"1. Introduction and Goals","text":"<p>Please delete guide text before submission</p> <p>Describes the relevant requirements and the driving forces that software architects and development team must consider. These include:</p> <p>\u2022 Underlying business goals,</p> <p>\u2022 Essential features,</p> <p>\u2022 Essential functional requirements,</p> <p>\u2022 Quality goals for the architecture and</p> <p>\u2022 Relevant stakeholders and their expectations</p> <p>...</p>"},{"location":"design-authority/dhcw/architecture-design-overview-template/#11-requirements-overview","title":"1.1 Requirements Overview","text":"<p>...</p>"},{"location":"design-authority/dhcw/architecture-design-overview-template/#12-quality-goals","title":"1.2 Quality Goals","text":"<p>...</p>"},{"location":"design-authority/dhcw/architecture-design-overview-template/#13-stakeholders","title":"1.3 Stakeholders","text":"<p>The target audience for this design, and their interests, include:</p> Role/Name Contact Expectations ... ... ..."},{"location":"design-authority/dhcw/architecture-design-overview-template/#2-architecture-constraints","title":"2. Architecture Constraints","text":"<p>Please delete guide text before submission</p> <p>Any requirement that constrains software architects in their freedom of design and implementation decisions or decision about the development process. These constraints sometimes go beyond individual systems and are valid for whole organizations and companies.</p> <p>...</p>"},{"location":"design-authority/dhcw/architecture-design-overview-template/#3-context-and-scope","title":"3. Context and Scope","text":"<p>Please delete guide text before submission </p> <p>As the name suggests - delimits your system (i.e. your scope) from all its communication partners (neighbouring systems and users, i.e. the context of your system). It thereby specifies the external interfaces.  </p> <p>If necessary, differentiate the business context (domain specific inputs and outputs) from the technical context (channels, protocols, hardware).</p> <p>...</p>"},{"location":"design-authority/dhcw/architecture-design-overview-template/#31-business-context","title":"3.1 Business Context","text":"<p>...</p>"},{"location":"design-authority/dhcw/architecture-design-overview-template/#32-technical-context","title":"3.2 Technical Context","text":"<p>...</p>"},{"location":"design-authority/dhcw/architecture-design-overview-template/#4-solution-strategy","title":"4. Solution Strategy","text":"<p>Please delete guide text before submission</p> <p>A short summary and explanation of the fundamental decisions and solution strategies, that shape system architecture. It includes:</p> <p>\u2022 Technology decisions</p> <p>\u2022 Decisions about the top-level decomposition of the system, e.g. usage of an architectural pattern or design pattern</p> <p>\u2022 Decisions on how to achieve key quality goals</p> <p>\u2022 Relevant organizational decisions, e.g. selecting a development process or delegating certain tasks to third parties.</p> <p>...</p>"},{"location":"design-authority/dhcw/architecture-design-overview-template/#5-building-block-view","title":"5. Building Block View","text":"<p>Please delete guide text before submission </p> <p>The building block view shows the static decomposition of the system into building blocks (modules, components, subsystems, classes, interfaces, packages, libraries, frameworks, layers, partitions, tiers, functions, macros, operations, data structures, ...) as well as their dependencies (relationships, associations, ...)  </p> <p>This view is mandatory for every architecture documentation. In analogy to a house this is the floor plan.</p> <p>...</p>"},{"location":"design-authority/dhcw/architecture-design-overview-template/#51-c4-level-1-view","title":"5.1 C4 Level 1 View","text":"<p>...</p>"},{"location":"design-authority/dhcw/architecture-design-overview-template/#52-c4-level-2-view","title":"5.2 C4 Level 2 View","text":"<p>...</p>"},{"location":"design-authority/dhcw/architecture-design-overview-template/#6-runtime-view","title":"6. Runtime View","text":"<p>Please delete guide text before submission</p> <p>The runtime view describes concrete behaviour and interactions of the system's building blocks in form of scenarios from the following areas:</p> <p>\u2022 Important use cases or features: how do building blocks execute them?</p> <p>\u2022 Interactions at critical external interfaces: how do building blocks cooperate with users and neighbouring systems?</p> <p>\u2022 Operation and administration: launch, start-up, stop</p> <p>\u2022 Error and exception scenarios</p> <p>Remark: the main criterion for the choice of possible scenarios (sequences, workflows) is their architectural relevance. It is not important to describe a large number of scenarios. You should rather document a &gt; representative selection.</p> <p>...</p>"},{"location":"design-authority/dhcw/architecture-design-overview-template/#7-deployment-view","title":"7. Deployment view","text":"<p>Please delete guide text before submission</p> <p>The deployment view describes:</p> <p>\u2022 Technical infrastructure used to execute your system, with elements like geographical locations, environments, computers, processors, channels and net topologies as well as other elements and</p> <p>\u2022 Mapping of (software) building blocks to that infrastructure elements.</p> <p>Often systems are executed in different environments, e.g. development environment, test environment, production environment. In such cases you should document all relevant environments.</p> <p>Especially document a deployment view if your software is executed as distributed system with more than one computer, processor, server or container or when you design and construct your own hardware processors and chips.</p> <p>From a software perspective it is sufficient to capture only those elements of an infrastructure that are needed to show a deployment of your building blocks. Hardware architects can go beyond that and describe an infrastructure to any level of detail they need to capture.</p> <p>...</p>"},{"location":"design-authority/dhcw/architecture-design-overview-template/#8-crosscutting-concepts","title":"8. Crosscutting Concepts","text":"<p>Please delete guide text before submission</p> <p>This section describes overall, principal regulations and solution ideas that are relevant in multiple parts (= cross-cutting) of your system. Such concepts are often related to multiple building blocks. They can include many different topics, such as</p> <p>\u2022 Models, especially domain models</p> <p>\u2022 Architecture or design patterns</p> <p>\u2022 Rules for using specific technology</p> <p>\u2022 Principal, often technical decisions of an overarching (= cross-cutting) nature</p> <p>\u2022 Implementation rules</p> <p>...</p>"},{"location":"design-authority/dhcw/architecture-design-overview-template/#81-design-patterns","title":"8.1 Design Patterns","text":"<p>...</p>"},{"location":"design-authority/dhcw/architecture-design-overview-template/#82-security","title":"8.2 Security","text":"<p>...</p>"},{"location":"design-authority/dhcw/architecture-design-overview-template/#83-scalability","title":"8.3 Scalability","text":"<p>...</p>"},{"location":"design-authority/dhcw/architecture-design-overview-template/#84-resilience","title":"8.4 Resilience","text":"<p>...</p>"},{"location":"design-authority/dhcw/architecture-design-overview-template/#85-observability","title":"8.5 Observability","text":"<p>...</p>"},{"location":"design-authority/dhcw/architecture-design-overview-template/#86-regulatory-compliance","title":"8.6 Regulatory &amp; Compliance","text":"<p>...</p>"},{"location":"design-authority/dhcw/architecture-design-overview-template/#9-architecture-decisions","title":"9. Architecture Decisions","text":"<p>Please delete guide text before submission</p> <p>Important, expensive, large scale or risky architecture decisions including rationales. With \"decisions\" we mean selecting one alternative based on given criteria.</p> <p>Please use your judgement to decide whether an architectural decision should be documented here in this central section or whether you better document it locally (e.g. within the white box template of one building block).</p> <p>Avoid redundancy. Refer to section 4, where you already captured the most important decisions of your architecture.</p> <p>...</p>"},{"location":"design-authority/dhcw/architecture-design-overview-template/#91-new-adrs","title":"9.1 New ADRs","text":"ID Impact ##### ..."},{"location":"design-authority/dhcw/architecture-design-overview-template/#92-design-history","title":"9.2 Design History","text":"Date Impact Rationale yyyy-mm-dd ... ..."},{"location":"design-authority/dhcw/architecture-design-overview-template/#10-quality-requirements","title":"10. Quality Requirements","text":"<p>Please delete guide text before submission </p> <p>This section contains all quality requirements as quality tree with scenarios. The most important ones have already been described in section 1.2. (quality goals)  </p> <p>Here you can also capture quality requirements with lesser priority, which will not create high risks when they are not fully achieved.</p> <p>...</p>"},{"location":"design-authority/dhcw/architecture-design-overview-template/#11-risks-and-technical-debt","title":"11. Risks and Technical Debt","text":"<p>Please delete guide text before submission </p> <p>As the name suggests - delimits your system (i.e. your scope) from all its communication partners (neighbouring systems and users, i.e. the context of your system). It thereby specifies the external interfaces.  </p> <p>If necessary, differentiate the business context (domain specific inputs and outputs) from the technical context (channels, protocols, hardware).</p>"},{"location":"design-authority/dhcw/architecture-design-overview-template/#111-risks","title":"11.1 Risks","text":"ID Impact Mitigation / Plan Owner #### {Low / Medium / High} ... ..."},{"location":"design-authority/dhcw/architecture-design-overview-template/#112-technical-debt","title":"11.2 Technical Debt","text":"ID Impact Mitigation / Plan Owner #### {Low / Medium / High} ... ..."},{"location":"design-authority/dhcw/architecture-design-overview-template/#12-glossary","title":"12. Glossary","text":"Term Definition ... ..."},{"location":"design-authority/dhcw/architecture-decision-record-process/","title":"Architecture Decision Record Process","text":"<p>Approved</p> <p>This process was approved by the DHCW Technical Design Authority (TDA) on 13/06/2025</p>"},{"location":"design-authority/dhcw/architecture-decision-record-process/#introduction","title":"Introduction","text":"<p>This document outlines the process for proposing, developing, collaborating on, and approving Architecture Decision Records (ADRs) within DHCW. The process emphasises collaboration and working in the open whilst minimising the involvement of formal governance bodies (e.g. Technical Design Authority (TDA) and Technical Design Assurance Group (TDAG)) as much as is practicable whilst maintaining suitable levels of assurance and governance.</p> <p>Anyone can propose an ADR and request collaboration to approve a decision. The proposal should clearly articulate the problem and context, and may include a solution or decision if ready. Early engagement is strongly encouraged, so it is expected proposals will be incomplete and very draft when first proposed.</p> <p>There are multiple levels of decision defined, which follow different processes proportionate to their impact/significance.</p> <p>Template</p> <p>The approved ADR template should be used to ensure consistency and completeness.</p>"},{"location":"design-authority/dhcw/architecture-decision-record-process/#when-to-create-an-adr","title":"When to Create an ADR","text":"<p>An ADR should be created for decisions that have a significant impact on the architecture of a system or the technical landscape of DHCW. The primary purpose is to capture the context and rationale behind important decisions for future reference and understanding.</p> <p>Generally, an ADR is justified when a decision:</p> <ul> <li>Affects the structure of a system or multiple systems.</li> <li>Requires coordination or consistency across different teams or projects.</li> <li>Impacts the long-term maintainability, scalability, security, or performance     of a system or service.</li> <li>Changes external interfaces or significant internal APIs.</li> <li>Would benefit future developers, architects, or stakeholders to understand     the \"why\" behind the decision.</li> </ul> <p>While the above guidelines cover many scenarios, an ADR is typically not required for:</p> <ul> <li>Decisions that do not fall into the category of \"Architecture\" (e.g.,     purely project management, administrative, or minor UI design choices).</li> <li>Trivial or routine activities with no lasting architectural impact.</li> <li>Decisions fully covered by existing, well-documented standards, policies,     or established patterns.</li> <li>Temporary workarounds, short-lived experiments, or proofs of concept     that are not intended to be permanent architectural components.</li> <li>Low-risk, self-contained decisions made by a single developer within a     project with no impact outside that immediate scope.</li> </ul>"},{"location":"design-authority/dhcw/architecture-decision-record-process/#initiation-and-commissioning","title":"Initiation and Commissioning","text":"<p>Prior to the creation of an ADR it is recommended that an Issue is raised in this GitHub repository outlining the need for a new ADR (or update to an existing one). This enables very early discussion around the potential ADR with minimal outlay and effort.</p> <p>Once the proposer wants to move forward with creating/updating an ADR, they are encouraged to use the standard Git/GitHub workflow and raise a Pull Request (PR) ahead of following the decision making process documented here.</p> Example Git Workflow <ul> <li>Clone this repository: <code>git clone git@github.com:GIGCymru/architecture.git</code></li> <li>Create a branch from <code>main</code> to work on (see Naming Conventions):   <code>git checkout main</code>, <code>git checkout -b adr-for-x</code></li> <li>Make the required changes (add/update files) in your editor of choice.   (note the template)</li> <li>Commit the changes: <code>git add changed-file.md</code>, <code>git commit -m \"Added new ADR for x\"</code></li> <li>Push the changes to GitHub <code>git push -u origin HEAD</code></li> <li>Raise a Pull Request on GitHub.com</li> </ul> <p>Notwithstanding the above guidance, the Technical Design Authority (TDA), Technical Design Assurance Group (TDAG), or other relevant governance bodies may commission the creation or update of an ADR in specific areas as needed.</p>"},{"location":"design-authority/dhcw/architecture-decision-record-process/#lifecycle-and-status","title":"Lifecycle and Status","text":"<p>Each ADR progresses through a lifecycle, and its current state is tracked using a defined status. This ensures clarity, traceability, and helps manage the relevance of decisions over time. The <code>Status</code> field in the ADR template must be updated to reflect the current state of the ADR.</p> <p>The defined statuses are:</p> <ul> <li>Proposed: The initial state of an ADR. It has been drafted and is     ready for discussion and review.</li> <li>Under Review: The ADR is actively being discussed and reviewed by     stakeholders (e.g. via a Pull Request for Level 1, or by a Temporary     Decision Group for Level 2+). This status indicates the ADR has moved     past the initial <code>Proposed</code> state and is undergoing evaluation before a     decision is reached.</li> <li>Accepted: The ADR has been approved by the relevant decision-making     process (e.g., consensus on a PR, TDG agreement). The decision     documented is now considered active and should be followed.</li> <li>Rejected: The proposed decision was reviewed but not approved. The ADR     is kept for the record of the discussion and outcome.</li> <li>Superseded: An <code>Accepted</code> ADR that has been replaced by a newer ADR.     The ADR should clearly indicate which ADR supersedes it.</li> <li>Deprecated: An <code>Accepted</code> ADR that is no longer considered relevant or     best practice. It might be phased out or archived but is not directly     replaced by a specific new ADR.</li> </ul> <p>The following diagram illustrates the typical lifecycle flow of an ADR:</p> <pre><code>stateDiagram-v2\n    accTitle: ADR Lifecycle State Diagram\n    accDescr: A diagram showing the various states and transitions for ADRs\n    [*] --&gt; Proposed\n    Proposed --&gt; Under_Review : Submitted for discussion / PR raised\n    Under_Review --&gt; Accepted : Consensus reached / Approved\n    Under_Review --&gt; Rejected : Not approved / Withdrawn\n    Accepted --&gt; Superseded : Replaced by new ADR\n    Accepted --&gt; Deprecated : No longer current best practice\n    Rejected --&gt; [*]\n    Superseded --&gt; [*]\n    Deprecated --&gt; [*]</code></pre>"},{"location":"design-authority/dhcw/architecture-decision-record-process/#quality-and-approval-criteria","title":"Quality and Approval Criteria","text":"<p>For an ADR to be considered \"good enough\" for approval and merging, it should meet a set of quality criteria. These criteria ensure that the decision is well-understood, justified, and provides sufficient context for future reference.</p> <p>The following checklist should be considered during the review of an ADR:</p> <ul> <li>Clear Problem Articulation: Is the problem statement, context, and the   driving factors behind the need for a decision clearly and concisely   described? (See the Summary and Drivers sections in the ADR template)</li> <li>Exploration of Alternatives: Have sufficient and relevant alternative   solutions been considered and documented? (See the Options section.)</li> <li>Documented Rationale and Trade-offs: Is the chosen solution clearly   stated, and is the rationale behind the decision well-justified? Are the   trade-offs (pros, cons, consequences) of the chosen solution and key   alternatives explicitly documented? (See the Options Analysis and   Recommendation sections.)</li> <li>Stakeholder Engagement: Has feedback from relevant stakeholders been   sought and incorporated, or is there a rationale if not?</li> <li>Sufficient Context and Linkages: Does the ADR include necessary   background information, references to related ADRs, issues (e.g., GitHub   issues), or other relevant documentation?</li> <li>Completeness and Clarity: Is the ADR well-written, easy to understand,   and does it adhere to the latest ADR template?</li> </ul> <p>It is the responsibility of the ADR proposer to strive to meet these criteria. During the review process (whether via a Pull Request for Level 1 decisions or within a Temporary Decision Group for higher levels), reviewers and TDG members are expected to assess the ADR against these quality criteria before recommending or granting approval.</p>"},{"location":"design-authority/dhcw/architecture-decision-record-process/#temporary-decision-groups-tdg","title":"Temporary Decision Groups (TDG)","text":"<p>Depending on the level of decision, it may require the formation of a Temporary Decision Group (TDG). This is a group of volunteers that will ideally have relevant expertise/experience in the topic area but also may just have an interest and desire to be involved in the ADR.</p> <p>When a TDG is utilised, any decision reached by the group is automatically accepted by the relevant assurance and governance committee.</p>"},{"location":"design-authority/dhcw/architecture-decision-record-process/#operations-and-decision-making","title":"Operations and Decision Making","text":"<p>Temporary Decision Groups (TDGs) are formed to collaboratively review and decide on ADRs, particularly for Level 2 and above. While open to interested volunteers, ensuring the group possesses the necessary domain expertise is crucial, especially for higher-level decisions (Level 3 and 4). The proposer (for Level 2/3) or the TDA (for Level 4) should actively seek participation from individuals with relevant knowledge and experience when forming the TDG. The governance body commissioning or reviewing the TDG composition is responsible for ensuring adequate expertise is represented.</p> <p>The primary goal of a TDG is to reach consensus on the proposed decision. Consensus means that all members can live with the decision, even if it wasn't their first choice, and support its implementation. Unanimous agreement is ideal but not always required; the aim is to avoid significant unresolved objections.</p> <p>Disagreements are expected and are a valuable part of the process. TDG members should engage in open discussion, present evidence, and explore alternatives to resolve conflicts. If consensus proves difficult to achieve after thorough discussion and exploration, the TDG should document the differing viewpoints and the reasons for the disagreement within the ADR.</p> <p>If a TDG is unable to reach a decision or resolve significant disagreements within the agreed timeframe, the matter should be escalated.</p> <ul> <li>For Level 2 and 3 decisions, the escalation path is back to the     Technical Design Assurance Group (TDAG). The TDG presents the     unresolved issues and differing viewpoints to the TDAG for guidance or     a final decision.</li> <li>For Level 4 decisions, the escalation path is back to the Technical     Design Authority (TDA), which commissioned the TDG.</li> </ul>"},{"location":"design-authority/dhcw/architecture-decision-record-process/#decision-levels","title":"Decision Levels","text":"<p>To ensure the ADR process is proportionate to the impact and scope of a decision, decisions are categorised into four levels:</p> <p>Note</p> <p>When determining the level, consider also how easily reversible the decision is (can it be easily stopped, omitted, or undone?) and how easily isolatable it is (can it run in parallel with similar decisions without interference?). Decisions that are hard to reverse and/or hard to isolate typically warrant a higher level due to increased risk and commitment.</p>"},{"location":"design-authority/dhcw/architecture-decision-record-process/#level-1-project-specific-decisions","title":"Level 1: Project-Specific Decisions","text":"<ul> <li>Scope: Primarily impacts a single project or a small, closely related   set of components within a project.</li> <li>Impact: Minimal impact outside the immediate project team.</li> <li>Characteristics: Often easily reversible and easily isolatable.   The commitment is typically low, allowing for quick trials and adjustments.</li> <li>Examples: Choice of a specific library within a project, minor   refactoring decisions, specific implementation details that don't affect   external interfaces or broader architectural patterns.</li> </ul>"},{"location":"design-authority/dhcw/architecture-decision-record-process/#level-2-cross-projectteam-decisions","title":"Level 2: Cross-Project/Team Decisions","text":"<ul> <li>Scope: Impacts multiple projects or teams, but not necessarily the entire   organisation.</li> <li>Impact: Requires coordination or consistency across several teams or   projects.</li> <li>Characteristics: May have varying degrees of reversibility and   isolatability. While potentially more complex to undo or run in parallel   than Level 1, they are generally less entangled than higher-level decisions.</li> <li>Examples: Standardising a specific tool or framework used by several   teams, decisions affecting shared services used by a subset of projects,   changes to internal APIs consumed by multiple teams.</li> </ul>"},{"location":"design-authority/dhcw/architecture-decision-record-process/#level-3-organisation-wide-decisions","title":"Level 3: Organisation-Wide Decisions","text":"<ul> <li>Scope: Impacts all projects, teams, or the entire organisation's technical   landscape.</li> <li>Impact: Requires broad consensus or mandates organisation-wide   standards or practices.</li> <li>Characteristics: Tend to be harder to reverse due to broad adoption   and significant impact if changed. They may also be harder to isolate   as they often establish organisation-wide standards or affect shared   infrastructure.</li> <li>Examples: Mandated programming languages, standard architectural   patterns for all new services, organisation-wide security policies   affecting technical implementation.</li> </ul>"},{"location":"design-authority/dhcw/architecture-decision-record-process/#level-4-majorsignificant-decisions","title":"Level 4: Major/Significant Decisions","text":"<ul> <li>Scope: Decisions with significant strategic, technical, or national-   level implications.</li> <li>Impact: High risk, high cost, or significant external visibility/   dependency. May involve external stakeholders or national standards.</li> <li>Characteristics: Typically hard to reverse and hard to isolate,   involving substantial commitment (e.g., financial, training, integration   effort). These demand the most rigorous review and careful consideration.</li> <li>Examples: Adoption of a major new cloud platform, significant changes   to core infrastructure, decisions impacting national data standards or   interoperability.</li> </ul>"},{"location":"design-authority/dhcw/architecture-decision-record-process/#process-by-level","title":"Process by Level","text":"<p>The process for reviewing and finalising an ADR varies by its defined level:</p>"},{"location":"design-authority/dhcw/architecture-decision-record-process/#level-1-project-specific-decisions-process","title":"Level 1: Project-Specific Decisions Process","text":"<ul> <li>Review Timeframe: A fixed review timeframe (default one week) is set   for the PR by the proposer and specified in the PRs description.</li> <li>Feedback: Team members and other relevant peers provide feedback via the   PR.</li> <li>Approval: The ADR is merged upon reaching consensus or at the end of the   review period if no major objections are raised.</li> <li>Notification: All Level 1 ADRs merged since the last Technical Design   Assurance Group (TDAG) meeting are added as 'below the line' submissions to   the TDAG agenda for information.</li> </ul>"},{"location":"design-authority/dhcw/architecture-decision-record-process/#level-2-cross-projectteam-decisions-process","title":"Level 2: Cross-Project/Team Decisions Process","text":"<ul> <li>Flagging: The proposer flags the ADR to the Technical Design   Assurance Group (TDAG) agenda as a Level 2 decision.</li> <li>TDG Formation: The proposer explains the ADR at the TDAG and requests   volunteers to form a TDG. The TDG must include at least two reviewers,   in addition to the proposer.</li> <li>Review Timeframe: The proposer, in consultation with the TDG, sets a   timeframe for discussion and review (default: two weeks).</li> <li>Decision: The TDG collaborates on the ADR and collectively makes the   decision.</li> <li>Notification: The finalised ADR and its decision are added to the next   TDAG agenda for information only.</li> </ul>"},{"location":"design-authority/dhcw/architecture-decision-record-process/#level-3-organisation-wide-decisions-process","title":"Level 3: Organisation-Wide Decisions Process","text":"<p>Level 3 decisions follow the same process as Level 2, but require five members (including the proposer) to form the TDG. In addition to submitting the agreed decision to TDAG for information, it is also submitted to the Technical Design Authority (TDA) agenda (below the line) for information only.</p>"},{"location":"design-authority/dhcw/architecture-decision-record-process/#level-4-majorsignificant-decisions-process","title":"Level 4: Major/Significant Decisions Process","text":"<p>Level 4 decisions follow the same process as Level 3 but the flagging and formation of the TDG is handled directly by TDA, bypassing TDAG, although the outcomes of decisions are shared with TDAG for information.</p>"},{"location":"design-authority/dhcw/architecture-decision-record-process/#roles-and-responsibilities","title":"Roles and Responsibilities","text":"<p>Clear roles and responsibilities are essential for the effective functioning of the ADR process. The following outlines key roles and their involvement:</p>"},{"location":"design-authority/dhcw/architecture-decision-record-process/#stewardship-and-maintenance","title":"Stewardship and Maintenance","text":"<p>The overall \"stewarding\" or \"librarianship\" of the ADRs, including the repository, process documentation, template, and ensuring consistency, falls under the remit of the ADR Steward. This role is expected to be a function within or designated by the Technical Design Assurance Group (TDAG) and/or Technical Design Authority (TDA).</p> <p>Once an ADR is Accepted:</p> <ul> <li>The decision it documents becomes a collective agreement.</li> <li>The ADR Proposer is typically the initial main author.</li> <li>Ongoing maintenance, such as identifying when an ADR might be outdated,     superseded, or deprecated, is a collective responsibility of the     architectural community.</li> <li>The ADR Steward, along with TDAG/TDA, will oversee the health of the     ADR log and may prompt reviews or updates as needed. Proposers of new,     related ADRs should also identify existing ADRs that may need to be     superseded.</li> </ul>"},{"location":"design-authority/dhcw/architecture-decision-record-process/#key-roles","title":"Key Roles","text":"Role Responsibility ADR Proposer Initiates an ADR, leads its development by drafting content and incorporating feedback. Presents the ADR to the relevant review body (e.g., via Pull Request, or to a TDG/TDAG/TDA). Responsible for ensuring the ADR meets quality criteria. TDG Chair (Often the ADR Proposer, or designated for Level 4 TDGs) Facilitates TDG discussions, ensures fair participation, helps track progress towards a decision, and may assist in summarizing the TDG's outcome and updating the ADR. TDG Members Actively participate in the evaluation, review, and decision-making for Level 2, 3, and 4 ADRs. Contribute expertise, challenge assumptions constructively, and help the TDG reach consensus on the decision. TDAG Facilitates TDG formation for Level 2 &amp; 3 ADRs. Acts as an escalation point for unresolved disagreements in Level 2 &amp; 3 TDGs. Reviews outcomes of Level 1, 2 &amp; 3 ADRs for information and process adherence. Can commission ADRs. Approves requests for private ADRs (Level 2 &amp; 3). Oversees the ADR process and supports the ADR Steward function. TDA Commissions and facilitates TDG formation for Level 4 ADRs. Acts as an escalation point for unresolved disagreements in Level 4 TDGs. Reviews outcomes of Level 3 &amp; 4 ADRs for information. Can commission ADRs. Approves requests for private ADRs (Level 4). Provides ultimate governance oversight for the ADR process and supports the ADR Steward function. ADR Steward (A function likely performed by TDAG/TDA secretariat or a designated individual/team) Owns the ADR repository structure and process documentation. Ensures ADR template compliance, consistency across ADRs, and manages the lifecycle metadata (e.g., status updates in the log). Assists in reporting on ADR activity."},{"location":"design-authority/dhcw/architecture-decision-record-process/#stages-activities-and-owners","title":"Stages, Activities and Owners","text":"Stage Activities Owner(s) 1. Pre-ADR Discussion Raise a GitHub Issue describing the problem or opportunity. ADR Proposer 2. Drafting the ADR Use template, outline problem, context, options. ADR Proposer 3. Assigning a Decision Level Determine decision level (1-4) based on scope/impact. ADR Proposer (reviewed by ADR Steward or TDAG) 4. Pull Request Creation Submit ADR draft as PR in the GitHub repo. ADR Proposer 5. TDG Formation (if Level \u22652) Identify and confirm volunteers, define TDG scope. ADR Proposer, with TDAG or TDA for Level 3/4 6. Review &amp; Collaboration Drive reviews, manage discussion, gather feedback. TDG Chair (or Proposer for Level 1) 7. Decision Making Reach consensus, capture rationale, finalise ADR. TDG (Chair facilitates), ADR Proposer 8. Approval &amp; Merge Merge PR, assign status (e.g. Approved), label by level ADR Proposer 9. Communication Add to TDAG/TDA agenda as needed, broadcast key decisions. TDAG &amp; TDA Coordinators 10. Lifecycle Management Monitor for relevance, deprecate outdated ADRs. ADR Steward"},{"location":"design-authority/dhcw/architecture-decision-record-process/#approval-authority","title":"Approval Authority","text":"<p>The primary role of TDAG and TDA in the context of ADRs that have been through a Temporary Decision Group (TDG) is one of oversight, process assurance, and handling escalations, rather than a direct re-approval or veto of a TDG's consensus decision.</p> <p>As stated in the \"Temporary Decision Groups (TDG)\" section, \"When a TDG is utilised, any decision reached by the group is automatically accepted by the relevant assurance and governance committee.\"</p> <p>TDAG/TDA members participate in TDGs relevant to their expertise, contributing to the consensus directly within that forum. Their \"approval\" authority is exercised through:</p> <ul> <li>Commissioning ADRs.</li> <li>Defining the scope and level of ADRs.</li> <li>Facilitating and ensuring the proper constitution of TDGs (especially         for Level 3 and 4).</li> <li>Acting as the escalation point if a TDG cannot reach consensus.</li> <li>Governing the overall ADR process itself.</li> <li>Approving exceptions, such as the private ADR process.</li> <li>For Level 1 ADRs (which do not use a TDG), the approval is by peer     consensus on the Pull Request, with TDAG reviewing for information.</li> </ul>"},{"location":"design-authority/dhcw/architecture-decision-record-process/#compliance-enforcement","title":"Compliance &amp; Enforcement","text":"<p>Beyond the ADR approval process, TDA and TDAG also play a key role in upholding the decisions documented in <code>Accepted</code> ADRs. Architectural designs and proposals submitted to TDA/TDAG for review are expected to align with these decisions.</p> <p>The ADR template includes a <code>Confirmation</code> section for proposers to articulate this alignment, justify any deviations, and to propose specific methods for confirming ongoing compliance with the decision.</p> <p>TDA and TDAG have the authority to challenge or reject submissions that do not adequately comply with, or justify deviations from, <code>Accepted</code> ADRs, thereby ensuring architectural consistency and adherence to accepted decisions.</p> <p>Teams need to be proactive in consulting the ADRs and using them as a living knowledge base of architectural decisions to inform designs and approaches.</p>"},{"location":"design-authority/dhcw/architecture-decision-record-process/#handling-sensitive-or-secure-adrs","title":"Handling Sensitive or Secure ADRs","text":"<p>The default is to collaborate on ADRs via the DHCW public GitHub repository, in the open.</p> <p>While ADRs are public by default to promote transparency, there are exceptional circumstances where the subject matter is highly sensitive (e.g., involving security vulnerabilities, confidential commercial information, or critical infrastructure details that should not be broadly disclosed).</p>"},{"location":"design-authority/dhcw/architecture-decision-record-process/#requesting-a-private-adr-process","title":"Requesting a Private ADR Process","text":"<p>If a proposed ADR topic is believed to be highly sensitive:</p> <ol> <li>The proposer must formally request an exception for private discussion     and restricted documentation from the Technical Design Authority (TDA)     or the Technical Design Assurance Group (TDAG) (depending on the     level of decision). This request should be made through appropriate internal     channels and should outline the nature of the sensitivity and why a private     process is necessary.</li> <li>The TDA/TDAG will review the request. Approval for a private process will     be granted if the justification for sensitivity is deemed valid.</li> </ol>"},{"location":"design-authority/dhcw/architecture-decision-record-process/#private-discussion-and-documentation","title":"Private Discussion and Documentation","text":"<p>If approved for a private process:</p> <ul> <li>Discussions will occur in a restricted forum, as determined and facilitated     by the TDA/TDAG (e.g., a private channel, dedicated secure meetings).</li> <li>An ADR will still be created using the standard template and will follow the     standard lifecycle (e.g., Proposed, Accepted).</li> <li>However, the ADR itself, containing sensitive details, will be stored in a     secure, access-controlled location designated by the TDA/TDAG, rather     than the public repository.</li> </ul>"},{"location":"design-authority/dhcw/architecture-decision-record-process/#transparency-of-outcome-for-private-adrs","title":"Transparency of Outcome for Private ADRs","text":"<p>To maintain a degree of transparency and traceability while protecting sensitive information a placeholder or summary ADR may be created in the public repository.</p> <p>This public-facing ADR would typically:</p> <ul> <li>Indicate that a decision on a sensitive topic has been made and recorded.</li> <li>State the ADR title (if the title itself is not sensitive).</li> <li>Provide a high-level, non-sensitive summary of the decision's scope or     impact, if possible and appropriate.</li> <li>Clearly state that the full details are restricted and stored in a     secure location due to sensitivity, referencing the approval from     TDA/TDAG.</li> <li>Link to the original generic public issue if one was created.</li> <li>The decision on whether to create a public placeholder/summary, and the     level of detail it contains, will be made by the TDA/TDAG, in     consultation with relevant security and information governance stakeholders.</li> <li>The existence of the decision and its status (e.g., Accepted) should still     be traceable through appropriate governance channels (TDA/TDAG records),     even if the full content is not publicly accessible.</li> </ul>"},{"location":"design-authority/dhcw/architecture-decision-record-process/#general-approach","title":"General Approach","text":"<p>The TDG (or the original proposer, for less complex ADRs) will conduct thorough research, analysis, and evaluation of potential solutions or options. This may involve:</p> <ul> <li>Gathering additional information and requirements.</li> <li>Evaluating different architectural patterns or technologies.</li> <li>Assessing the potential risks and benefits of each option.</li> <li>Developing prototypes or proof-of-concepts, if necessary.</li> </ul> <p>Throughout the development process, the TDG (or proposer) should actively seek feedback from relevant stakeholders, including other architects, developers, operations engineers, and business representatives. This feedback should be incorporated into the ADR document.</p>"},{"location":"design-authority/dhcw/architecture-decision-record-process/#appendix-adr-creation-workflow","title":"Appendix - ADR Creation Workflow","text":"<p>The following diagram illustrates the typical end-to-end process for creating and approving an ADR, from initial idea to a recorded decision.</p> <pre><code>graph TD\n    accTitle: ADR Workflow\n    accDescr: Flowchart showing the typical steps for proposing, developing, and deciding on an Architecture Decision Record.\n\n    Start([\"Start: Identify need for a new or updated ADR\"]) --&gt; Raise_GitHub_Issue(\"Optional: Raise GitHub Issue for Early Discussion\");\n    Raise_GitHub_Issue          --&gt; Is_Sensitive{\"Is ADR content expected to be **sensitive**?\"};\n\n    %% Private or Public ADR\n    Is_Sensitive        -- Yes  --&gt; Request_Private[\"Request private process from TDAG (Level 1-3) or TDA (Level 4)\"];\n    Is_Sensitive        -- No   --&gt; Process_Publicly;\n\n    Request_Private             --&gt; Private_Approval{\"Private Process Approved?\"};\n    Private_Approval    -- Yes  --&gt; Process_Privately[\"ADR Handled **Privately**: Secure discussion &amp; storage. **Optional** public placeholder on GitHub.\"];\n    Private_Approval    -- No   --&gt; Process_Publicly[\"ADR Handled **Publicly**: Open discussion, public storage via GitHub &amp; Pull Request process\"];\n    Process_Privately           --&gt; TDG_Decision{\"Decision Level?\"};\n    Process_Publicly            --&gt; TDG_Decision;\n\n    %% Level 1 Process\n    TDG_Decision        -- 'Level 1'    --&gt; Peer_Review_ADR[\"Proposer requests ADR Peer Review (default: 1 week)\"];\n    Peer_Review_ADR     --&gt; TDG_Consensus_Q\n\n    %% Level 2 - 4 Process\n    TDG_Decision        -- 'Level &gt;= 2' --&gt; Flag_TDAG_TDA[\"Flag to TDAG (Level 2 &amp; 3) or TDA (Level 4)\"];\n\n    Flag_TDAG_TDA --&gt; TDG_Formed[\"TDG Formed (Proposer + members, size / composition varies by level)\"];\n\n    TDG_Formed --&gt; TDG_Collaboration[\"TDG Collaborates, Reviews &amp; Seeks Consensus (default: 2 weeks)\"];\n\n    TDG_Collaboration --&gt; TDG_Consensus_Q{\"General Consensus on ADR?\"};\n    TDG_Consensus_Q -- Yes --&gt; Accept_Reject_ADR;\n    TDG_Consensus_Q -- No --&gt; Escalate[\"Escalate to TDAG (Level 1 - 3) or TDA (Level 4) for Resolution\"];\n    Escalate --&gt; TDAG_TDA_Decides[\"TDAG/TDA Makes Final Decision\"];\n    TDAG_TDA_Decides --&gt; Accept_Reject_ADR;\n\n    %% Finalise ADR\n    Accept_Reject_ADR[\"Update ADR Status (e.g., 'Accepted', 'Rejected') &amp; Merge Pull Request\"] --&gt; Notify_Governance[\"Notify TDAG (Level 1-3) and TDA (Level 4)\"];\n    Notify_Governance --&gt; End([\"End\"]);</code></pre>"},{"location":"design-authority/dhcw/meetings/2025-06-13/","title":"DHCW TDA 13/06/2025","text":""},{"location":"design-authority/dhcw/meetings/2025-06-13/#items","title":"Items","text":"Reference Item Outcome TDA-001 ADR Process for Approval Approved &amp; Action TDA-A003 TDA-002 Changes to Top Level Architecture Principles for Discussion Action TDA\u2013A001 TDA-003 Digital Products &amp; Software Engineering Principles for Approval To return for approval next TDA TDA-004 Enterprise Architecture Metamodel for Information N/A TDA-005 UCD Principles for Approval To return for approval next TDA AOB-1 NHS Wales DNS/Domains Discussion It was agreed this would need a lot more discussion and will be taken offline. AOB-2 TDA Comms/Output record keeping Action TDA-A002"},{"location":"design-authority/dhcw/meetings/2025-06-13/#actions","title":"Actions","text":"Ref Owner Description TDA-A001 IE/CC Identify key individuals to be involved in the top level architecture principles changes and schedule a session to discuss and review. TDA\u2013A002 RR/CC Share the outcomes and actions from TDA on the NHS Wales Architecture site going forward. TDA\u2013A003 RR/CC Create a plan for how to communicate and advertise the ADR process within DHCW"},{"location":"design-authority/dhcw/meetings/2025-07-25/","title":"DHCW TDA 25/07/2025","text":""},{"location":"design-authority/dhcw/meetings/2025-07-25/#previous-actions","title":"Previous Actions","text":"<p>See TDA 13/06/2025</p> Ref Owner Description Status TDA-A001 IE/CC Identify key individuals to be involved in the top level architecture principles \u2705 Done TDA\u2013A002 RR/CC Share the outcomes and actions from TDA on the NHS Wales Architecture site going \u2705 Done TDA\u2013A003 RR/CC Create a plan for how to communicate and advertise the ADR process within DHCW Ongoing"},{"location":"design-authority/dhcw/meetings/2025-07-25/#items","title":"Items","text":"Reference Item Outcome TDA-006 Update Terms of Reference\u200b Approved &amp; Action TDA-A004 TDA-007 Approval of Digital Products &amp; Software Engineering \u200bPrinciples Approved TDA-008 Approval of UCD Principles\u200b Approved TDA-009 Approval of revisions to Level 1 Architecture Principles\u200b Approved &amp; Actions TDA-A005, TDA-A006, TDA-A007, TDA-A008 TDA-010 Cloud Selection ADR\u200b Approved &amp; Action TDA-A009 TDA-011 Update on National Target Architecture \u200b N/A TDA-012 API Delivery Framework\u200b Action TDA-A010 TDA-013 Review of Clinical Principles\u200b Action TDA-A011"},{"location":"design-authority/dhcw/meetings/2025-07-25/#actions","title":"Actions","text":"Ref Owner Description TDA-A004 AJ/CC Update Terms of Reference\u200b to reflect updated membership TDA-A005 CC/GW/RR Incorporate system design and procurement implications for single source of truth principle TDA-A006 JH/RM Review policy for supported browser versions and implications, considering GOV.UK work in this area TDA-A007 CC Review order of top level architecture principles, moving start with user needs to the top etc. TDA-A008 CC/GW Propose an ADR for the use of FHIR before considering other healthcare standards for interoperability TDA-A009 CL Form a Temporary Decision Group (TDG) to develop an Architecture Decision Record (ADR) and framework for the selection of Cloud provider for products and services TDA-A010 RR Develop ways of working around API Delivery model for review TDA-A011 All Review Clinical Principles\u200b for approval an next TDA TDA-A012 CC Add Rationale and Implications to all principles for review TDA-A013 CC Undertake holistic review of all principles and propose changes to make cohesive for review"},{"location":"design-authority/dhcw/meetings/2025-09-05/","title":"DHCW TDA 05/09/2025","text":""},{"location":"design-authority/dhcw/meetings/2025-09-05/#previous-actions","title":"Previous Actions","text":"<p>See TDA 25/07/2025</p> Ref Owner Description Status TDA\u2013A003 RR/CC Create a plan for how to communicate and advertise the ADR process within DHCW Todo TDA-A004 AJ/CC Update Terms of Reference\u200b to reflect updated membership \u2705 Done TDA-A005 CC/GW/RR Incorporate system design and procurement implications for single source of truth principle In-Progress TDA-A006 JH/RM Review policy for supported browser versions and implications, considering GOV.UK work in this area \u2705 Done TDA-A007 CC Review order of top level architecture principles, moving start with user needs to the top etc. \u2705 Done TDA-A008 CC/GW Propose an ADR for the use of FHIR before considering other healthcare standards for interoperability Todo TDA-A009 CL Form a Temporary Decision Group (TDG) to develop an Architecture Decision Record (ADR) and framework for the selection of Cloud provider for products and services \u2705 Done TDA-A010 RR Develop ways of working around API Delivery model for review In-Progress TDA-A011 All Review Clinical Principles\u200b for approval an next TDA \u2705 Done TDA-A012 CC Add Rationale and Implications to all principles for review Todo TDA-A013 CC Undertake holistic review of all principles and propose changes to make cohesive for review Todo"},{"location":"design-authority/dhcw/meetings/2025-09-05/#items","title":"Items","text":"Reference Item Outcome TDA-014 Review Technical Debt Noted &amp; Action TDA-A014 TDA-015 Technical Design Assurance Group (TDAG) Report Noted TDA-016 Review of Clinical Principles\u200b Action TDA-A015 TDA-017 Update on Cloud Selection ADR\u200b Noted TDA-018 Auditing as a principle Action TDA-A016 TDA-019 Enterprise Tooling approval process discussion N/A"},{"location":"design-authority/dhcw/meetings/2025-09-05/#actions","title":"Actions","text":"Ref Owner Due Description TDA-A014 AVT/CC 26/09 Review tech debt tracking &amp; reporting TDA-A015 CC/SH 26/09 Review Clinical Principles after TDA feedback TDA-A016 CC/SH 03/10 Determine where to add clinical auditing to our principles"},{"location":"design-authority/dhcw/meetings/2025-10-17/","title":"DHCW TDA 17/10/2025","text":""},{"location":"design-authority/dhcw/meetings/2025-10-17/#previous-actions","title":"Previous Actions","text":"<p>See TDA 05/09/2025</p> Ref Owner Due Description Status TDA\u2013A003 RR/CC 17/10 Create a plan for how to communicate and advertise the ADR process within DHCW \u2705 Done TDA-A005 CC/GW/RR 17/10 Incorporate system design and procurement implications for single source of truth principle \u2705 Done TDA-A008 CC/GW 17/10 Propose an ADR for the use of FHIR before considering other healthcare standards for interoperability \u2705 Done TDA-A010 RR 17/10 Develop ways of working around API Delivery model for review \u2705 Done TDA-A012 CC 17/10 Add Rationale and Implications to all principles for review \u23f8\ufe0f On Hold TDA-A013 CC 17/10 Undertake holistic review of all principles and propose changes to make cohesive for review \u23f8\ufe0f On Hold TDA-A014 AVT/CC 26/09 Review tech debt tracking &amp; reporting \u2705 Done TDA-A015 CC/SH 26/09 Review Clinical Principles after TDA feedback \u2705 Done TDA-A016 CC/SH 03/10 Determine where to add clinical auditing to our principles \u2705 Done"},{"location":"design-authority/dhcw/meetings/2025-10-17/#items","title":"Items","text":"Reference Item Outcome TDA-020 Discuss Technical Debt Reporting Discussed TDA-021 Technical Design Assurance Group (TDAG) Report Noted TDA- Approve comms plan (TDA-A008) \u2705 Approved &amp; Action TDA-A021 &amp; 22 TDA-022 Governance &amp; Update of architecture principles in the wider NHS Wales context now that the DHCW principles are in the hands of the wider community.\u200b Action TDA-A019 TDA-023 National Target Architecture (NTA) Update\u200b Noted TDA-024 TDA-A008: ADR for the use of FHIR for interoperability \u2705 Approved TDA-025 Demo of Ardoq N/A TDA-026 DG&amp;S update N/A"},{"location":"design-authority/dhcw/meetings/2025-10-17/#actions","title":"Actions","text":"Ref Owner Due Description TDA-A017 CC 07/11 Propose a clear definition of \"architecture\" for ADR scope and share with the group. TDA-A018 CC 07/11 Clarify expectations around financial implications of architectural decisions in the process. TDA-A019 CC 07/11 Consider aligning ADR decision levels with architectural principle levels. TDA-A020 CC 07/11 Update and publish the agreed architecture principles on the public site. TDA-A021 CC/RR/ME 07/11 Refine and publish the approved architecture toolkit comms. TDA-A022 IE/SL/RH 07/11 Cascade the need to utilise the architecture toolkit (ADRs/AODs etc.) to staff TDA-A023 CC/AV 07/11 Work together to define and publish an agreed definition of technical debt."},{"location":"design-authority/dhcw/terms-of-reference/","title":"Terms of Reference","text":""},{"location":"design-authority/dhcw/terms-of-reference/#introduction","title":"Introduction","text":"<p>The DHCW Technical Design Authority (TDA) commissions, owns and steers the development of DHCW\u2019s Enterprise Architecture with the aim of ensuring alignment with the strategic objectives of the organisation and wider Health and Care policy and strategy.</p> <p>The TDA meets monthly for 90 minutes.</p>"},{"location":"design-authority/dhcw/terms-of-reference/#objectives","title":"Objectives","text":"<ul> <li>Establish the Enterprise Architecture (EA) including principles, standards, patterns, architecture descriptions, catalogues and roadmaps.</li> <li>Drive the adoption of agile, continuous, self-service delivery.</li> <li> <p>Commission and oversee TDA Working Groups in the production of EA artifacts including:</p> </li> <li> <p>Architecture principles, standards &amp; patterns</p> </li> <li>Reviewing roadmaps (e.g. platform &amp; product roadmaps)</li> <li>Architecture catalogues &amp; assessments</li> <li> <p>Architecture descriptions</p> </li> <li> <p>Through the Technical Design Assurance Group (TDAG), review and assure architecture &amp; design outputs.</p> </li> <li>Provide an escalation route to the Technical Design Assurance Group (TDAG).</li> <li>Advise DHCW Execs on digital threats and opportunities.</li> <li>Lead the design of digital technology foundations for DHCW</li> </ul>"},{"location":"design-authority/dhcw/terms-of-reference/#quorum","title":"Quorum","text":"<p>The following or delegates are required to be quorate:</p> <ul> <li>Executive Director of Strategy</li> <li>Executive Director of Operations</li> <li>Chief Product and Technology Officer</li> <li>Chief Data Officer</li> <li>Cyber Security</li> </ul> <p>In addition, specific domain leads (or delegates) are required to be quorate if a paper/submission is relevant to their domain. This will be determined by the chair.</p>"},{"location":"design-authority/dhcw/terms-of-reference/#scope","title":"Scope","text":"<p>In Scope\u200b:</p> <p>All architecture domains:</p> <ul> <li>Digital Workplace\u200b</li> <li>Digital Products &amp; Software Engineering\u200b</li> <li>Open Architecture &amp; Integration\u200b</li> <li>Data &amp; Analytics\u200b</li> <li>Security &amp; Identity\u200b</li> <li>Cloud &amp; Infrastructure</li> <li>User-Centred Design</li> <li>Clinical</li> </ul> <p>Out of Scope:</p> <ul> <li>Business change/readiness\u200b</li> <li>Project or programme governance\u200b</li> <li>Existing projects or solutions (other than major changes)\u200b</li> <li>Compliance</li> </ul>"},{"location":"design-authority/ea-metamodel/","title":"Introduction","text":"<p>Our Enterprise Architecture Metamodel provides a structured overview of the core component types and their relationships within our model.</p> <p>We are utilising a single shared instance of Ardoq to model the health and care architecture across NHS Wales.</p> <p>Our metamodel is derived from the Ardoq Use Case Solutions and customised the fit the context of NHS Wales. Any deviations from the Ardoq recommended metamodel are capture as metamodel decisions.</p>"},{"location":"design-authority/ea-metamodel/#decisions","title":"Decisions","text":"<p>Warning</p> <p>If a new decision/change is made to the metamodel ensure the metamodel diagram here is updated alongside the Gremlin query and associated report in Ardoq</p> <p>The following decisions have been made regarding the metamodel:</p> <ul> <li>Multiple Application Instances</li> </ul>"},{"location":"design-authority/ea-metamodel/#metamodel-diagram","title":"Metamodel Diagram","text":"<p>This is a high-level diagram of the metamodel to aid comprehension, it is a non-exhaustive view and therefore  doesn't capture every aspect of the model.</p> <pre><code>graph TD\n  accTitle: Enterprise Architecture Metamodel.\n  accDescr: A diagram showing a high level relationships between components in the enterprise architecture metamodel.\n  Business_Capability --&gt;|Is Realized By| Application\n  Technical_Capability --&gt;|Is Realized By| Application\n  Person --&gt;|Belongs To| Organization\n  Person --&gt;|Assigned To| Roles\n  Person --&gt;|Owns, Is Expert In| Application\n  Organisation --&gt;|Own, Supports, Supplies, Consumes| Application\n  External_Organisation --&gt;|Supplies| Application\n  Application --&gt;|Is Supported By| Database\n  Application --&gt;|Accesses / Connects To| Logical_Information\n  Application --&gt;|Connects To / Is Supported By / Depends On| Technology_Service\n  Infrastructure --&gt;|Is Supported By| Database\n  Database --&gt;|Is Located At| Locations\n  Technology_Services --&gt;|Is Supported By| Infrastructure</code></pre> <p>Tip</p> <p>See Mermaid Docs for more information on creating/editing these diagrams and the Mermaid Live Editor.</p>"},{"location":"design-authority/ea-metamodel/#metamodel-compliance-query","title":"Metamodel Compliance Query","text":"<p>A Gremlin query is maintained within Ardoq to produce a \"Metamodel Compliance\" report. It will identify any relationships between components that do not match the agreed metamodel (i.e. non-compliant 'source -&gt; reference -&gt; target' relationships).</p> <p>The source for this query is maintained within the <code>ea-metamodel-compliance.groovy</code> file of this repository, allowing for version control. The contents of the latest version of this query can be seen below:</p> ea-metamodel-compliance.groovy<pre><code>def validReferences = [\n  ['Business Capability', 'Is Realized By', 'Application'],\n  ['Business Capability', 'ardoq_parent', 'Business Capability'],\n  ['Technical Capability', 'Is Realized By', 'Application'],\n  ['Technical Capability', 'ardoq_parent', 'Technical Capability'],\n  //\n  ['Person', 'Is Expert In', 'Application'],\n  ['Person', 'Is Expert In', 'Business Capability'],\n  ['Person', 'Owns', 'Application'],\n  //\n  ['Organizational Unit', 'Consumes', 'Application'],\n  ['Organizational Unit', 'Consumes', 'Application Module'],\n  ['Organizational Unit', 'Supplies', 'Application'],\n  ['Organizational Unit', 'Supports', 'Application'],\n  ['Organizational Unit', 'Owns', 'Application'],\n  ['Organizational Unit', 'ardoq_parent', 'Organization'],\n  ['Organizational Unit', 'ardoq_parent', 'Organizational Unit'],\n  ['Organizational Unit', 'Partners With', 'Organizational Unit'],\n  //\n  ['Application Module', 'ardoq_parent', 'Application'],\n  ['Application', 'ardoq_parent', 'Application'],\n  ['Application', 'ardoq_parent', 'Application Group'],\n  ['Application', 'Has Successor', 'Application'],\n  ['Application', 'Connects To', 'Application'],\n  ['Application', 'Depends On', 'Application'],\n  ['Interface', 'ardoq_parent', 'Application'],\n  ['Interface', 'Connects To', 'Application']\n]\n\ndef isLegalReference = {\n  project('sourceType', 'type', 'targetType').\n    by(outV().label()).\n    by(label()).\n    by(inV().label()).\n  filter{\n    validReferences.any{ validReference -&gt;\n      validReference[0] == it.get()['sourceType'] &amp;&amp;\n      validReference[1] == it.get()['type'] &amp;&amp;\n      validReference[2] == it.get()['targetType']\n    }\n  }\n}\n\ng.V().\n  hasLabel('Application', 'Business Capability', 'Person', 'Organizational Unit').\n  bothE().\n  dedup().\n  not(isLegalReference()).\n  project('source', 'source type', 'reference', 'target', 'targetType type').\n    by(outV().values('name')).\n    by(outV().label()).\n    by(label()).\n    by(inV().values('name')).\n    by(inV().label())\n</code></pre>"},{"location":"design-authority/ea-metamodel/multiple-application-instances/","title":"Multiple Application Instances","text":"<p>Success</p> <p>Decision Made: 09/05/2025</p>"},{"location":"design-authority/ea-metamodel/multiple-application-instances/#decision-required","title":"Decision Required","text":"<p>How to represent multiple instances of an Application.</p>"},{"location":"design-authority/ea-metamodel/multiple-application-instances/#description","title":"Description","text":"<p>Where a Application has a separate instances for different consumers (e.g. each Health Board has its own instance of an Application ~ such as WelshPAS) we need a way to represent this.</p>"},{"location":"design-authority/ea-metamodel/multiple-application-instances/#decision","title":"Decision","text":"<p>There will be a 'generic' representation of the Application in the metamodel and each 'instance' of the Application will be represented as children with a descriptive identified added to the name e.g.</p>"},{"location":"design-authority/ea-metamodel/multiple-application-instances/#rationale","title":"Rationale","text":"<p>Whilst this adds complexity to the model and will lead to duplication it better represents the reality of the enterprise and the inherent complexity. In addition, it allows relationships that are specific to a particular instance to be modelled.</p>"},{"location":"design-authority/ea-metamodel/multiple-application-instances/#model-diagram","title":"Model Diagram","text":"<pre><code>graph TD\n  accTitle: Example WelshPAS Instances Model\n  accDescr: Shows an example of the parent/child relationship for WelshPAS where each Health Board has its own instance of the application.\n  WelshPAS --&gt; W1[\"WelshPAS [ABUHB]\"]\n  WelshPAS --&gt; W2[\"WelshPAS [BCUHB]\"]\n  WelshPAS --&gt; W3[\"WelshPAS [CTM]\"]\n  WelshPAS --&gt; W4[\"WelshPAS [...]\"]</code></pre>"},{"location":"principles/","title":"Architecture Principles","text":"<p>Architecture principles are fundamental rules and guidelines that inform and support the way we design and develop technology solutions across NHS Wales. They help ensure consistency, promote best practices, and align our technology decisions with organisational goals. They must be adopted when building and procuring technical solutions.</p> <p>Our principles are developed and approved by the DHCW Technical Design Authority (TDA).</p> <p>Principles apply across various contexts, technologies, and systems and are stable over time, even as specific technologies or situations change.</p> <p>Our principles help us make consistent choices when faced with new or ambiguous situations where detailed rules may not exist or apply. They provide a 'compass' rather than a detailed 'map'.</p> <p>To ensure that digital systems applications and services are aligned to health and care strategy, complying with these principles should form part of the governance for technical solutions, alongside architectural decision records and defined interoperability standards.</p> <p>The principles are a guide for decision making, there will be circumstances where a trade-off needs to be made between strict adherence with the principles and other considerations.</p> <p>The rationale for not complying with the principles should be documented, for example through an architectural decision record. To the greatest extent possible, there should be an understanding of the route to compliance, and a target timetable to compliance.</p> <p>These principles have been derived from the NHS England Architecture Principles January 2021 v4. They also reflect the Digital Service Standards for Wales published by the Centre for Digital Public Services.</p>"},{"location":"principles/#approved-principles","title":"Approved Principles","text":"<p>The following principles have been formally reviewed and approved by the DHCW Technical Design Authority (TDA):</p> <ul> <li>Architecture Principles - Our foundational   principles that guide all architectural decisions</li> <li>Cloud &amp; Infrastructure - Principles for   cloud adoption and infrastructure design</li> <li>Data &amp; Analytics - Guidelines for data   management, analytics, and insights</li> <li>Digital Products &amp; Software Engineering -   Best practices for building and maintaining digital products</li> <li>Digital Workplace - Principles for creating   effective digital working environments</li> <li>Open Architecture &amp; Integration - Guidelines for   creating interoperable and extensible systems</li> <li>Security &amp; Identity - Core security and   identity management principles</li> <li>User-Centred Design - Principles for creating   services that meet user needs</li> </ul>"},{"location":"principles/#principles-under-development","title":"Principles Under Development","text":"<p>The following principles are currently being developed and reviewed. While not yet formally approved, they provide valuable guidance in their respective areas:</p> <ul> <li>Clinical Principles - Guidelines for clinical systems   and healthcare technology</li> </ul>"},{"location":"principles/#using-these-principles","title":"Using These Principles","text":"<p>These principles should be:</p> <ul> <li>Referenced when making architectural decisions</li> <li>Used to evaluate proposed solutions</li> <li>Considered during system design and development</li> <li>Referenced in Architecture Decision Records (ADRs)</li> </ul> <p>If you need to deviate from these principles, document your rationale in an ADR and seek appropriate approval through the Governance Process.</p>"},{"location":"principles/#contributing","title":"Contributing","text":"<p>If you'd like to suggest changes to existing principles or propose new ones, please Create an Issue and raise your proposal through the appropriate channels.</p>"},{"location":"principles/architecture-principles/","title":"Architecture Principles","text":"<p>Approved</p> <p>These principles have been approved by the DHCW TDA</p>"},{"location":"principles/architecture-principles/#1-start-with-user-needs","title":"1. Start with User Needs","text":"<p>Digital services must be designed around the identified, evidence-based needs of their users.</p> <p>See also User Centred Design Principles.</p> Rationale <p>Building services based on a deep understanding of user needs is the most effective way to ensure they are adopted, deliver their intended benefits, and are easy to support. A user-centred approach reduces the risk of building the wrong thing, leading to better outcomes for patients and staff, and lower operational costs.</p> Implications <ul> <li>Teams must conduct user research continuously throughout the design,     development, and live operation of a service to ensure it continues to     meet user needs.</li> <li>The term \"user\" includes all consumers of a service. This includes     end-users of a graphical interface (e.g. patients, clinicians) as well     as technical users of an API (e.g. developers).</li> <li>All significant design and development decisions must be based on     evidence from user research.</li> <li>Teams must use feedback and data from live services to iterate and     improve the user experience.</li> </ul>"},{"location":"principles/architecture-principles/#2-design-for-change","title":"2. Design for Change","text":"<p>Digital services must be architected to be loosely coupled and highly cohesive, enabling them to evolve easily and safely over time.</p> <p>See also Digital Products and Software Engineering.</p> Rationale <p>Business, clinical, and technology requirements will inevitably change. Architectures that are rigid, monolithic, and tightly coupled make it difficult, risky, and expensive to respond to these changes.</p> <p>By designing systems that are modular with well-defined interfaces, we can isolate the impact of changes, reduce complexity, and enable teams to deliver new features and improvements independently and efficiently.</p> Implications <ul> <li>Services must be designed as modular components with single, well-defined     responsibilities. Communication between components must be via stable,     versioned APIs.</li> <li>Services should be configurable to handle variations in environment or     behaviour without requiring code changes and redeployment.</li> <li>A comprehensive suite of automated tests is essential to provide the     confidence needed to refactor and make changes safely.</li> <li>Automated CI/CD pipelines must be in place to make the process of testing     and deploying changes frequent, low-risk, and reliable.</li> <li>Significant architectural decisions and their trade-offs must be     documented in Architecture Decision Records (ADRs).</li> <li>Third-party dependencies must be carefully managed with a clear strategy     for updates to avoid technical debt and security vulnerabilities.</li> </ul>"},{"location":"principles/architecture-principles/#3-embed-security-and-privacy-by-design","title":"3. Embed Security and Privacy by Design","text":"<p>Security and privacy must be treated as core quality attributes, embedded throughout the entire service lifecycle from inception to decommissioning.</p> <p>See also Security and Identity Principles.</p> Rationale <p>To protect sensitive health and care data and maintain public trust, security cannot be an afterthought. By embedding security and privacy considerations into every stage of design and development, we build services that are secure by default.</p> <p>This proactive approach reduces the risk of data breaches and ensures compliance with legal obligations.</p> Implications <ul> <li>Users and systems must be granted the minimum level of access and     permissions necessary to perform their functions.</li> <li>Services must only collect, process, and retain the data that is     absolutely necessary for their specified and legitimate purpose.</li> <li>Teams must follow secure coding practices (e.g., OWASP Top 10), conduct     regular code reviews, and use tools to scan for vulnerabilities in code     and third-party dependencies.</li> <li>Security must be continuously validated through automated testing,      regular vulnerability scanning, and periodic penetration testing for     high-risk services.</li> <li>All services must demonstrate conformance with relevant data protection     and security standards on a continuous basis.</li> <li>All security-relevant events must be logged to a secure, immutable audit     trail to support monitoring, investigation, and incident response.</li> </ul>"},{"location":"principles/architecture-principles/#4-use-the-national-data-resource","title":"4. Use the National Data Resource","text":"<p>Services should read from and write to the National Data Resource, contributing to a single, comprehensive record for each citizen. This supports both longitudinal records and real-time pathways. Services should not use direct point-to-point integrations but instead exchange data through the National Data Resource.</p> <p>See also Data and Analytics Principles.</p> Rationale <p>Architectures based on point-to-point data integrations and data sharing are complex, brittle, and expensive to maintain. This principle avoids these issues by establishing the National Data Resource as a central hub for data exchange, removing the need for direct data messaging, copying and migrations between individual applications. This radically simplifies the landscape, ensuring that all services are working from a consistent, shared understanding of data. It removes ambiguity and reduces the clinical risk of decisions being made on stale or conflicting information.</p> <p>While applications retain stewardship and mastery of their own data, their mandatory, real-time synchronisation with the National Data Resource is what ensures consistency, quality, and clear provenance across the system. This model provides a complete, trustworthy view of patient information. Furthermore, because data is persisted in the shared record, it mitigates the clinical risk of information being unavailable if a source application goes offline. In principle, it also allows new, simpler applications to be developed that can use the shared record as their primary data layer.</p> Implications <ul> <li>Services must read data from the National Data Resource, treating it as a     source of truth, updating their internal data store as appropriate. </li> <li>Services must write data changes to the National Data Resource with     minimum delay, so that other services always have access to current     data. </li> <li>All interactions with the National Data Resource occur through versioned,     documented, and discoverable open APIs. Direct database access is     prohibited.</li> <li>Services should not share data directly with other services, because this     excludes other services, and will compromise the reference data layer\u2019s     integrity as a single source of truth.  </li> <li>This principle applies to any data that is relevant to another service. A     catalogue of these data must be maintained. Examples include, but are     not limited to:<ul> <li>Patient demographics</li> <li>Longitudinal patient record data (e.g. events, results, medications)</li> <li>Reference data (e.g. clinical terminologies)</li> <li>Practitioner and staff information</li> <li>Documents and medical images</li> </ul> </li> <li>Clear stewardship for each data entity must be established. The steward     is responsible for the quality, availability, and lifecycle management     of that data.</li> <li>Procurement processes for new systems must contractually mandate     compliance with this principle, ensuring any proposed solution will     integrate with the National Data Resource via the required APIs.</li> <li>Existing systems must have a clear roadmap to integrate fully with the     National Data Resource. </li> </ul>"},{"location":"principles/architecture-principles/#5-enable-interoperability-with-open-apis","title":"5. Enable Interoperability with Open APIs","text":"<p>All digital services must expose their data and functionality through well-defined, secure, and open APIs.</p> <p>See also Open Architecture &amp; Integration Principles.</p> Rationale <p>A modular architecture, where services communicate via open APIs, is essential for creating a flexible and innovative digital ecosystem. This approach prevents vendor lock-in, allows individual components to be replaced or upgraded without impacting the entire system, and fosters a competitive market where suppliers compete on quality.</p> <p>By making data and functionality programmatically accessible, we enable seamless integration and the creation of new, composite services that can better meet user needs.</p> Implications <ul> <li>Services must be designed with their API as the primary interface. The     API contract should be defined early in the development process.</li> <li>APIs must adhere to widely adopted open standards. E.g. For health data,     HL7 FHIR standards must be used where applicable.</li> <li>All APIs must be documented and published in a central API catalogue,     making them easy for other teams to find and consume.</li> <li>A clear API versioning strategy must be in place to allow for evolution     without breaking existing consumer applications.</li> <li>System-to-system integration must not use direct database connections,     shared file systems, or proprietary protocols. All integration must be     via the published APIs.</li> </ul>"},{"location":"principles/architecture-principles/#6-build-for-reuse-use-shared-platforms","title":"6. Build for Reuse, Use Shared Platforms","text":"<p>Digital services must reuse existing common platforms and components. New components must be built for reuse unless a clear exception is justified.</p> Rationale <p>Reusing proven platforms and components accelerates the delivery of new services, reduces the total cost of ownership, and improves consistency across the digital estate. It avoids the duplication of effort and the proliferation of solutions that solve the same problem in slightly different ways.</p> <p>When a suitable component does not exist, we must build new capabilities with reusability in mind. This fosters a collaborative engineering culture and ensures that our investment in building a new component provides value beyond a single project. This principle applies to both building new services and procuring third-party solutions.</p> Implications <ul> <li>Teams must first search for and evaluate existing common platforms or     components before starting new development. A central catalogue of     approved platforms and components must be maintained and consulted.</li> <li>Using an existing, approved platform is the default choice. A decision to     build a new component to solve a problem that is already addressed by     a common platform requires a documented exception (e.g. an ADR).</li> <li>Any new component or service that has the potential for reuse must be     built with a clear, versioned API, be well-documented, and be     independently deployable.</li> <li>Every common platform and component must have a clear owner and a     defined support model to manage its lifecycle, including maintenance,     versioning, and eventual retirement.</li> <li>There must be a clear process for teams to contribute improvements and     bug fixes back to the common platforms and components they use.</li> </ul>"},{"location":"principles/architecture-principles/#7-deliver-sustainable-services","title":"7. Deliver Sustainable Services","text":"<p>Digital services must be designed, delivered, and operated in a financially, technically, and environmentally sustainable manner throughout their entire lifecycle.</p> Rationale <p>To ensure long-term value and responsible use of public resources, services cannot be built with only short-term goals in mind. A sustainable approach considers the total cost of ownership, the long-term health of the technical solution, and its environmental impact.</p> <p>This holistic view prevents the creation of services that become prohibitively expensive to run, impossible to maintain due to technical debt, or misaligned with our environmental responsibilities. </p> Implications <p>Financial sustainability</p> <ul> <li>Whole-life cost models must be developed during service design, covering     development, hosting, support, and eventual decommissioning. </li> <li>Operational funding for services must be identified and secured beyond     any initial project funding.</li> <li>Cloud services must be managed using FinOps best practices to control and     optimise costs.</li> </ul> <p>Technical sustainability</p> <ul> <li>Technology choices must be supportable and maintainable for the expected     life of the service, considering skills availability and vendor     viability.</li> <li>Technical debt must be actively managed, tracked, and addressed as part     of the development lifecycle.</li> <li>A clear strategy for dependency management, patching, and component     obsolescence must be in place.</li> </ul> <p>Environmental sustainability</p> <ul> <li>Design choices should favour resource efficiency (e.g. efficient code,     optimised data storage, appropriate scaling).</li> <li>Where possible, leverage cloud provider tools to measure, report on, and     reduce the carbon footprint of services.</li> <li>Procurement of hardware and services should consider the environmental     impact of the entire supply chain.</li> </ul>"},{"location":"principles/architecture-principles/#8-public-cloud-first","title":"8. Public Cloud First","text":"<p>Public cloud is the default hosting environment for all new and modernised digital services. Any alternative deployment model requires a documented and approved exception.</p> <p>See also Cloud and Infrastructure Principles.</p> Rationale <p>Leveraging public cloud services accelerates the delivery of value by providing on-demand access to scalable, resilient, and secure infrastructure. This approach allows teams to focus on developing user-centric services rather than managing underlying hardware. The public cloud offers significant advantages in agility, cost-effectiveness, and access to a wide range of modern, managed services. This principle supports our goals for sustainability and operational excellence.</p> Implications <ul> <li>All new services must be designed and built to run on a public cloud     platform. Modernisation of existing services should include a plan for     cloud migration.</li> <li>A decision to host a service outside of the public cloud must be     justified and documented in an Architecture Decision Record (ADR),     citing specific technical, security, or legislative constraints that     cannot be met by available cloud offerings.</li> <li>To mitigate vendor lock-in, services should be designed with portability     in mind. Favour cloud-agnostic technologies like containers and     standard open-source software. The use of provider-specific services     that are not easily portable must be a conscious trade-off, justified     by significant value.</li> <li>Teams must adopt practices for monitoring, managing, and optimising cloud     costs. Budgets must be planned for operational expenditure models.</li> <li>A commitment to developing and maintaining cloud engineering, security,     and architecture skills within teams is required. </li> <li>Teams must understand and operate within the shared responsibility model     for security in the cloud, implementing appropriate controls for     identity, access, network, and data protection.</li> </ul>"},{"location":"principles/architecture-principles/#9-build-for-modern-browsers","title":"9. Build for Modern Browsers","text":"<p>User-facing digital services must be browser-based, responsive, and compliant with current web and accessibility standards.</p> <p>See also User Centred Design Principles.</p> Rationale <p>Building services for the web is the most effective way to ensure they are accessible to the widest possible audience, regardless of their device or operating system. This approach eliminates the significant cost, time, and complexity associated with developing, distributing, and maintaining separate native applications for different platforms.</p> <p>A single, responsive, standards-compliant web application simplifies deployment, reduces support overhead, and allows teams to leverage the robust security, accessibility, and performance features inherent in modern evergreen browsers. It ensures a consistent user experience and means users can access services instantly without needing to install anything.</p> Implications <ul> <li>Native mobile or desktop applications will not be built unless a specific,     compelling user need is identified that cannot be met by a web     application. This requires a documented exception.</li> <li>User interfaces must be fully responsive, providing a functional and     intuitive experience on all common device sizes, from mobile phones to     large desktop monitors.</li> <li>All services must comply with Web Content Accessibility Guidelines.</li> <li>Services must be tested and functional on the latest versions of all     modern, evergreen browsers (e.g., Chrome, Firefox, Edge, Safari).     Support for older, non-evergreen browsers (like Internet Explorer) is     not required.</li> <li>Solutions must not rely on browser plugins or extensions.</li> </ul>"},{"location":"principles/architecture-principles/#10-design-for-public-internet","title":"10. Design for Public Internet","text":"<p>Digital services must be built using modern, open, and widely adopted internet standards and protocols.</p> Rationale <p>Building services that are capable of being safely and securely deployed over the public internet is a foundational goal. Adhering to modern internet standards (like HTTPS, TLS 1.2+, REST, OAuth 2.0, OpenID Connect) ensures services are secure, resilient, and interoperable by default.</p> <p>This approach avoids vendor lock-in from proprietary protocols, simplifies integration between different systems, and allows services to be accessed from a wide range of standard devices without special software or network configurations. It provides the architectural flexibility to choose the most optimal and cost-effective deployment model, whether on-premises or in the public cloud, without being constrained by private network dependencies.</p> Implications <ul> <li>Services must be designed to operate securely over the public internet.     Dependencies on private networks should be for specific, justified     use-cases and not the default assumption.</li> <li>All data-in-transit must be encrypted using current, recommended versions     of TLS. APIs should be exposed over HTTPS, following RESTful principles     or other modern API standards.</li> <li>User and system authentication / authorisation should leverage open     standards like OAuth 2.0 and OpenID Connect.</li> <li>When procuring or commissioning new services, there must     be a requirement for adherence to open internet standards, avoiding     solutions that mandate proprietary clients or protocols.</li> <li>Existing systems that do not conform must have a clear roadmap for     modernisation or be fronted by a standards-compliant API gateway or     facade.</li> </ul>"},{"location":"principles/clinical/","title":"Clinical Principles","text":"<p>Warning</p> <p>These principles are not yet approved by the DHCW TDA</p> <p>These principles have been developed by Digital Health and Care Wales (DHCW) Clinical Design Principles Working group who report to the DHCW Technical Design Authority (TDA). The principles are owned by the DHCW Executive Medical Director/CCIO Wales and maintained by the Associate Director of Clinical Informatics Professionals &amp; Business Change in collaboration with the DHCW Clinical Design Principles Working Group.</p> <p>A principle is a guideline which supports consistent clinical design decisions and delivery. These principles are a guide for decision making by Service Owners, Product Owners and Clinical Informatics professionals.</p> <p>To ensure that digital products and services comply with these principles, the principles should form part of the governance for their release.</p> <p>There may be rare circumstances where a trade-off needs to be made between strict adherence with the principles and other considerations. The rationale for not complying with the principles should be documented. To the greatest extent possible, there should be an understanding of the route to compliance, and a target timetable to compliance.</p> <p>These principles reflect:</p> <ul> <li>NHS Design Principles</li> <li>Government Design Principles - GOV.UK</li> <li>Digital Service Standards for Wales</li> <li>NHS Service Standard</li> <li>Health &amp; Care Quality Standards 2023</li> <li>UK Regulation of Medical Devices</li> <li>Clinical Safety Standards DCB0129 and DCB0160 (Wales equivalent TBC)</li> <li>DHCW Clinical Informatics Framework</li> </ul>"},{"location":"principles/clinical/#1-design-with-the-clinical-voice","title":"1. Design with the Clinical Voice","text":"<p>Description: Involve clinicians at all stages of the discovery and design process to ensure practical and effective solutions.</p> <p>Rationale: Ensures that designs are grounded in clinical expertise and real-world application.</p> <p>Result: Solutions that are more Useful, Usable and Used as aligned with clinical workflow.</p>"},{"location":"principles/clinical/#2-design-for-safer-care","title":"2. Design for Safer Care","text":"<p>Description: Ensure digital health technologies are safer and trusted by users and patients.</p> <p>Rationale: Compliance with clinical professional and regulatory standards including clinical safety standards and medical device regulations.</p> <p>Result: Enhanced patient safety and reduced incidence of digital-related safety issues.</p>"},{"location":"principles/clinical/#3-design-together-for-wales","title":"3. Design Together for Wales","text":"<p>Description: Develop solutions that can be used across the entire NHS Wales system.</p> <p>Rationale: Reduces unwarranted variation and duplication, ensuring consistency.</p> <p>Result: More efficient use of resources and consistent UX across Wales.</p>"},{"location":"principles/clinical/#4-design-for-clinical-value","title":"4. Design for Clinical Value","text":"<p>Description: Design to provide tangible clinical benefits to patients and healthcare providers.</p> <p>Rationale: Focuses on improving clinical outcomes and enhancing the quality of care.</p> <p>Result: Improved clinical outcomes and higher quality of care for patients.</p>"},{"location":"principles/clinical/#5-design-for-data-driven-care","title":"5. Design for Data Driven Care","text":"<p>Description: Ensure that solutions are designed to Collect, Store and Share structured clinical data through the Care Data Repository (CDR).</p> <p>Rationale: The CDR is a foundational component of the national digital architecture, supporting safer, more informed decision making.</p> <p>Result: Improved data quality and enhanced clinical insights that supports better outcomes for patients and more efficient service delivery.</p>"},{"location":"principles/clinical/#glossary","title":"Glossary","text":"Term Definition Clinical benefit A positive, clinical meaningful effect of an intervention on a patient\u2019s health. Clinical safety Specifically pertains to the safety of clinical systems and technologies used within healthcare Clinical voice The voice of frontline clinicians delivering healthcare Clinical workflows The systematic processes and interactions that guide the delivery of healthcare, encompassing all tasks and steps performed by staff and patients. Clinician Someone qualified in an area of very skilled health work Health &amp; care Encompasses a broad range of services aimed at maintaining and improving overall health and well-being. Health outcome The effect or result of an intervention, condition or event on an individual\u2019s health or well-being. Patient safety The prevention of errors, injuries, accidents, and other adverse events that may occur during healthcare delivery. Real-world application The practical use of a concept, skill, or technology in real-life situations. User experience (UX) The overall experience a person has when interacting with a product, system, or service."},{"location":"principles/cloud-and-infrastructure/","title":"Cloud and Infrastructure Principles","text":"<p>Approved</p> <p>These principles have been approved by the DHCW TDA</p>"},{"location":"principles/cloud-and-infrastructure/#multi-cloud","title":"Multi Cloud","text":"<p>For SaaS solutions and specialist PaaS services, we will choose our provider based on analysis of capabilities in the marketplace. For IaaS and generic PaaS deployments we will identify a single provider of these services.</p>"},{"location":"principles/cloud-and-infrastructure/#make-security-easy-to-adopt","title":"Make security easy to adopt","text":"<p>Common security tooling and monitoring to be implemented for all clouds. We will build the underpinning cloud security infrastructure and monitoring systems, so that these are available for everyone to use. Technical solutions (guardrails/policies) will be implemented to reduce risk of user error when configuring cloud services.</p>"},{"location":"principles/cloud-and-infrastructure/#design-for-portability","title":"Design for portability","text":"<p>Design for portability and avoid vendor lock-in unless there is compelling case for doing so.</p>"},{"location":"principles/cloud-and-infrastructure/#design-for-self-service","title":"Design for self-service","text":"<p>Leverage automation for infrastructure deployment, configuration management, and testing. Utilise Infrastructure as Code (IaC) practices and continuous integration/continuous deployment (CI/CD) pipelines. Self-service should be adopted where possible.</p>"},{"location":"principles/cloud-and-infrastructure/#keep-the-network-simple-resilient-and-reliable","title":"Keep the network simple, resilient and reliable","text":"<p>The network systems should be kept as simple as possible with a focus on reliability and availability, even during periods of planned maintenance.</p>"},{"location":"principles/cloud-and-infrastructure/#optimise-cloud-benefits","title":"Optimise cloud benefits","text":"<p>Maximise the benefits of using the cloud. Utilise the cloud services that deliver most value to the organisation. Select the most optimum service model (SaaS, FaaS, PaaS, IaaS, etc). Offload management overhead where possible.</p>"},{"location":"principles/cloud-and-infrastructure/#design-for-elasticity-and-cost-optimisation","title":"Design for elasticity and cost optimisation","text":"<p>Design for efficiency and cost minimisation \u2013 lever the elasticity of cloud services.</p>"},{"location":"principles/cloud-and-infrastructure/#design-for-reliability","title":"Design for reliability","text":"<p>Design for high-availability, resilience, data protection and disaster recovery. Follow best practices and patterns available from the relevant cloud provider.</p>"},{"location":"principles/cloud-and-infrastructure/#design-for-performance","title":"Design for performance","text":"<p>Design applications and infrastructure to ensure that they meet user response time expectations and can grow and adapt to changes in demand.</p>"},{"location":"principles/cloud-and-infrastructure/#consider-open-source-first","title":"Consider open-source first","text":"<p>Optimise use of Open-Source vs Proprietary products. Choose the most economically advantageous solution.</p>"},{"location":"principles/cloud-and-infrastructure/#simplify-and-standardise","title":"Simplify and standardise","text":"<p>Avoid technology sprawl. Balance the supportability implications of technology choices with the benefits of using unfamiliar technologies.</p>"},{"location":"principles/data-and-analytics/","title":"Data &amp; Analytics Principles","text":"<p>Approved</p> <p>These principles have been approved by the DHCW TDA</p>"},{"location":"principles/data-and-analytics/#data-is-captured-once-and-reused","title":"Data is captured once and reused","text":"<p>Data is captured once and reused refers to the practice of collecting patient information (such as medical history, test results, and treatment plans) during an initial encounter and then using that data throughout the patient\u2019s care journey. This approach aims to improve efficiency, reduce duplication, and enhance continuity of care.</p>"},{"location":"principles/data-and-analytics/#data-is-semantically-interoperable","title":"Data is semantically interoperable","text":"<p>Data is not only syntactically consistent (i.e. formatted correctly) but also semantically consistent. Different systems can understand and interpret the data in the same way because the data carries the same meaning across systems. For example, a diagnosis code or a medication name will be interpreted correctly regardless of the system accessing it.</p>"},{"location":"principles/data-and-analytics/#data-for-analytical-use-is-not-an-after-thought","title":"Data for analytical use is not an after thought","text":"<p>Secondary uses of data is integral to the design of any new applications. Publishing data to analytical stores must be included prior to deployment.</p>"},{"location":"principles/data-and-analytics/#data-is-secured","title":"Data is secured","text":"<p>Data is compliant with security, regulatory and privacy requirements. Appropriate measures have been implemented to protect it from unauthorised access, disclosure, alteration, or destruction. Data security involves safeguarding sensitive information and ensuring its confidentiality, integrity, and availability.</p> <p>This can be achieved through various technical, organisational, and procedural controls, such as encryption, access controls, authentication mechanisms, data backups, and security monitoring. Effective data security practices aim to mitigate risks associated with data breaches, cyber attacks, insider threats, and other security vulnerabilities, thereby safeguarding the privacy, trust, and reputation of individuals and organisations.</p>"},{"location":"principles/data-and-analytics/#data-is-findable-accessible-and-well-described","title":"Data is findable, accessible and well described","text":"<p>Data should be easy to find for both humans and computers. These data should be well described through comprehensive metadata and should include metrics relating to data quality and coverage. Data should be easily discoverable, available for authorised users, and accompanied by detailed documentation that enhances its understanding and usability.</p>"},{"location":"principles/data-and-analytics/#data-is-high-quality","title":"Data is high quality","text":"<p>Data quality is monitored and reported. High-quality data serves as a reliable foundation for analysis, decision-making, and insights generation. It instils confidence in the results derived from data-driven processes and provides the opportunity to derive maximum value from data assets.</p>"},{"location":"principles/digital-products-and-software-engineering/","title":"Digital Products &amp; Software Engineering Principles","text":"<p>Approved</p> <p>These principles have been approved by the DHCW TDA</p>"},{"location":"principles/digital-products-and-software-engineering/#introduction","title":"Introduction","text":"<p>These principles guide the design, development, delivery, and lifecycle management of digital products and software. They operate within the framework set by the overarching Architecture Principles and aim to ensure that our digital solutions are valuable, user-focused, high-quality, sustainable, and aligned with strategic objectives.</p>"},{"location":"principles/digital-products-and-software-engineering/#deliver-measurable-value-continuously","title":"Deliver Measurable Value Continuously","text":"<p>Digital products and software must demonstrably meet user needs and organisational strategic objectives. Development efforts should prioritise features that deliver the highest value, released iteratively to enable rapid feedback and adaptation.</p> Rationale <p>Focusing on continuous value delivery ensures that resources are applied effectively, benefits are realised sooner, and products evolve in line with changing requirements and priorities within the dynamic health and care landscape.</p> Implications <ul> <li>Adopt agile and lean methodologies (e.g., Scrum, Kanban) for product     development and delivery.</li> <li>Define clear value propositions, key performance indicators (KPIs), and     success metrics for all digital initiatives.</li> <li>Prioritise backlogs based on value, risk, learning opportunities, and     dependencies.</li> <li>Embrace frequent, small, and incremental releases to gather feedback     and deliver value early.</li> <li>Establish robust feedback loops with users, clinicians, and     stakeholders throughout the product lifecycle.</li> <li>Product roadmaps are living documents, regularly reviewed and adjusted     based on feedback and value realisation.</li> </ul>"},{"location":"principles/digital-products-and-software-engineering/#user-needs-drive-product-evolution","title":"User Needs Drive Product Evolution","text":"<p>The ongoing development and evolution of digital products must be guided by a deep and empathetic understanding of user needs, behaviours, workflows, and feedback within the specific context of health and care in Wales.</p> Rationale <p>While (User-Centred Design principles](../user-centred-design/index.md) focus on the how of designing for users, this principle emphasises that what we build and how it evolves is continuously validated against real user requirements to ensure fitness for purpose and positive impact on health and care outcomes.</p> Implications <ul> <li>Integrate user research (e.g., interviews, observations, surveys) and     usability testing as continuous activities throughout the product     lifecycle.</li> <li>Develop and maintain clear user personas, user stories, and journey maps     relevant to Welsh health and care pathways.</li> <li>Utilise data analytics and user feedback mechanisms to understand user     behaviour, identify pain points, and measure satisfaction.</li> <li>Product backlogs and feature development are directly informed and     prioritised by validated user needs and evidence from diverse user     groups.</li> <li>Ensure services are simple to use, accessible, and inclusive, meeting     relevant standards and supporting both Welsh and English languages.</li> </ul>"},{"location":"principles/digital-products-and-software-engineering/#engineer-for-quality-resilience-and-maintainability","title":"Engineer for Quality, Resilience, and Maintainability","text":"<p>Software must be robust, secure, performant, and easy to maintain and evolve over its lifecycle to ensure long-term viability, minimise technical debt, and reduce the total cost of ownership, which is especially critical for systems supporting health and care services.</p> Rationale <p>High-quality engineering practices lead to more reliable, secure, and adaptable systems that can better respond to future needs without excessive rework or risk.</p> Implications <ul> <li>Adhere to approved coding standards, architectural patterns, and software     development best practices.</li> <li>Implement comprehensive and automated testing strategies, including unit,     integration, contract, performance, and security testing.</li> <li>Conduct regular, constructive code reviews and proactive refactoring to     improve code quality and manage technical debt.</li> <li>Design for modularity, loose coupling, and high cohesion to facilitate     independent development, deployment, and scalability of components.</li> <li>Embed security considerations throughout the software development     lifecycle (DevSecOps), aligning with Security &amp; Identity principles.</li> <li>Apply rigorous clinical risk management throughout the software lifecycle     for any product with potential clinical impact, adhering to relevant      clinical safety standards and regulatory requirements.</li> <li>Ensure systems are designed for observability (comprehensive logging,     monitoring, tracing, and alerting) to support operational stability and     rapid issue resolution.</li> <li>Strive for resource-efficient software design and implementation to     minimise environmental impact, aligning with sustainability goals.</li> <li>Document software architecture and design decisions clearly and keep      documentation up-to-date.</li> </ul>"},{"location":"principles/digital-products-and-software-engineering/#embrace-agile-and-devops-culture-and-practices","title":"Embrace Agile and DevOps Culture and Practices","text":"<p>Foster a collaborative, communicative, and continuously improving culture, supported by DevOps practices, to enable rapid, reliable, and sustainable delivery of high-quality digital products and software.</p> Rationale <p>An agile and DevOps approach breaks down silos, improves flow, automates processes, and empowers teams, leading to faster delivery cycles, higher quality, increased innovation, and better responsiveness to evolving needs.</p> Implications <ul> <li>Promote the formation of empowered, cross-functional teams with shared     ownership and accountability.</li> <li>Implement robust CI/CD pipelines to automate build, testing, and     deployment processes.</li> <li>Encourage open communication, knowledge sharing, and collaborative     problem-solving within and between teams.</li> <li>Leverage endorsed collaboration tools and platforms to enhance teamwork     and knowledge sharing, in alignment with Digital Workplace principles     where applicable.</li> <li>Adopt \"you build it, you run it\" philosophies where appropriate, with     teams taking responsibility for the operational support of their     services.</li> <li>Conduct regular retrospectives and experiments to continuously learn,     adapt, and improve processes, tools, and team practices.</li> <li>Champion psychological safety to encourage experimentation and learning     from failures.</li> </ul>"},{"location":"principles/digital-products-and-software-engineering/#leverage-reusability-and-promote-interoperability","title":"Leverage Reusability and Promote Interoperability","text":"<p>Maximise efficiency, consistency, and integration capabilities by identifying, creating, and utilising common components, services, platforms, and data standards. Design systems to interoperate seamlessly within the ecosystem and with authorised external systems.</p> Rationale <p>Reusability reduces duplication of effort, accelerates delivery, and lowers costs. Interoperability is fundamental for a connected health and care system, enabling data to flow securely and efficiently where it's needed.</p> Implications <ul> <li>Prioritise the use of existing approved platforms, APIs, shared services,     and common libraries.</li> <li>Develop new components and services with reusability and clear interface     contracts (e.g. APIs) in mind.</li> <li>Adhere to established national and international interoperability     standards relevant to health and care (e.g., HL7 FHIR, openEHR where     appropriate).</li> <li>Maintain and contribute to a catalogue of reusable assets, APIs, and data     models.</li> <li>Employ API-first design strategies to facilitate integration and enable a     composable enterprise.</li> <li>Ensure data is exchanged using agreed-upon formats and semantics,     aligning with Data &amp; Analytics principles.</li> </ul>"},{"location":"principles/digital-products-and-software-engineering/#make-data-informed-product-and-technical-decisions","title":"Make Data-Informed Product and Technical Decisions","text":"<p>Product strategies, feature prioritisation, architectural choices, and engineering improvements should be guided by objective data and evidence, rather than solely by assumptions or opinions.</p> Rationale <p>Using data to inform decisions reduces risk, helps to validate hypotheses, optimises resource allocation, and ensures that efforts are focused on areas that will yield the most significant impact for users.</p> Implications <ul> <li>Instrument applications and systems to collect relevant operational data,     user analytics, and performance metrics.</li> <li>Establish and monitor Key Performance Indicators (KPIs) and Service Level     Objectives (SLOs) for digital products and services.</li> <li>Regularly analyze collected data to identify trends, insights, user     behaviours, system bottlenecks, and areas for improvement.</li> <li>Utilize A/B testing, canary releases, and other experimentation     techniques to validate changes and guide product evolution where     appropriate.</li> <li>Ensure that data used for decision-making is accurate, timely, and     relevant, and that its collection and use comply with data privacy and     governance policies.</li> </ul>"},{"location":"principles/digital-products-and-software-engineering/#manage-technology-pragmatically-and-sustainably","title":"Manage Technology Pragmatically and Sustainably","text":"<p>Technology choices must be driven by fitness for purpose, long-term sustainability, alignment with the strategic technology roadmap, security requirements, and total cost of ownership, rather than by novelty or individual preference.</p> Rationale <p>Pragmatic technology management ensures that we invest in solutions that are supportable, scalable, secure, and cost-effective over their intended lifespan, minimising risks associated with obsolescence or niche skill dependencies, and aligning with overarching Architecture Principles.</p> Implications <ul> <li>Follow a \"reuse before buy, buy before build\" approach: prioritise     reusing existing or publicly available solutions (including open source     with appropriate support), then consider acquiring commercial     off-the-shelf products, before commissioning new bespoke development,      as guided by Architecture Principles.</li> <li>Evaluate technologies using clear criteria, including maturity,     community/vendor support, security posture, scalability, performance,     interoperability, skills availability, and alignment with existing     technology stacks.</li> <li>Favor proven technologies, open standards, and solutions that align with     the Cloud &amp; Infrastructure principles.</li> <li>Proactively manage technical debt: identify, prioritise, and address it     systematically.</li> <li>Consider the full lifecycle implications of technology choices, including     development, deployment, operations, maintenance, and eventual     decommissioning.</li> <li>Maintain a clear technology radar and roadmap, regularly reviewing and     updating it based on our evolving needs and the technology landscape.</li> <li>Ensure that skills and knowledge for chosen technologies are developed     and maintained.</li> </ul>"},{"location":"principles/digital-workplace/","title":"Digital Workplace Principles","text":"<p>Approved</p> <p>These principles have been approved by the DHCW TDA</p>"},{"location":"principles/digital-workplace/#employee-experience-is-always-a-key-priority","title":"Employee experience is always a key priority","text":"<p>When designing, implementing, configuring or procuring products for the Digital Workplace, the employee (end-user) experience is always a key priority. Systems should be designed to meet user needs. Staff need to have the right tools for the right job.</p>"},{"location":"principles/digital-workplace/#support-must-be-proactive-in-nature-and-driven-by-data","title":"Support must be proactive in nature and driven by data","text":"<p>Proactive support reduces avoidable downtime and service disruption for our employees. Monitoring the user experience and underpinning infrastructure enables a shift to more proactive incident and problem management.</p>"},{"location":"principles/digital-workplace/#flexibility-to-work-effectively-from-multiple-locations-and-on-multiple-devices","title":"Flexibility to work effectively from multiple locations and on multiple devices","text":"<p>Employees will have the same rich digital workplace experience from all approved locations, whether from a DHCW office, other NHS premises or a location with only internet access, and from any approved device.</p> <p>Solutions must be designed to support an optimal hybrid-working experience and employees who have a blended work pattern (office, home/remote).</p>"},{"location":"principles/digital-workplace/#the-digital-workplace-exploits-ai-and-automation","title":"The Digital Workplace exploits AI and Automation","text":"<p>AI and automation supports and augments the work of the employee, freeing up time for higher-value work and improved employee wellbeing.</p>"},{"location":"principles/digital-workplace/#adopt-modern-technologies-and-best-practices","title":"Adopt modern technologies and best practices","text":"<p>Modern technologies and practices provide a richer digital experience for employees, allowing them to benefit from the latest features and services to support them in their work.</p>"},{"location":"principles/digital-workplace/#security-as-an-enabler","title":"Security as an enabler","text":"<p>Robust security measures must be implemented to both protect data and resources, but also facilitate enhanced production, collaboration and innovation.</p>"},{"location":"principles/digital-workplace/#digital-first","title":"Digital First","text":"<p>Systems and processes that support the Digital Workplace should be digital by design, reducing and eventually removing the need for manual alternatives.</p>"},{"location":"principles/digital-workplace/#reduce-the-carbon-footprint","title":"Reduce the Carbon Footprint","text":"<p>Reducing the carbon footprint of the Digital Workplace is essential to support decarbonisation goals.</p>"},{"location":"principles/digital-workplace/#supporting-the-accessibility-needs-of-workforce","title":"Supporting the accessibility needs of workforce","text":"<p>Systems that underpin the Digital Workplace must enable all staff to work to the best of their abilities and support any staff with particular needs.</p>"},{"location":"principles/digital-workplace/#supporting-the-use-of-the-welsh-language","title":"Supporting the use of the Welsh Language","text":"<p>We will ensure that Welsh language interfaces and supporting technology is made easily available to our users. Welsh language requirements will be included as part of the procurement for relevant services.</p>"},{"location":"principles/digital-workplace/#internet-first","title":"Internet First","text":"<p>When designing, implementing, configuring or procuring products for the Digital Workplace.</p>"},{"location":"principles/open-architecture/","title":"Open Architecture &amp; Integration Principles","text":"<p>Approved</p> <p>These principles have been approved by the DHCW TDA</p>"},{"location":"principles/open-architecture/#api-first","title":"API First","text":"<p>APIs will be the primary interface through which our platforms and products interact and exchange data.</p>"},{"location":"principles/open-architecture/#open-architecture","title":"Open Architecture","text":"<p>Our architecture will be open, enabled by discoverable, well documented, standards based and reusable APIs and governed by appropriate and proportionate onboarding processes.</p>"},{"location":"principles/open-architecture/#open-standards","title":"Open Standards","text":"<p>Interactions and data exchange between platforms and products will be based on open standards by default.</p>"},{"location":"principles/open-architecture/#secure-by-design","title":"Secure by Design","text":"<p>Our APIs, platforms and products will be designed and built to be secure from the ground up.</p>"},{"location":"principles/open-architecture/#shift-assurance-left","title":"Shift assurance left","text":"<p>Assurance, governance and quality will be built into our platforms and products from the ground up.</p>"},{"location":"principles/open-architecture/#user-centric-focused-on-value","title":"User centric &amp; focused on value","text":"<p>Platforms and products will be designed with our users in mind and architecture decisions will consider what will generate the best return of value in the long run.</p>"},{"location":"principles/open-architecture/#flexible-modular-scalable","title":"Flexible, Modular &amp; Scalable","text":"<p>We will design our platforms and products to be flexible, modular and scalable.</p>"},{"location":"principles/security-and-identity/","title":"Identity &amp; Security Principles","text":""},{"location":"principles/security-and-identity/#security-as-an-enabler","title":"Security as an enabler","text":"<p>Security should be viewed not as a barrier but a fundamental element that supports and enhances business objectives, innovation, and operation efficiency. Robust security measures will enable agility and trust.</p>"},{"location":"principles/security-and-identity/#minimum-effective-toolset","title":"Minimum effective toolset","text":"<p>Use the smallest number of tools and solutions necessary to achieve security objective effectively.</p>"},{"location":"principles/security-and-identity/#secure-supply-chain","title":"Secure supply chain","text":"<p>Ensure the supply chain is secured by ensuring the security, integrity and reliability of all parties responsible for delivery of services or products. This will involve an assessment of  security controls and standards of a supplier, and their incident response plans and capability.</p>"},{"location":"principles/security-and-identity/#assume-when-not-if","title":"Assume when not if","text":"<p>Instead of assuming a security breach might happen, DHCW must assume it will happen and plan accordingly. This will mean elevating response and recovery capabilities to the same status of detection and prevention.</p>"},{"location":"principles/security-and-identity/#design-for-isolation-where-possible","title":"Design for Isolation where possible","text":"<p>Systems, applications and processes should be compartmentalised where possible. Systems, applications and processes should be designed to isolate components and restrict their interaction unless explicitly required.</p>"},{"location":"principles/security-and-identity/#zero-trust","title":"Zero Trust","text":"<p>No device, user or system should be automatically trusted whether inside or outside the network perimeter, and must be given the minimum access necessary to complete their tasks (least privilege). All interactions must be monitored and audited.</p>"},{"location":"principles/security-and-identity/#defence-in-depth","title":"Defence in depth","text":"<p>Multiple layers of security controls and measures must be implemented to protect systems, infrastructure and data.</p>"},{"location":"principles/security-and-identity/#secure-by-design","title":"Secure by Design","text":"<p>Security must be incorporated into the design and development process of systems, infrastructure and applications from the start of the project, rather than considering security late in the design lifecycle.</p>"},{"location":"principles/security-and-identity/#single-source-of-truth","title":"Single source of truth","text":"<p>All users, applications and systems rely on a single, consistent, and authoritative source for authentication and user data.</p>"},{"location":"principles/security-and-identity/#verify-then-trust-emerging-technologies","title":"Verify then Trust Emerging Technologies","text":"<p>New technology such as GenAI must be comprehensively evaluated and validated before use by DHCW, particularly for critical systems.</p>"},{"location":"principles/security-and-identity/#simple-as-possible","title":"Simple as Possible","text":"<p>Minimise the complexity of the design, implementation and management of systems, applications and processes where possible. Use validated or previously used successful designs where possible.</p>"},{"location":"principles/user-centred-design/","title":"User-Centred Design (UCD) Principles","text":"<p>Approved</p> <p>These principles have been approved by the DHCW TDA</p>"},{"location":"principles/user-centred-design/#start-with-user-needs","title":"Start with user needs","text":"<p>Test your assumptions.</p> <p>Public services are for everyone and must be driven by user needs.</p> <p>User research prevents wasted resources and reveals real problems, enabling evidence-based, cost-effective decisions.</p>"},{"location":"principles/user-centred-design/#design-with-data","title":"Design with  data","text":"<p>Use data to make decision.</p> <p>Continuously monitor service performance and use data and user feedback to prioritise improvements and identify problems that need to be fixed</p>"},{"location":"principles/user-centred-design/#do-the-hard-work-to-make-it-simple-and-inclusive","title":"Do the hard work to make it simple and inclusive","text":"<p>Make the service easy to use and make sure everyone can use it.</p> <p>Design inclusively, ensuring easy access for all, including those often excluded.</p> <p>Healthcare can be complex. Do the hard work to make it simpler</p>"},{"location":"principles/user-centred-design/#design-for-outcome-and-context","title":"Design for outcome and context","text":"<p>Consider what good will look like, how it fits with the entire services, and how you will measure outcomes.</p> <p>Understand users and their needs in the context of health and care.</p>"},{"location":"principles/user-centred-design/#iterate-learn-improve","title":"Iterate. Learn, Improve","text":"<p>Use an incremental, fast-paced approach to get working products into users\u2019 hands as early as possible, as often as possible.</p> <p>Rapidly iterate and focus on the improvements that have the most value, based on user feedback.</p>"},{"location":"principles/user-centred-design/#make-things-open-and-consistent","title":"Make things open and consistent","text":"<p>Use and contribute to open standards, common components and patterns and share what you\u2019re doing whenever you can.</p>"},{"location":"principles/user-centred-design/#design-services-in-welsh-and-english","title":"Design services in Welsh and English","text":"<p>Design and build services that promote and ease the use of Welsh and treat those who speak it equally with those who speak English.</p>"},{"location":"principles/user-centred-design/#design-for-trust","title":"Design for trust","text":"<p>Services must be secure and safe to maintain users\u2019 trust.</p> <p>Digital information, tools and services have the potential to cause patient harm.</p> <p>Respect and protect users' confidentiality and privacy.</p>"},{"location":"principles/user-centred-design/#minimise-environmental-impact","title":"Minimise environmental impact","text":"<p>The climate crisis is a health crisis.</p> <p>Follow sustainability best practice to reduce the environmental impact of your service across its lifespan.</p>"}]}